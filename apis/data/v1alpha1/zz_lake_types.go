/*
Copyright 2022 Upbound Inc.
*/

// Code generated by upjet. DO NOT EDIT.

package v1alpha1

import (
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
	"k8s.io/apimachinery/pkg/runtime/schema"

	v1 "github.com/crossplane/crossplane-runtime/apis/common/v1"
)

type AwsObservation struct {

	// Unique identifier associated with the IAM Role that Data Lake assumes when accessing the data stores.
	ExternalID *string `json:"externalId,omitempty" tf:"external_id,omitempty"`

	// Amazon Resource Name (ARN) of the IAM Role that Data Lake assumes when accessing S3 Bucket data stores. The IAM Role must support the following actions against each S3 bucket:
	IAMAssumedRoleArn *string `json:"iamAssumedRoleArn,omitempty" tf:"iam_assumed_role_arn,omitempty"`

	// Amazon Resource Name (ARN) of the user that Data Lake assumes when accessing S3 Bucket data stores.
	IAMUserArn *string `json:"iamUserArn,omitempty" tf:"iam_user_arn,omitempty"`

	// Unique identifier of the role that Data Lake can use to access the data stores. If necessary, use the Atlas UI or API to retrieve the role ID. You must also specify the aws.0.test_s3_bucket.
	RoleID *string `json:"roleId,omitempty" tf:"role_id,omitempty"`

	// Name of the S3 data bucket that the provided role ID is authorized to access. You must also specify the aws.0.role_id.
	TestS3Bucket *string `json:"testS3Bucket,omitempty" tf:"test_s3_bucket,omitempty"`
}

type AwsParameters struct {

	// Unique identifier of the role that Data Lake can use to access the data stores. If necessary, use the Atlas UI or API to retrieve the role ID. You must also specify the aws.0.test_s3_bucket.
	// +kubebuilder:validation:Required
	RoleID *string `json:"roleId" tf:"role_id,omitempty"`

	// Name of the S3 data bucket that the provided role ID is authorized to access. You must also specify the aws.0.role_id.
	// +kubebuilder:validation:Required
	TestS3Bucket *string `json:"testS3Bucket" tf:"test_s3_bucket,omitempty"`
}

type CollectionsObservation struct {

	// Array of objects where each object represents a stores data store to map with the collection.
	DataSources []DataSourcesObservation `json:"dataSources,omitempty" tf:"data_sources,omitempty"`

	// Name of the data store.
	Name *string `json:"name,omitempty" tf:"name,omitempty"`
}

type CollectionsParameters struct {
}

type DataProcessRegionObservation struct {

	// Name of the cloud service provider. Atlas Data Lake only supports AWS.
	CloudProvider *string `json:"cloudProvider,omitempty" tf:"cloud_provider,omitempty"`

	// Name of the AWS region in which the S3 bucket is hosted.
	Region *string `json:"region,omitempty" tf:"region,omitempty"`
}

type DataProcessRegionParameters struct {

	// Name of the cloud service provider. Atlas Data Lake only supports AWS.
	// +kubebuilder:validation:Required
	CloudProvider *string `json:"cloudProvider" tf:"cloud_provider,omitempty"`

	// Name of the AWS region in which the S3 bucket is hosted.
	// +kubebuilder:validation:Required
	Region *string `json:"region" tf:"region,omitempty"`
}

type DataSourcesObservation struct {

	// Default format that Data Lake assumes if it encounters a file without an extension while searching the storeName.
	DefaultFormat *string `json:"defaultFormat,omitempty" tf:"default_format,omitempty"`

	// Controls how Atlas Data Lake searches for and parses files in the storeName before mapping them to the <collection>.
	Path *string `json:"path,omitempty" tf:"path,omitempty"`

	// Name of a data store to map to the <collection>. Must match the name of an object in the stores array.
	StoreName *string `json:"storeName,omitempty" tf:"store_name,omitempty"`
}

type DataSourcesParameters struct {
}

type LakeObservation struct {

	// AWS provider of the cloud service where Data Lake can access the S3 Bucket.
	Aws []AwsObservation `json:"aws,omitempty" tf:"aws,omitempty"`

	// The cloud provider region to which Atlas Data Lake routes client connections for data processing. Set to null to direct Atlas Data Lake to route client connections to the region nearest to the client based on DNS resolution.
	DataProcessRegion []DataProcessRegionObservation `json:"dataProcessRegion,omitempty" tf:"data_process_region,omitempty"`

	// The list of hostnames assigned to the Atlas Data Lake. Each string in the array is a hostname assigned to the Atlas Data Lake.
	Hostnames []*string `json:"hostnames,omitempty" tf:"hostnames,omitempty"`

	ID *string `json:"id,omitempty" tf:"id,omitempty"`

	// The unique ID for the project to create a data lake.
	ProjectID *string `json:"projectId,omitempty" tf:"project_id,omitempty"`

	// Current state of the Atlas Data Lake:
	State *string `json:"state,omitempty" tf:"state,omitempty"`

	// Configuration details for mapping each data store to queryable databases and collections. For complete documentation on this object and its nested fields, see databases. An empty object indicates that the Data Lake has no mapping configuration for any data store.
	StorageDatabases []StorageDatabasesObservation `json:"storageDatabases,omitempty" tf:"storage_databases,omitempty"`

	// Each object in the array represents a data store. Data Lake uses the storage.databases configuration details to map data in each data store to queryable databases and collections. For complete documentation on this object and its nested fields, see stores. An empty object indicates that the Data Lake has no configured data stores.
	StorageStores []StorageStoresObservation `json:"storageStores,omitempty" tf:"storage_stores,omitempty"`
}

type LakeParameters struct {

	// AWS provider of the cloud service where Data Lake can access the S3 Bucket.
	// +kubebuilder:validation:Optional
	Aws []AwsParameters `json:"aws,omitempty" tf:"aws,omitempty"`

	// The cloud provider region to which Atlas Data Lake routes client connections for data processing. Set to null to direct Atlas Data Lake to route client connections to the region nearest to the client based on DNS resolution.
	// +kubebuilder:validation:Optional
	DataProcessRegion []DataProcessRegionParameters `json:"dataProcessRegion,omitempty" tf:"data_process_region,omitempty"`

	// The unique ID for the project to create a data lake.
	// +kubebuilder:validation:Optional
	ProjectID *string `json:"projectId,omitempty" tf:"project_id,omitempty"`
}

type StorageDatabasesObservation struct {

	// Array of objects where each object represents a collection and data sources that map to a stores data store.
	Collections []CollectionsObservation `json:"collections,omitempty" tf:"collections,omitempty"`

	MaxWildcardCollections *float64 `json:"maxWildcardCollections,omitempty" tf:"max_wildcard_collections,omitempty"`

	// Name of the data store.
	Name *string `json:"name,omitempty" tf:"name,omitempty"`

	// Array of objects where each object represents an aggregation pipeline on a collection. To learn more about views, see Views.
	Views []ViewsObservation `json:"views,omitempty" tf:"views,omitempty"`
}

type StorageDatabasesParameters struct {
}

type StorageStoresObservation struct {
	AdditionalStorageClasses []*string `json:"additionalStorageClasses,omitempty" tf:"additional_storage_classes,omitempty"`

	// Name of the AWS S3 bucket.
	Bucket *string `json:"bucket,omitempty" tf:"bucket,omitempty"`

	// The delimiter that separates storage_databases.#.collections.#.data_sources.#.path segments in the data store.
	Delimiter *string `json:"delimiter,omitempty" tf:"delimiter,omitempty"`

	// Determines whether or not to use S3 tags on the files in the given path as additional partition attributes.
	IncludeTags *bool `json:"includeTags,omitempty" tf:"include_tags,omitempty"`

	// Name of the data store.
	Name *string `json:"name,omitempty" tf:"name,omitempty"`

	// Prefix Data Lake applies when searching for files in the S3 bucket .
	Prefix *string `json:"prefix,omitempty" tf:"prefix,omitempty"`

	// Defines where the data is stored.
	Provider *string `json:"provider,omitempty" tf:"provider,omitempty"`

	// Name of the AWS region in which the S3 bucket is hosted.
	Region *string `json:"region,omitempty" tf:"region,omitempty"`
}

type StorageStoresParameters struct {
}

type ViewsObservation struct {

	// Name of the data store.
	Name *string `json:"name,omitempty" tf:"name,omitempty"`

	// Aggregation pipeline stage(s) to apply to the source collection.
	Pipeline *string `json:"pipeline,omitempty" tf:"pipeline,omitempty"`

	// Name of the source collection for the view.
	Source *string `json:"source,omitempty" tf:"source,omitempty"`
}

type ViewsParameters struct {
}

// LakeSpec defines the desired state of Lake
type LakeSpec struct {
	v1.ResourceSpec `json:",inline"`
	ForProvider     LakeParameters `json:"forProvider"`
}

// LakeStatus defines the observed state of Lake.
type LakeStatus struct {
	v1.ResourceStatus `json:",inline"`
	AtProvider        LakeObservation `json:"atProvider,omitempty"`
}

// +kubebuilder:object:root=true

// Lake is the Schema for the Lakes API. Provides a Data Lake resource.
// +kubebuilder:printcolumn:name="READY",type="string",JSONPath=".status.conditions[?(@.type=='Ready')].status"
// +kubebuilder:printcolumn:name="SYNCED",type="string",JSONPath=".status.conditions[?(@.type=='Synced')].status"
// +kubebuilder:printcolumn:name="EXTERNAL-NAME",type="string",JSONPath=".metadata.annotations.crossplane\\.io/external-name"
// +kubebuilder:printcolumn:name="AGE",type="date",JSONPath=".metadata.creationTimestamp"
// +kubebuilder:subresource:status
// +kubebuilder:resource:scope=Cluster,categories={crossplane,managed,mongodbatlas}
type Lake struct {
	metav1.TypeMeta   `json:",inline"`
	metav1.ObjectMeta `json:"metadata,omitempty"`
	// +kubebuilder:validation:XValidation:rule="self.managementPolicy == 'ObserveOnly' || has(self.forProvider.aws)",message="aws is a required parameter"
	// +kubebuilder:validation:XValidation:rule="self.managementPolicy == 'ObserveOnly' || has(self.forProvider.projectId)",message="projectId is a required parameter"
	Spec   LakeSpec   `json:"spec"`
	Status LakeStatus `json:"status,omitempty"`
}

// +kubebuilder:object:root=true

// LakeList contains a list of Lakes
type LakeList struct {
	metav1.TypeMeta `json:",inline"`
	metav1.ListMeta `json:"metadata,omitempty"`
	Items           []Lake `json:"items"`
}

// Repository type metadata.
var (
	Lake_Kind             = "Lake"
	Lake_GroupKind        = schema.GroupKind{Group: CRDGroup, Kind: Lake_Kind}.String()
	Lake_KindAPIVersion   = Lake_Kind + "." + CRDGroupVersion.String()
	Lake_GroupVersionKind = CRDGroupVersion.WithKind(Lake_Kind)
)

func init() {
	SchemeBuilder.Register(&Lake{}, &LakeList{})
}
