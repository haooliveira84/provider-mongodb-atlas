name: mongodb/mongodbatlas
resources:
    federated_database_query_limit:
        subCategory: ""
        description: Provides a Federated Database Instance Query Limit.
        name: federated_database_query_limit
        title: federated_database_query_limit
        argumentDocs:
            bytesProcessed.daily: ': Limit on the number of bytes processed for the data federation instance for the current day.'
            bytesProcessed.monthly: ': Limit on the number of bytes processed for the data federation instance for the current month.'
            bytesProcessed.query: ': Limit on the number of bytes processed during a single data federation query.'
            bytesProcessed.weekly: ': Limit on the number of bytes processed for the data federation instance for the current week.'
            current_usage: '- Amount that indicates the current usage of the limit.'
            default_limit: '- Default value of the limit.'
            id: '- The Terraform''s unique identifier used internally for state management.'
            lastModifiedDate: '- Only used for Data Federation limits. Timestamp that indicates when this usage limit was last modified. This field uses the ISO 8601 timestamp format in UTC.'
            limit_name: '- (Required) String enum that indicates whether the identity provider is active or not. Accepted values are:'
            maximumLimit: '- Maximum value of the limit.'
            name: '- Name that identifies the user-managed limit to modify.'
            overrun_policy: '- (Required) String enum that identifies action to take when the usage limit is exceeded. If limit span is set to QUERY, this is ignored because MongoDB Cloud stops the query when it exceeds the usage limit. Accepted values are "BLOCK" OR "BLOCK_AND_KILL"'
            project_id: '- (Required) The unique ID for the project to create a Federated Database Instance.'
            tenant_name: '- (Required) Name of the Atlas Federated Database Instance.'
            value: '- (Required) Amount to set the limit to.'
        importStatements: []
    ldap-configuration:
        subCategory: ""
        description: Provides a LDAP Configuration resource.
        name: ldap-configuration
        title: ldap-configuration
        argumentDocs:
            authentication_enabled: '- (Required) Specifies whether user authentication with LDAP is enabled.'
            authorization_enabled: '- (Optional) Specifies whether user authorization with LDAP is enabled. You cannot enable user authorization with LDAP without first enabling user authentication with LDAP.'
            authz_query_template: '- (Optional) An LDAP query template that Atlas executes to obtain the LDAP groups to which the authenticated user belongs. Used only for user authorization. Use the {USER} placeholder in the URL to substitute the authenticated username. The query is relative to the host specified with hostname. The formatting for the query must conform to RFC4515 and RFC 4516. If you do not provide a query template, Atlas attempts to use the default value: {USER}?memberOf?base.'
            bind_password: '- (Required) The password used to authenticate the bind_username.'
            bind_username: '- (Required) The user DN that Atlas uses to connect to the LDAP server. Must be the full DN, such as CN=BindUser,CN=Users,DC=myldapserver,DC=mycompany,DC=com.'
            ca_certificate: '- (Optional) CA certificate used to verify the identify of the LDAP server. Self-signed certificates are allowed.'
            hostname: '- (Required) The hostname or IP address of the LDAP server. The server must be visible to the internet or connected to your Atlas cluster with VPC Peering.'
            port: '- (Optional) The port to which the LDAP server listens for client connections. Default: 636'
            project_id: '- (Required) The unique ID for the project to configure LDAP.'
            user_to_dn_mapping: '- (Optional) Maps an LDAP username for authentication to an LDAP Distinguished Name (DN). Each document contains a match regular expression and either a substitution or ldap_query template used to transform the LDAP username extracted from the regular expression. Atlas steps through the each document in the array in the given order, checking the authentication username against the match filter. If a match is found, Atlas applies the transformation and uses the output to authenticate the user. Atlas does not check the remaining documents in the array. For more details and examples see the MongoDB Atlas API Reference.'
            user_to_dn_mapping.0.ldap_query: '- (Optional) An LDAP query formatting template that inserts the LDAP name matched by the match regular expression into an LDAP query URI as specified by RFC 4515 and RFC 4516. Each numeric value is replaced by the corresponding regular expression capture group extracted from the LDAP username that matched the match regular expression.'
            user_to_dn_mapping.0.match: '- (Optional) A regular expression to match against a provided LDAP username. Each parenthesis-enclosed section represents a regular expression capture group used by the substitution or ldap_query template.'
            user_to_dn_mapping.0.substitution: '- (Optional) An LDAP Distinguished Name (DN) formatting template that converts the LDAP name matched by the match regular expression into an LDAP Distinguished Name. Each bracket-enclosed numeric value is replaced by the corresponding regular expression capture group extracted from the LDAP username that matched the match regular expression.'
        importStatements: []
    ldap-verify:
        subCategory: ""
        description: Provides a LDAP Verify resource.
        name: ldap-verify
        title: ldap-verify
        argumentDocs:
            authz_query_template: '- (Optional) An LDAP query template that Atlas executes to obtain the LDAP groups to which the authenticated user belongs. Used only for user authorization. Use the {USER} placeholder in the URL to substitute the authenticated username. The query is relative to the host specified with hostname. The formatting for the query must conform to RFC4515 and RFC 4516. If you do not provide a query template, Atlas attempts to use the default value: {USER}?memberOf?base.'
            bind_password: '- (Required) The password used to authenticate the bind_username.'
            bind_username: '- (Required) The user DN that Atlas uses to connect to the LDAP server. Must be the full DN, such as CN=BindUser,CN=Users,DC=myldapserver,DC=mycompany,DC=com.'
            ca_certificate: '- (Optional) CA certificate used to verify the identify of the LDAP server. Self-signed certificates are allowed.'
            hostname: '- (Required) The hostname or IP address of the LDAP server. The server must be visible to the internet or connected to your Atlas cluster with VPC Peering.'
            links: '- One or more links to sub-resources. The relations in the URLs are explained in the Web Linking Specification.'
            port: '- (Optional) The port to which the LDAP server listens for client connections. Default: 636'
            project_id: '- (Required) The unique ID for the project to configure LDAP.'
            request_id: '- The unique identifier for the request to verify the LDAP over TLS/SSL configuration.'
            status: '- The current status of the LDAP over TLS/SSL configuration. One of the following values: PENDING, SUCCESS, and FAILED.'
            validations: '- Array of validation messages related to the verification of the provided LDAP over TLS/SSL configuration details. The array contains a document for each test that Atlas runs. Atlas stops running tests after the first failure. The following return values can be seen here: Values'
        importStatements: []
    mongodbatlas_access_list_api_key:
        subCategory: ""
        description: Creates the access list entries for the specified Atlas Organization API Key.
        name: mongodbatlas_access_list_api_key
        title: access_list_api_key
        examples:
            - name: test
              manifest: |-
                {
                  "api_key_id": "a29120e123cd",
                  "cidr_block": "1.2.3.4/32",
                  "org_id": "\u003cORG-ID\u003e"
                }
            - name: test
              manifest: |-
                {
                  "api_key_id": "a29120e123cd",
                  "ip_address": "2.3.4.5",
                  "org_id": "\u003cORG-ID\u003e"
                }
        argumentDocs:
            api_key_id: '- Unique identifier for the Organization API Key for which you want to create a new access list entry.'
            cidr_block: '- (Optional) Range of IP addresses in CIDR notation to be added to the access list. Your access list entry can include only one cidrBlock, or one ipAddress.'
            ip_address: '- (Optional) Single IP address to be added to the access list.'
            org_id: '- (Required) Unique 24-hexadecimal digit string that identifies the organization that contains your projects.'
        importStatements: []
    mongodbatlas_advanced_cluster:
        subCategory: ""
        description: Provides an Advanced Cluster resource.
        name: mongodbatlas_advanced_cluster
        title: advanced_cluster
        examples:
            - name: test
              manifest: |-
                {
                  "cluster_type": "REPLICASET",
                  "name": "NAME OF CLUSTER",
                  "project_id": "PROJECT ID",
                  "replication_specs": [
                    {
                      "region_configs": [
                        {
                          "analytics_specs": [
                            {
                              "instance_size": "M10",
                              "node_count": 1
                            }
                          ],
                          "electable_specs": [
                            {
                              "instance_size": "M10",
                              "node_count": 3
                            }
                          ],
                          "priority": 7,
                          "provider_name": "AWS",
                          "region_name": "US_EAST_1"
                        }
                      ]
                    }
                  ]
                }
            - name: test
              manifest: |-
                {
                  "cluster_type": "REPLICASET",
                  "name": "NAME OF CLUSTER",
                  "project_id": "PROJECT ID",
                  "replication_specs": [
                    {
                      "region_configs": [
                        {
                          "backing_provider_name": "AWS",
                          "electable_specs": [
                            {
                              "instance_size": "M5"
                            }
                          ],
                          "priority": 7,
                          "provider_name": "TENANT",
                          "region_name": "US_EAST_1"
                        }
                      ]
                    }
                  ]
                }
            - name: test
              manifest: |-
                {
                  "cluster_type": "REPLICASET",
                  "name": "NAME OF CLUSTER",
                  "project_id": "PROJECT ID",
                  "replication_specs": [
                    {
                      "region_configs": [
                        {
                          "electable_specs": [
                            {
                              "instance_size": "M10"
                            }
                          ],
                          "priority": 7,
                          "provider_name": "AWS",
                          "region_name": "US_EAST_1"
                        }
                      ]
                    }
                  ]
                }
            - name: test
              manifest: |-
                {
                  "cluster_type": "REPLICASET",
                  "name": "NAME OF CLUSTER",
                  "project_id": "PROJECT ID",
                  "replication_specs": [
                    {
                      "region_configs": [
                        {
                          "analytics_specs": [
                            {
                              "instance_size": "M10",
                              "node_count": 1
                            }
                          ],
                          "electable_specs": [
                            {
                              "instance_size": "M10",
                              "node_count": 3
                            }
                          ],
                          "priority": 7,
                          "provider_name": "AWS",
                          "region_name": "US_EAST_1"
                        },
                        {
                          "electable_specs": [
                            {
                              "instance_size": "M10",
                              "node_count": 2
                            }
                          ],
                          "priority": 6,
                          "provider_name": "GCP",
                          "region_name": "NORTH_AMERICA_NORTHEAST_1"
                        }
                      ]
                    }
                  ]
                }
            - name: cluster
              manifest: |-
                {
                  "advanced_configuration": [
                    {
                      "javascript_enabled": true,
                      "oplog_size_mb": 30,
                      "sample_refresh_interval_bi_connector": 300
                    }
                  ],
                  "backup_enabled": true,
                  "cluster_type": "SHARDED",
                  "name": "${var.cluster_name}",
                  "project_id": "${mongodbatlas_project.project.id}",
                  "replication_specs": [
                    {
                      "num_shards": 3,
                      "region_configs": [
                        {
                          "analytics_specs": [
                            {
                              "instance_size": "M10",
                              "node_count": 1
                            }
                          ],
                          "electable_specs": [
                            {
                              "instance_size": "M10",
                              "node_count": 3
                            }
                          ],
                          "priority": 7,
                          "provider_name": "AWS",
                          "region_name": "US_EAST_1"
                        },
                        {
                          "analytics_specs": [
                            {
                              "instance_size": "M10",
                              "node_count": 1
                            }
                          ],
                          "electable_specs": [
                            {
                              "instance_size": "M10",
                              "node_count": 2
                            }
                          ],
                          "priority": 6,
                          "provider_name": "AZURE",
                          "region_name": "US_EAST_2"
                        },
                        {
                          "analytics_specs": [
                            {
                              "instance_size": "M10",
                              "node_count": 1
                            }
                          ],
                          "electable_specs": [
                            {
                              "instance_size": "M10",
                              "node_count": 2
                            }
                          ],
                          "priority": 5,
                          "provider_name": "GCP",
                          "region_name": "US_EAST_4"
                        }
                      ]
                    }
                  ]
                }
              references:
                name: var.cluster_name
                project_id: mongodbatlas_project.project.id
            - name: cluster
              manifest: |-
                {
                  "advanced_configuration": [
                    {
                      "javascript_enabled": true,
                      "oplog_size_mb": 999,
                      "sample_refresh_interval_bi_connector": 300
                    }
                  ],
                  "backup_enabled": true,
                  "cluster_type": "GEOSHARDED",
                  "name": "${var.cluster_name}",
                  "project_id": "${mongodbatlas_project.project.id}",
                  "replication_specs": [
                    {
                      "num_shards": 3,
                      "region_configs": [
                        {
                          "analytics_specs": [
                            {
                              "instance_size": "M10",
                              "node_count": 1
                            }
                          ],
                          "electable_specs": [
                            {
                              "instance_size": "M10",
                              "node_count": 3
                            }
                          ],
                          "priority": 7,
                          "provider_name": "AWS",
                          "region_name": "US_EAST_1"
                        },
                        {
                          "analytics_specs": [
                            {
                              "instance_size": "M10",
                              "node_count": 1
                            }
                          ],
                          "electable_specs": [
                            {
                              "instance_size": "M10",
                              "node_count": 2
                            }
                          ],
                          "priority": 6,
                          "provider_name": "AZURE",
                          "region_name": "US_EAST_2"
                        },
                        {
                          "analytics_specs": [
                            {
                              "instance_size": "M10",
                              "node_count": 1
                            }
                          ],
                          "electable_specs": [
                            {
                              "instance_size": "M10",
                              "node_count": 2
                            }
                          ],
                          "priority": 5,
                          "provider_name": "GCP",
                          "region_name": "US_EAST_4"
                        }
                      ],
                      "zone_name": "zone n1"
                    },
                    {
                      "num_shards": 2,
                      "region_configs": [
                        {
                          "analytics_specs": [
                            {
                              "instance_size": "M10",
                              "node_count": 1
                            }
                          ],
                          "electable_specs": [
                            {
                              "instance_size": "M10",
                              "node_count": 3
                            }
                          ],
                          "priority": 7,
                          "provider_name": "AWS",
                          "region_name": "EU_WEST_1"
                        },
                        {
                          "analytics_specs": [
                            {
                              "instance_size": "M10",
                              "node_count": 1
                            }
                          ],
                          "electable_specs": [
                            {
                              "instance_size": "M10",
                              "node_count": 2
                            }
                          ],
                          "priority": 6,
                          "provider_name": "AZURE",
                          "region_name": "EUROPE_NORTH"
                        },
                        {
                          "analytics_specs": [
                            {
                              "instance_size": "M10",
                              "node_count": 1
                            }
                          ],
                          "electable_specs": [
                            {
                              "instance_size": "M10",
                              "node_count": 2
                            }
                          ],
                          "priority": 5,
                          "provider_name": "GCP",
                          "region_name": "US_EAST_4"
                        }
                      ],
                      "zone_name": "zone n2"
                    }
                  ]
                }
              references:
                name: var.cluster_name
                project_id: mongodbatlas_project.project.id
        argumentDocs:
            AWS: '- Amazon AWS'
            AZURE: '- Microsoft Azure'
            CONTINUOUS: ':  Atlas creates your cluster using the most recent MongoDB release. Atlas automatically updates your cluster to the latest major and rapid MongoDB releases as they become available.'
            GCP: '- Google Cloud Platform'
            LTS: ': Atlas creates your cluster using the latest patch release of the MongoDB version that you specify in the mongoDBMajorVersion field. Atlas automatically updates your cluster to subsequent patch releases of this MongoDB version. Atlas doesn''t update your cluster to newer rapid or major MongoDB releases as they become available.'
            PROVISIONED: volume types must fall within the allowable IOPS range for the selected volume size.
            STANDARD: volume types can't exceed the default IOPS rate for the selected volume size.
            TENANT: '- M2 or M5 multi-tenant cluster. Use replication_specs.#.region_configs.#.backing_provider_name to set the cloud service provider.'
            backup_enabled: |-
                - (Optional) Flag that indicates whether the cluster can perform backups.
                If true, the cluster can perform backups. You must set this value to true for NVMe clusters.
            bi_connector_config: '- (Optional) Configuration settings applied to BI Connector for Atlas on this cluster. The MongoDB Connector for Business Intelligence for Atlas (BI Connector) is only available for M10 and larger clusters. The BI Connector is a powerful tool which provides users SQL-based access to their MongoDB databases. As a result, the BI Connector performs operations which may be CPU and memory intensive. Given the limited hardware resources on M10 and M20 cluster tiers, you may experience performance degradation of the cluster when enabling the BI Connector. If this occurs, upgrade to an M30 or larger cluster or disable the BI Connector. See below.'
            bi_connector_config.enabled: '- (Optional) Specifies whether or not BI Connector for Atlas is enabled on the cluster.l'
            bi_connector_config.false: to disable BI Connector for Atlas.
            bi_connector_config.read_preference: '- (Optional) Specifies the read preference to be used by BI Connector for Atlas on the cluster. Each BI Connector for Atlas read preference contains a distinct combination of readPreference and readPreferenceTags options. For details on BI Connector for Atlas read preferences, refer to the BI Connector Read Preferences Table.'
            bi_connector_config.true: to enable BI Connector for Atlas.
            cluster_id: '- The cluster ID.'
            cluster_type: '- (Required) Atlas provides different instance sizes, each with a default storage capacity and RAM size. The instance size you select is used for all the data-bearing servers in your cluster. See Create a Cluster providerSettings.instanceSizeName for valid values and default resources.'
            connection_strings: '- Set of connection strings that your applications use to connect to this cluster. More info in Connection-strings. Use the parameters in this object to connect your applications to this cluster. To learn more about the formats of connection strings, see Connection String Options. NOTE: Atlas returns the contents of this object after the cluster is operational, not while it builds the cluster.'
            connection_strings.aws_private_link: '-  Private-endpoint-aware mongodb://connection strings for each interface VPC endpoint you configured to connect to this cluster. Returned only if you created a AWS PrivateLink connection to this cluster. DEPRECATED Use connection_strings.private_endpoint[n].connection_string instead.'
            connection_strings.aws_private_link_srv: '- Private-endpoint-aware mongodb+srv://connection strings for each interface VPC endpoint you configured to connect to this cluster. Returned only if you created a AWS PrivateLink connection to this cluster. Use this URI format if your driver supports it. If it doesn’t, use connectionStrings.awsPrivateLink. DEPRECATED Use connection_strings.private_endpoint[n].srv_connection_string instead.'
            connection_strings.private: '-   Network-peering-endpoint-aware mongodb://connection strings for each interface VPC endpoint you configured to connect to this cluster. Returned only if you created a network peering connection to this cluster.'
            connection_strings.private_endpoint: '- Private endpoint connection strings. Each object describes the connection strings you can use to connect to this cluster through a private endpoint. Atlas returns this parameter only if you deployed a private endpoint to all regions to which you deployed this cluster''s nodes.'
            connection_strings.private_endpoint.#.connection_string: '- Private-endpoint-aware mongodb://connection string for this private endpoint.'
            connection_strings.private_endpoint.#.endpoints: '- Private endpoint through which you connect to Atlas when you use connection_strings.private_endpoint[n].connection_string or connection_strings.private_endpoint[n].srv_connection_string'
            connection_strings.private_endpoint.#.endpoints.#.endpoint_id: '- Unique identifier of the private endpoint.'
            connection_strings.private_endpoint.#.endpoints.#.provider_name: '- Cloud provider to which you deployed the private endpoint. Atlas returns AWS or AZURE.'
            connection_strings.private_endpoint.#.endpoints.#.region: '- Region to which you deployed the private endpoint.'
            connection_strings.private_endpoint.#.srv_connection_string: '- Private-endpoint-aware mongodb+srv:// connection string for this private endpoint. The mongodb+srv protocol tells the driver to look up the seed list of hosts in DNS . Atlas synchronizes this list with the nodes in a cluster. If the connection string uses this URI format, you don''t need to: Append the seed list or Change the URI if the nodes change. Use this URI format if your driver supports it. If it doesn''t, use connection_strings.private_endpoint[n].connection_string'
            connection_strings.private_endpoint.#.srv_shard_optimized_connection_string: '- Private endpoint-aware connection string optimized for sharded clusters that uses the mongodb+srv:// protocol to connect to MongoDB Cloud through a private endpoint. If the connection string uses this Uniform Resource Identifier (URI) format, you don''t need to change the Uniform Resource Identifier (URI) if the nodes change. Use this Uniform Resource Identifier (URI) format if your application and Atlas cluster supports it. If it doesn''t, use and consult the documentation for connectionStrings.privateEndpoint[n].srvConnectionString.'
            connection_strings.private_endpoint.#.type: '- Type of MongoDB process that you connect to with the connection strings. Atlas returns MONGOD for replica sets, or MONGOS for sharded clusters.'
            connection_strings.private_srv: '-  Network-peering-endpoint-aware mongodb+srv://connection strings for each interface VPC endpoint you configured to connect to this cluster. Returned only if you created a network peering connection to this cluster.'
            connection_strings.standard: '-   Public mongodb:// connection string for this cluster.'
            connection_strings.standard_srv: '- Public mongodb+srv:// connection string for this cluster. The mongodb+srv protocol tells the driver to look up the seed list of hosts in DNS. Atlas synchronizes this list with the nodes in a cluster. If the connection string uses this URI format, you don’t need to append the seed list or change the URI if the nodes change. Use this URI format if your driver supports it. If it doesn’t  , use connectionStrings.standard.'
            default_read_concern: '- (Optional) Default level of acknowledgment requested from MongoDB for read operations set for this cluster. MongoDB 4.4 clusters default to available.'
            default_write_concern: '- (Optional) Default level of acknowledgment requested from MongoDB for write operations set for this cluster. MongoDB 4.4 clusters default to 1.'
            disk_size_gb: '- (Optional) Capacity, in gigabytes, of the host''s root volume. Increase this number to add capacity, up to a maximum possible value of 4096 (i.e., 4 TB). This value must be a positive number. You can''t set this value with clusters with local NVMe SSDs. The minimum disk size for dedicated clusters is 10 GB for AWS and GCP. If you specify diskSizeGB with a lower disk size, Atlas defaults to the minimum disk size value. If your cluster includes Azure nodes, this value must correspond to an existing Azure disk type (8, 16, 32, 64, 128, 256, 512, 1024, 2048, or 4095)Atlas calculates storage charges differently depending on whether you choose the default value or a custom value. The maximum value for disk storage cannot exceed 50 times the maximum RAM for the selected cluster. If you require additional storage space beyond this limitation, consider upgrading your cluster to a higher tier. If your cluster spans cloud service providers, this value defaults to the minimum default of the providers involved.'
            encryption_at_rest_provider: '- (Optional) Possible values are AWS, GCP, AZURE or NONE.  Only needed if you desire to manage the keys, see Encryption at Rest using Customer Key Management for complete documentation.  You must configure encryption at rest for the Atlas project before enabling it on any cluster in the project. For Documentation, see AWS, GCP and Azure. Requirements are if replication_specs.#.region_configs.#.<type>Specs.instance_size is M10 or greater and backup_enabled is false or omitted.'
            fail_index_key_too_long: '- (Optional) When true, documents can only be updated or inserted if, for all indexed fields on the target collection, the corresponding index entries do not exceed 1024 bytes. When false, mongod writes documents that exceed the limit but does not index them.'
            "false": to disable disk auto-scaling.
            id: "-\tThe Terraform's unique identifier used internally for state management."
            javascript_enabled: '- (Optional) When true, the cluster allows execution of operations that perform server-side executions of JavaScript. When false, the cluster disables execution of those operations.'
            labels: '- (Optional) Configuration for the collection of key-value pairs that tag and categorize the cluster. See below.'
            labels.key: '- The key that you want to write.'
            labels.value: '- The value that you want to write.'
            minimum_enabled_tls_protocol: '- (Optional) Sets the minimum Transport Layer Security (TLS) version the cluster accepts for incoming connections.Valid values are:'
            mongo_db_major_version: '- (Optional) Version of the cluster to deploy. Atlas supports the following MongoDB versions for M10+ clusters: 4.0, 4.2, 4.4, or 5.0. If omitted, Atlas deploys a cluster that runs MongoDB 4.4. If replication_specs#.region_configs#.<type>Specs.instance_size: M0, M2 or M5, Atlas deploys MongoDB 4.4. Atlas always deploys the cluster with the latest stable release of the specified version.  If you set a value to this parameter and set version_release_system CONTINUOUS, the resource returns an error. Either clear this parameter or set version_release_system: LTS.'
            mongo_db_version: '- Version of MongoDB the cluster runs, in major-version.minor-version format.'
            mongodbatlas_privatelink_endpoint_service: |-
                resources are fully applied. Add a depends_on = [mongodbatlas_privatelink_endpoint_service.example] to ensure connection_strings are available following terraform apply.
                If the expected connection string(s) do not contain a value, a terraform refresh may need to be performed to obtain the value. One can also view the status of the peered connection in the Atlas UI.
            name: '- (Required) Name of the cluster as it appears in Atlas. Once the cluster is created, its name cannot be changed. WARNING Changing the name will result in destruction of the existing cluster and the creation of a new cluster.'
            no_table_scan: '- (Optional) When true, the cluster disables the execution of any query that requires a collection scan to return results. When false, the cluster allows the execution of those operations.'
            oplog_min_retention_hours: '- (Optional) Minimum retention window for cluster''s oplog expressed in hours. A value of null indicates that the cluster uses the default minimum oplog window that MongoDB Cloud calculates.'
            oplog_size_mb: '- (Optional) The custom oplog size of the cluster. Without a value that indicates that the cluster uses the default oplog size calculated by Atlas.'
            paused: |-
                (Optional) - Flag that indicates whether the cluster is paused or not. You can pause M10 or larger clusters.  You cannot initiate pausing for a shared/tenant tier cluster.  See Considerations for Paused Clusters
                NOTE Pause lasts for up to 30 days. If you don't resume the cluster within 30 days, Atlas resumes the cluster.  When the cluster resumption happens Terraform will flag the changed state.  If you wish to keep the cluster paused, reapply your Terraform configuration.   If you prefer to allow the automated change of state to unpaused use:
                lifecycle { ignore_changes = [paused] }
            pit_enabled: '- (Optional) - Flag that indicates if the cluster uses Continuous Cloud Backup.'
            project_id: '- (Required) Unique ID for the project to create the database user.'
            region_configs: objects (your cluster is multi-region or multi-cloud), they must have priorities in descending order. The highest priority is 7.
            region_configs.#.electable_specs.0.node_count: to 1 or higher, it must have a priority of exactly one (1) less than another region in the replication_specs.#.region_configs.# array. The highest-priority region must have a priority of 7. The lowest possible priority is 1.
            region_configs.provider_name: |-
                - (Optional) Cloud service provider on which the servers are provisioned.
                The possible values are:
            region_configs.read_only_specs: '- (Optional) Hardware specifications for read-only nodes in the region. Read-only nodes can become the primary and can enable local reads. If you don''t specify this parameter, no read-only nodes are deployed to the region. See below'
            region_configs.read_only_specs.disk_iops: '- (Optional) Target throughput (IOPS) desired for AWS storage attached to your cluster. Set only if you selected AWS as your cloud service provider. You can''t set this parameter for a multi-cloud cluster.'
            region_configs.read_only_specs.ebs_volume_type: '- (Optional) Type of storage you want to attach to your AWS-provisioned cluster. Set only if you selected AWS as your cloud service provider. You can''t set this parameter for a multi-cloud cluster. Valid values are:'
            region_configs.read_only_specs.instance_size: '- (Optional) Hardware specification for the instance sizes in this region. Each instance size has a default storage and memory capacity. The instance size you select applies to all the data-bearing hosts in your instance size.'
            region_configs.read_only_specs.node_count: '- (Optional) Number of nodes of the given type for MongoDB Atlas to deploy to the region.'
            region_configs.region_name: '- (Optional) Physical location of your MongoDB cluster. The region you choose can affect network latency for clients accessing your databases.  Requires the Atlas region name, see the reference list for AWS, GCP, Azure.'
            replication_specs: '- Configuration for cluster regions and the hardware provisioned in them. See below'
            replication_specs.#.container_id: '- A key-value map of the Network Peering Container ID(s) for the configuration specified in region_configs. The Container ID is the id of the container created when the first cluster in the region (AWS/Azure) or project (GCP) was created.  The syntax is "providerName:regionName" = "containerId". Example AWS:US_EAST_1" = "61e0797dde08fb498ca11a71.'
            replication_specs.num_shards: '- (Required) Provide this value if you set a cluster_type of SHARDED or GEOSHARDED. Omit this value if you selected a cluster_type of REPLICASET. This API resource accepts 1 through 50, inclusive. This parameter defaults to 1. If you specify a num_shards value of 1 and a cluster_type of SHARDED, Atlas deploys a single-shard sharded cluster. Don''t create a sharded cluster with a single shard for production environments. Single-shard sharded clusters don''t provide the same benefits as multi-shard configurations.'
            replication_specs.region_configs: '- (Optional) Configuration for the hardware specifications for nodes set for a given regionEach region_configs object describes the region''s priority in elections and the number and type of MongoDB nodes that Atlas deploys to the region. Each region_configs object must have either an analytics_specs object, electable_specs object, or read_only_specs object. See below'
            replication_specs.region_configs.analytics_auto_scaling: '- (Optional) Configuration for the Collection of settings that configures analytics-auto-scaling information for the cluster. The values for the analytics_auto_scaling parameter must be the same for every item in the replication_specs array. See below'
            replication_specs.region_configs.analytics_auto_scaling.compute_enabled: '- (Optional) Flag that indicates whether instance size auto-scaling is enabled. This parameter defaults to false.'
            replication_specs.region_configs.analytics_auto_scaling.compute_enabled.compute_max_instance_size: '- (Optional) Maximum instance size to which your cluster can automatically scale (such as M40). Atlas requires this parameter if replication_specs.#.region_configs.#.analytics_auto_scaling.0.compute_enabled is true.'
            replication_specs.region_configs.analytics_auto_scaling.compute_enabled.compute_min_instance_size: '- (Optional) Minimum instance size to which your cluster can automatically scale (such as M10). Atlas requires this parameter if replication_specs.#.region_configs.#.analytics_auto_scaling.0.compute_scale_down_enabled is true.'
            replication_specs.region_configs.analytics_auto_scaling.compute_enabled.compute_scale_down_enabled: '- (Optional) Flag that indicates whether the instance size may scale down. Atlas requires this parameter if replication_specs.#.region_configs.#.analytics_auto_scaling.0.compute_enabled : true. If you enable this option, specify a value for replication_specs.#.region_configs.#.analytics_auto_scaling.0.compute_min_instance_size.'
            replication_specs.region_configs.analytics_auto_scaling.disk_gb_enabled: '- (Optional) Flag that indicates whether this cluster enables disk auto-scaling. This parameter defaults to true.'
            replication_specs.region_configs.analytics_specs: '- (Optional) Hardware specifications for analytics nodes needed in the region. Analytics nodes handle analytic data such as reporting queries from BI Connector for Atlas. Analytics nodes are read-only and can never become the primary. If you don''t specify this parameter, no analytics nodes deploy to this region. See below'
            replication_specs.region_configs.analytics_specs.disk_iops: '- (Optional) Target throughput (IOPS) desired for AWS storage attached to your cluster. Set only if you selected AWS as your cloud service provider. You can''t set this parameter for a multi-cloud cluster.'
            replication_specs.region_configs.analytics_specs.ebs_volume_type: '- (Optional) Type of storage you want to attach to your AWS-provisioned cluster. Set only if you selected AWS as your cloud service provider. You can''t set this parameter for a multi-cloud cluster. Valid values are:'
            replication_specs.region_configs.analytics_specs.instance_size: '- (Optional) Hardware specification for the instance sizes in this region. Each instance size has a default storage and memory capacity. The instance size you select applies to all the data-bearing hosts in your instance size.'
            replication_specs.region_configs.analytics_specs.node_count: '- (Optional) Number of nodes of the given type for MongoDB Atlas to deploy to the region.'
            replication_specs.region_configs.auto_scaling: '- (Optional) Configuration for the Collection of settings that configures auto-scaling information for the cluster. The values for the auto_scaling parameter must be the same for every item in the replication_specs array. See below'
            replication_specs.region_configs.auto_scaling.disk_gb_enabled: '- (Optional) Flag that indicates whether this cluster enables disk auto-scaling. This parameter defaults to true.'
            replication_specs.region_configs.auto_scaling.disk_gb_enabled.compute_enabled: '- (Optional) Flag that indicates whether instance size auto-scaling is enabled. This parameter defaults to false.'
            replication_specs.region_configs.auto_scaling.disk_gb_enabled.compute_enabled.compute_max_instance_size: '- (Optional) Maximum instance size to which your cluster can automatically scale (such as M40). Atlas requires this parameter if replication_specs.#.region_configs.#.auto_scaling.0.compute_enabled is true.'
            replication_specs.region_configs.auto_scaling.disk_gb_enabled.compute_enabled.compute_min_instance_size: '- (Optional) Minimum instance size to which your cluster can automatically scale (such as M10). Atlas requires this parameter if replication_specs.#.region_configs.#.auto_scaling.0.compute_scale_down_enabled is true.'
            replication_specs.region_configs.auto_scaling.disk_gb_enabled.compute_enabled.compute_scale_down_enabled: '- (Optional) Flag that indicates whether the instance size may scale down. Atlas requires this parameter if replication_specs.#.region_configs.#.auto_scaling.0.compute_enabled : true. If you enable this option, specify a value for replication_specs.#.region_configs.#.auto_scaling.0.compute_min_instance_size.'
            replication_specs.region_configs.backing_provider_name: '- (Optional) Cloud service provider on which you provision the host for a multi-tenant cluster. Use this only when a provider_name is TENANT and instance_size of a specs is M2 or M5.'
            replication_specs.region_configs.electable_specs: '- (Optional) Hardware specifications for electable nodes in the region. Electable nodes can become the primary and can enable local reads. If you do not specify this option, no electable nodes are deployed to the region. See below'
            replication_specs.region_configs.electable_specs.disk_iops: '- (Optional) Target throughput (IOPS) desired for AWS storage attached to your cluster. Set only if you selected AWS as your cloud service provider. You can''t set this parameter for a multi-cloud cluster.'
            replication_specs.region_configs.electable_specs.ebs_volume_type: '- (Optional) Type of storage you want to attach to your AWS-provisioned cluster. Set only if you selected AWS as your cloud service provider. You can''t set this parameter for a multi-cloud cluster. Valid values are:'
            replication_specs.region_configs.electable_specs.instance_size: '- (Required) Hardware specification for the instance sizes in this region. Each instance size has a default storage and memory capacity. The instance size you select applies to all the data-bearing hosts in your instance size.'
            replication_specs.region_configs.electable_specs.node_count: '- (Optional) Number of nodes of the given type for MongoDB Atlas to deploy to the region.'
            replication_specs.region_configs.priority: '- (Optional)  Election priority of the region. For regions with only read-only nodes, set this value to 0.'
            replication_specs.zone_name: '- (Optional) Name for the zone in a Global Cluster.'
            retain_backups_enabled: '- (Optional) Set to true to retain backup snapshots for the deleted cluster. M10 and above only.'
            root_cert_type: '- (Optional) - Certificate Authority that MongoDB Atlas clusters use. You can specify ISRGROOTX1 (for ISRG Root X1).'
            sample_refresh_interval_bi_connector: '- (Optional) Interval in seconds at which the mongosqld process re-samples data to create its relational schema. The default value is 300. The specified value must be a positive integer. Available only for Atlas deployments in which BI Connector for Atlas is enabled.'
            sample_size_bi_connector: '- (Optional) Number of documents per database to sample when gathering schema information. Defaults to 100. Available only for Atlas deployments in which BI Connector for Atlas is enabled.'
            state_name: '- Current state of the cluster. The possible states are:'
            termination_protection_enabled: '- Flag that indicates whether termination protection is enabled on the cluster. If set to true, MongoDB Cloud won''t delete the cluster. If set to false, MongoDB Cloud will delete the cluster.'
            timeouts: '- (Optional) The duration of time to wait for Cluster to be created, updated, or deleted. The timeout value is defined by a signed sequence of decimal numbers with an time unit suffix such as: 1h45m, 300s, 10m, .... The valid time units are:  ns, us (or µs), ms, s, m, h. The default timeout for Advanced Cluster create & delete is 3h. Learn more about timeouts here.'
            transaction_lifetime_limit_seconds: '- (Optional) Lifetime, in seconds, of multi-document transactions. Defaults to 60 seconds.'
            "true": to enable disk auto-scaling.
            version_release_system: '- (Optional) - Release cadence that Atlas uses for this cluster. This parameter defaults to LTS. If you set this field to CONTINUOUS, you must omit the mongo_db_major_version field. Atlas accepts:'
        importStatements: []
    mongodbatlas_alert_configuration:
        subCategory: ""
        description: Provides an Alert Configuration resource.
        name: mongodbatlas_alert_configuration
        title: alert_configuration
        examples:
            - name: test
              manifest: |-
                {
                  "enabled": true,
                  "event_type": "OUTSIDE_METRIC_THRESHOLD",
                  "matcher": [
                    {
                      "field_name": "HOSTNAME_AND_PORT",
                      "operator": "EQUALS",
                      "value": "SECONDARY"
                    }
                  ],
                  "metric_threshold_config": [
                    {
                      "metric_name": "ASSERT_REGULAR",
                      "mode": "AVERAGE",
                      "operator": "LESS_THAN",
                      "threshold": 99,
                      "units": "RAW"
                    }
                  ],
                  "notification": [
                    {
                      "delay_min": 0,
                      "email_enabled": true,
                      "interval_min": 5,
                      "roles": [
                        "GROUP_CHARTS_ADMIN",
                        "GROUP_CLUSTER_MANAGER"
                      ],
                      "sms_enabled": false,
                      "type_name": "GROUP"
                    }
                  ],
                  "project_id": "\u003cPROJECT-ID\u003e"
                }
            - name: test
              manifest: |-
                {
                  "enabled": true,
                  "event_type": "REPLICATION_OPLOG_WINDOW_RUNNING_OUT",
                  "matcher": [
                    {
                      "field_name": "HOSTNAME_AND_PORT",
                      "operator": "EQUALS",
                      "value": "SECONDARY"
                    }
                  ],
                  "notification": [
                    {
                      "delay_min": 0,
                      "email_enabled": true,
                      "interval_min": 5,
                      "roles": [
                        "GROUP_CHARTS_ADMIN",
                        "GROUP_CLUSTER_MANAGER"
                      ],
                      "sms_enabled": false,
                      "type_name": "GROUP"
                    }
                  ],
                  "project_id": "\u003cPROJECT-ID\u003e",
                  "threshold_config": [
                    {
                      "operator": "LESS_THAN",
                      "threshold": 1,
                      "units": "HOURS"
                    }
                  ]
                }
            - name: test
              manifest: |-
                {
                  "enabled": true,
                  "event_type": "OUTSIDE_METRIC_THRESHOLD",
                  "matcher": [
                    {
                      "field_name": "HOSTNAME_AND_PORT",
                      "operator": "EQUALS",
                      "value": "SECONDARY"
                    }
                  ],
                  "metric_threshold_config": [
                    {
                      "metric_name": "ASSERT_REGULAR",
                      "mode": "AVERAGE",
                      "operator": "LESS_THAN",
                      "threshold": 99,
                      "units": "RAW"
                    }
                  ],
                  "notification": [
                    {
                      "delay_min": 0,
                      "email_enabled": true,
                      "interval_min": 5,
                      "roles": [
                        "GROUP_DATA_ACCESS_READ_ONLY",
                        "GROUP_CLUSTER_MANAGER",
                        "GROUP_DATA_ACCESS_ADMIN"
                      ],
                      "sms_enabled": false,
                      "type_name": "GROUP"
                    },
                    {
                      "delay_min": 0,
                      "email_enabled": false,
                      "interval_min": 5,
                      "sms_enabled": true,
                      "type_name": "ORG"
                    }
                  ],
                  "project_id": "PROJECT ID"
                }
        argumentDocs:
            GROUP: (Project)
            GROUP_CHARTS_ADMIN: |-
                | ORG_OWNER         |
                | GROUP_CLUSTER_MANAGER         | ORG_MEMBER        |
                | GROUP_DATA_ACCESS_ADMIN       | ORG_GROUP_CREATOR |
                | GROUP_DATA_ACCESS_READ_ONLY   | ORG_BILLING_ADMIN |
                | GROUP_DATA_ACCESS_READ_WRITE  | ORG_READ_ONLY     |
                | GROUP_OWNER                   |                     |
                | GROUP_READ_ONLY               |                     |
            alert_configuration_id: '- Unique identifier for the alert configuration.'
            api_token: '- Slack API token. Required for the SLACK notifications type. If the token later becomes invalid, Atlas sends an email to the project owner and eventually removes the token.'
            channel_name: '- Slack channel name. Required for the SLACK notifications type.'
            created: '- Timestamp in ISO 8601 date and time format in UTC when this alert configuration was created.'
            datadog_api_key: '- Datadog API Key. Found in the Datadog dashboard. Required for the DATADOG notifications type.'
            datadog_region: '- Region that indicates which API URL to use. Accepted regions are: US, EU. The default Datadog region is US.'
            delay_min: '- Number of minutes to wait after an alert condition is detected before sending out the first notification.'
            email_address: '- Email address to which alert notifications are sent. Required for the EMAIL notifications type.'
            email_enabled: '- Flag indicating email notifications should be sent. This flag is only valid if type_name is set to ORG, GROUP, or USER.'
            enabled: '- It is not required, but If the attribute is omitted, by default will be false, and the configuration would be disabled. You must set true to enable the configuration.'
            event_type: '- (Required) The type of event that will trigger an alert.'
            field_name: '- Name of the field in the target object to match on.'
            flow_name: '- Flowdock flow name in lower-case letters. Required for the FLOWDOCK notifications type'
            flowdock_api_token: '- The Flowdock personal API token. Required for the FLOWDOCK notifications type. If the token later becomes invalid, Atlas sends an email to the project owner and eventually removes the token.'
            group_id: '- Unique identifier of the project that owns this alert configuration.'
            id: '- Unique identifier used for terraform for internal manages and can be used to import.'
            interval_min: '- Number of minutes to wait between successive notifications for unacknowledged alerts that are not resolved. The minimum value is 5. NOTE PAGER_DUTY, VICTOR_OPS, and OPS_GENIE notifications do not return this value. The notification interval must be configured and managed within each external service.'
            metric_name: '- Name of the metric to check. The full list being quite large, please refer to atlas docs here for general metrics and here for serverless metrics'
            microsoft_teams_webhook_url: '- Microsoft Teams Webhook Uniform Resource Locator (URL) that MongoDB Cloud needs to send this notification via Microsoft Teams. Required if type_name is MICROSOFT_TEAMS. If the URL later becomes invalid, MongoDB Cloud sends an email to the project owners. If the key remains invalid, MongoDB Cloud removes it.'
            mobile_number: '- Mobile number to which alert notifications are sent. Required for the SMS notifications type.'
            mode: '- This must be set to AVERAGE. Atlas computes the current metric value as an average.'
            operator: '- If omitted, the configuration is disabled.'
            ops_genie_api_key: '- Opsgenie API Key. Required for the OPS_GENIE notifications type. If the key later becomes invalid, Atlas sends an email to the project owner and eventually removes the token.'
            ops_genie_region: '- Region that indicates which API URL to use. Accepted regions are: US ,EU. The default Opsgenie region is US.'
            org_name: '- Flowdock organization name in lower-case letters. This is the name that appears after www.flowdock.com/app/ in the URL string. Required for the FLOWDOCK notifications type.'
            project_id: '- (Required) The ID of the project where the alert configuration will create.'
            roles: |-
                - Optional. One or more roles that receive the configured alert. If you include this field, Atlas sends alerts only to users assigned the roles you specify in the array. If you omit this field, Atlas sends alerts to users assigned any role. This parameter is only valid if type_name is set to ORG, GROUP, or USER.
                Accepted values are:
            service_key: '- PagerDuty service key. Required for the PAGER_DUTY notifications type. If the key later becomes invalid, Atlas sends an email to the project owner and eventually removes the key.'
            sms_enabled: '- Flag indicating if text message notifications should be sent to this user''s mobile phone. This flag is only valid if type_name is set to ORG, GROUP, or USER.'
            team_id: '- Unique identifier of a team.'
            team_name: '- Label for the team that receives this notification.'
            threshold: '- Threshold value outside of which an alert will be triggered.'
            type_name: |-
                - Type of alert notification.
                Accepted values are:
            units: |-
                - The units for the threshold value. Depends on the type of metric.
                Refer to the MongoDB API Alert Configuration documentation for a list of accepted values.
            updated: '- Timestamp in ISO 8601 date and time format in UTC when this alert configuration was last updated.'
            username: '- Name of the Atlas user to which to send notifications. Only a user in the project that owns the alert configuration is allowed here. Required for the USER notifications type.'
            value: '- If omitted, the configuration is disabled.'
            victor_ops_api_key: '- VictorOps API key. Required for the VICTOR_OPS notifications type. If the key later becomes invalid, Atlas sends an email to the project owner and eventually removes the key.'
            victor_ops_routing_key: '- VictorOps routing key. Optional for the VICTOR_OPS notifications type. If the key later becomes invalid, Atlas sends an email to the project owner and eventually removes the key.'
            webhook_secret: '- Optional authentication secret for the WEBHOOK notifications type.'
            webhook_url: '- Target URL  for the WEBHOOK notifications type.'
        importStatements: []
    mongodbatlas_api_key:
        subCategory: ""
        description: Provides a API Key resource.
        name: mongodbatlas_api_key
        title: api_key
        examples:
            - name: test
              manifest: |-
                {
                  "description": "key-name",
                  "org_id": "\u003cORG_ID\u003e",
                  "role_names": [
                    "ORG_READ_ONLY"
                  ]
                }
        argumentDocs:
            api_key_id: '- Unique identifier for this Organization API key.'
            description: '- Description of this Organization API key.'
            org_id: '- Unique identifier for the organization whose API keys you want to retrieve. Use the /orgs endpoint to retrieve all organizations to which the authenticated user has access.'
            role_names: |-
                - Name of the role. This resource returns all the roles the user has in Atlas.
                The following are valid roles:
        importStatements: []
    mongodbatlas_auditing:
        subCategory: ""
        description: Provides a Auditing resource.
        name: mongodbatlas_auditing
        title: auditing
        examples:
            - name: test
              manifest: |-
                {
                  "audit_authorization_success": false,
                  "audit_filter": "{ 'atype': 'authenticate', 'param': {   'user': 'auditAdmin',   'db': 'admin',   'mechanism': 'SCRAM-SHA-1' }}",
                  "enabled": true,
                  "project_id": "\u003cproject-id\u003e"
                }
        argumentDocs:
            audit_authorization_success: '- Indicates whether the auditing system captures successful authentication attempts for audit filters using the "atype" : "authCheck" auditing event. For more information, see auditAuthorizationSuccess.  Warning! Enabling Audit authorization successes can severely impact cluster performance. Enable this option with caution.'
            audit_filter: '- JSON-formatted audit filter. For complete documentation on custom auditing filters, see Configure Audit Filters.'
            configuration_type: '- Denotes the configuration method for the audit filter. Possible values are:'
            enabled: '- Denotes whether or not the project associated with the {project_id} has database auditing enabled.  Defaults to false.'
            project_id: '- (Required) The unique ID for the project to configure auditing. Note: When changing this value to a different project_id it will delete the current audit settings for the original project that was assigned to.'
        importStatements: []
    mongodbatlas_backup_compliance_policy:
        subCategory: ""
        description: Provides a Backup Compliance Policy resource.
        name: mongodbatlas_backup_compliance_policy
        title: backup_compliance_policy
        examples:
            - name: backup_policy
              manifest: |-
                {
                  "authorized_email": "user@email.com",
                  "copy_protection_enabled": false,
                  "encryption_at_rest_enabled": false,
                  "on_demand_policy_item": [
                    {
                      "frequency_interval": 1,
                      "retention_unit": "days",
                      "retention_value": 3
                    }
                  ],
                  "pit_enabled": false,
                  "policy_item_daily": [
                    {
                      "frequency_interval": 1,
                      "retention_unit": "days",
                      "retention_value": 7
                    }
                  ],
                  "policy_item_hourly": [
                    {
                      "frequency_interval": 1,
                      "retention_unit": "days",
                      "retention_value": 7
                    }
                  ],
                  "policy_item_monthly": [
                    {
                      "frequency_interval": 1,
                      "retention_unit": "months",
                      "retention_value": 12
                    }
                  ],
                  "policy_item_weekly": [
                    {
                      "frequency_interval": 1,
                      "retention_unit": "weeks",
                      "retention_value": 4
                    }
                  ],
                  "project_id": "\u003cPROJECT-ID\u003e",
                  "restore_window_days": 7
                }
              dependencies:
                mongodbatlas_cloud_backup_schedule.test: |-
                    {
                      "cluster_name": "${mongodbatlas_cluster.my_cluster.name}",
                      "policy_item_daily": [
                        {
                          "frequency_interval": 1,
                          "retention_unit": "days",
                          "retention_value": 7
                        }
                      ],
                      "policy_item_hourly": [
                        {
                          "frequency_interval": 1,
                          "retention_unit": "days",
                          "retention_value": 7
                        }
                      ],
                      "policy_item_monthly": [
                        {
                          "frequency_interval": 1,
                          "retention_unit": "months",
                          "retention_value": 12
                        }
                      ],
                      "policy_item_weekly": [
                        {
                          "frequency_interval": 1,
                          "retention_unit": "weeks",
                          "retention_value": 4
                        }
                      ],
                      "project_id": "${mongodbatlas_cluster.my_cluster.project_id}",
                      "reference_hour_of_day": 3,
                      "reference_minute_of_hour": 45,
                      "restore_window_days": 4
                    }
                mongodbatlas_cluster.my_cluster: |-
                    {
                      "cloud_backup": true,
                      "name": "clusterTest",
                      "project_id": "\u003cPROJECT-ID\u003e",
                      "provider_instance_size_name": "M10",
                      "provider_name": "AWS",
                      "provider_region_name": "EU_CENTRAL_1"
                    }
        argumentDocs:
            "1": through 28 where the number represents the day of the month (i.e. 1 is the first of the month and 5 is the fifth day of the month).
            "40": represents the last day of the month (depending on the month).
            authorized_email: '- Email address of a security or legal representative for the Backup Compliance Policy who is authorized to update the Backup Compliance Policy settings.'
            copy_protection_enabled: '- Flag that indicates whether to enable additional backup copies for the cluster. If unspecified, this value defaults to false.'
            encryption_at_rest_enabled: '- Flag that indicates whether Encryption at Rest using Customer Key Management is required for all clusters with a Backup Compliance Policy. If unspecified, this value defaults to false.'
            frequency_interval: '- Desired frequency of the new backup policy item specified by frequency_type (hourly in this case). The supported values for hourly policies are 1, 2, 4, 6, 8 or 12 hours. Note that 12 hours is the only accepted value for NVMe clusters.'
            frequency_type: '- Frequency associated with the backup policy item. For hourly policies, the frequency type is defined as ondemand. Note that this is a read-only value and not required in plan files - its value is implied from the policy resource type.'
            id: '- Unique identifier of the backup policy item.'
            pit_enabled: '- Flag that indicates whether the cluster uses Continuous Cloud Backups with a Backup Compliance Policy. If unspecified, this value defaults to false.'
            project_id: '- (Required) Unique 24-hexadecimal digit string that identifies your project.'
            restore_window_days: '- Number of previous days that you can restore back to with Continuous Cloud Backup with a Backup Compliance Policy. You must specify a positive, non-zero integer, and the maximum retention window can''t exceed the hourly retention time. This parameter applies only to Continuous Cloud Backups with a Backup Compliance Policy.'
            retention_unit: '- Scope of the backup policy item: days, weeks, or months.'
            retention_value: '- Value to associate with retention_unit.'
            state: '- Label that indicates the state of the Backup Compliance Policy settings. MongoDB Cloud ignores this setting when you enable or update the Backup Compliance Policy settings.'
            updated_date: '- ISO 8601 timestamp format in UTC that indicates when the user updated the Data Protection Policy settings. MongoDB Cloud ignores this setting when you enable or update the Backup Compliance Policy settings.'
            updated_user: '- Email address that identifies the user who updated the Backup Compliance Policy settings. MongoDB Cloud ignores this email setting when you enable or update the Backup Compliance Policy settings.'
        importStatements: []
    mongodbatlas_cloud_backup_schedule:
        subCategory: ""
        description: Provides a Cloud Backup Schedule resource.
        name: mongodbatlas_cloud_backup_schedule
        title: cloud_backup_schedule
        examples:
            - name: test
              manifest: |-
                {
                  "cluster_name": "${mongodbatlas_cluster.my_cluster.name}",
                  "policy_item_daily": [
                    {
                      "frequency_interval": 1,
                      "retention_unit": "days",
                      "retention_value": 2
                    }
                  ],
                  "policy_item_hourly": [
                    {
                      "frequency_interval": 1,
                      "retention_unit": "days",
                      "retention_value": 1
                    }
                  ],
                  "project_id": "${mongodbatlas_cluster.my_cluster.project_id}",
                  "reference_hour_of_day": 3,
                  "reference_minute_of_hour": 45,
                  "restore_window_days": 4
                }
              references:
                cluster_name: mongodbatlas_cluster.my_cluster.name
                project_id: mongodbatlas_cluster.my_cluster.project_id
              dependencies:
                mongodbatlas_cluster.my_cluster: |-
                    {
                      "cloud_backup": true,
                      "name": "clusterTest",
                      "project_id": "\u003cPROJECT-ID\u003e",
                      "provider_instance_size_name": "M10",
                      "provider_name": "AWS",
                      "provider_region_name": "EU_CENTRAL_1"
                    }
            - name: test
              manifest: |-
                {
                  "cluster_name": "${mongodbatlas_cluster.my_cluster.name}",
                  "project_id": "${mongodbatlas_cluster.my_cluster.project_id}",
                  "reference_hour_of_day": 3,
                  "reference_minute_of_hour": 45,
                  "restore_window_days": 4
                }
              references:
                cluster_name: mongodbatlas_cluster.my_cluster.name
                project_id: mongodbatlas_cluster.my_cluster.project_id
              dependencies:
                mongodbatlas_cluster.my_cluster: |-
                    {
                      "cloud_backup": true,
                      "name": "clusterTest",
                      "project_id": "\u003cPROJECT-ID\u003e",
                      "provider_instance_size_name": "M10",
                      "provider_name": "AWS",
                      "provider_region_name": "EU_CENTRAL_1"
                    }
            - name: test
              manifest: |-
                {
                  "cluster_name": "${mongodbatlas_cluster.my_cluster.name}",
                  "policy_item_daily": [
                    {
                      "frequency_interval": 1,
                      "retention_unit": "days",
                      "retention_value": 2
                    }
                  ],
                  "policy_item_hourly": [
                    {
                      "frequency_interval": 1,
                      "retention_unit": "days",
                      "retention_value": 1
                    }
                  ],
                  "policy_item_monthly": [
                    {
                      "frequency_interval": 5,
                      "retention_unit": "months",
                      "retention_value": 4
                    }
                  ],
                  "policy_item_weekly": [
                    {
                      "frequency_interval": 4,
                      "retention_unit": "weeks",
                      "retention_value": 3
                    }
                  ],
                  "project_id": "${mongodbatlas_cluster.my_cluster.project_id}",
                  "reference_hour_of_day": 3,
                  "reference_minute_of_hour": 45,
                  "restore_window_days": 4
                }
              references:
                cluster_name: mongodbatlas_cluster.my_cluster.name
                project_id: mongodbatlas_cluster.my_cluster.project_id
              dependencies:
                mongodbatlas_cluster.my_cluster: |-
                    {
                      "cloud_backup": true,
                      "name": "clusterTest",
                      "project_id": "\u003cPROJECT-ID\u003e",
                      "provider_instance_size_name": "M10",
                      "provider_name": "AWS",
                      "provider_region_name": "EU_CENTRAL_1"
                    }
            - name: test
              manifest: |-
                {
                  "cluster_name": "${mongodbatlas_cluster.my_cluster.name}",
                  "copy_settings": [
                    {
                      "cloud_provider": "AWS",
                      "frequencies": [
                        "HOURLY",
                        "DAILY",
                        "WEEKLY",
                        "MONTHLY",
                        "ON_DEMAND"
                      ],
                      "region_name": "US_EAST_1",
                      "replication_spec_id": "${mongodbatlas_cluster.my_cluster.replication_specs.*.id[0]}",
                      "should_copy_oplogs": false
                    }
                  ],
                  "policy_item_daily": [
                    {
                      "frequency_interval": 1,
                      "retention_unit": "days",
                      "retention_value": 14
                    }
                  ],
                  "project_id": "${mongodbatlas_cluster.my_cluster.project_id}",
                  "reference_hour_of_day": 3,
                  "reference_minute_of_hour": 45,
                  "restore_window_days": 4
                }
              references:
                cluster_name: mongodbatlas_cluster.my_cluster.name
                project_id: mongodbatlas_cluster.my_cluster.project_id
              dependencies:
                mongodbatlas_cluster.my_cluster: |-
                    {
                      "cloud_backup": true,
                      "name": "clusterTest",
                      "project_id": "\u003cPROJECT-ID\u003e",
                      "provider_instance_size_name": "M10",
                      "provider_name": "AWS",
                      "provider_region_name": "US_EAST_2"
                    }
        argumentDocs:
            "1": through 28 where the number represents the day of the month i.e. 1 is the first of the month and 5 is the fifth day of the month.
            "40": represents the last day of the month (depending on the month).
            auto_export_enabled: '- Flag that indicates whether automatic export of cloud backup snapshots to the AWS bucket is enabled. Value can be one of the following:'
            cloud_provider: '- (Required) Human-readable label that identifies the cloud provider that stores the snapshot copy. i.e. "AWS" "AZURE" "GCP"'
            cluster_id: '- Unique identifier of the Atlas cluster.'
            cluster_name: '- (Required) The name of the Atlas cluster that contains the snapshot backup policy you want to retrieve.'
            export_bucket_id: '- Unique identifier of the mongodbatlas_cloud_backup_snapshot_export_bucket export_bucket_id value.'
            frequencies: '- (Required) List that describes which types of snapshots to copy. i.e. "HOURLY" "DAILY" "WEEKLY" "MONTHLY" "ON_DEMAND"'
            frequency_interval: '- Desired frequency of the new backup policy item specified by frequency_type (hourly in this case). The supported values for hourly policies are 1, 2, 4, 6, 8 or 12 hours. Note that 12 hours is the only accepted value for NVMe clusters.'
            frequency_type: '- Frequency associated with the export snapshot item.'
            id: '- Unique identifier of the backup policy item.'
            id_policy: '- Unique identifier of the backup policy.'
            next_snapshot: '- Timestamp in the number of seconds that have elapsed since the UNIX epoch when Atlas takes the next snapshot.'
            policy_item_daily: '- (Optional) Daily policy item'
            policy_item_hourly: '- (Optional) Hourly policy item'
            policy_item_monthly: '- (Optional) Monthly policy item'
            policy_item_weekly: '- (Optional) Weekly policy item'
            project_id: '- (Required) The unique identifier of the project for the Atlas cluster.'
            reference_hour_of_day: '- (Optional) UTC Hour of day between 0 and 23, inclusive, representing which hour of the day that Atlas takes snapshots for backup policy items.'
            reference_minute_of_hour: '- (Optional) UTC Minutes after reference_hour_of_day that Atlas takes snapshots for backup policy items. Must be between 0 and 59, inclusive.'
            region_name: '- (Required) Target region to copy snapshots belonging to replicationSpecId to. Please supply the ''Atlas Region'' which can be found under https://www.mongodb.com/docs/atlas/reference/cloud-providers/ ''regions'' link'
            replication_spec_id: -(Required) Unique 24-hexadecimal digit string that identifies the replication object for a zone in a cluster. For global clusters, there can be multiple zones to choose from. For sharded clusters and replica set clusters, there is only one zone in the cluster. To find the Replication Spec Id, consult the replicationSpecs array returned from Return One Multi-Cloud Cluster in One Project.
            restore_window_days: '- (Optional) Number of days back in time you can restore to with point-in-time accuracy. Must be a positive, non-zero integer.'
            retention_unit: '- Scope of the backup policy item: days, weeks, or months.'
            retention_value: '- Value to associate with retention_unit.'
            should_copy_oplogs: '- (Required) Flag that indicates whether to copy the oplogs to the target region. You can use the oplogs to perform point-in-time restores.'
            update_snapshots: '- (Optional) Specify true to apply the retention changes in the updated backup policy to snapshots that Atlas took previously.'
            use_org_and_group_names_in_export_prefix: '- Specify true to use organization and project names instead of organization and project UUIDs in the path for the metadata files that Atlas uploads to your S3 bucket after it finishes exporting the snapshots. To learn more about the metadata files that Atlas uploads, see Export Cloud Backup Snapshot.'
        importStatements: []
    mongodbatlas_cloud_backup_snapshot:
        subCategory: ""
        description: Provides a Cloud Backup Snapshot resource.
        name: mongodbatlas_cloud_backup_snapshot
        title: cloud_backup_snapshot
        examples:
            - name: test
              manifest: |-
                {
                  "cluster_name": "${mongodbatlas_cluster.my_cluster.name}",
                  "description": "myDescription",
                  "project_id": "${mongodbatlas_cluster.my_cluster.project_id}",
                  "retention_in_days": 1
                }
              references:
                cluster_name: mongodbatlas_cluster.my_cluster.name
                project_id: mongodbatlas_cluster.my_cluster.project_id
              dependencies:
                mongodbatlas_cloud_backup_snapshot_restore_job.test: |-
                    {
                      "cluster_name": "${mongodbatlas_cloud_backup_snapshot.test.cluster_name}",
                      "delivery_type": [
                        {
                          "download": true
                        }
                      ],
                      "project_id": "${mongodbatlas_cloud_backup_snapshot.test.project_id}",
                      "snapshot_id": "${mongodbatlas_cloud_backup_snapshot.test.snapshot_id}"
                    }
                mongodbatlas_cluster.my_cluster: |-
                    {
                      "cloud_backup": true,
                      "name": "MyCluster",
                      "project_id": "5cf5a45a9ccf6400e60981b6",
                      "provider_instance_size_name": "M10",
                      "provider_name": "AWS",
                      "provider_region_name": "EU_WEST_2"
                    }
        argumentDocs:
            cloud_provider: '- Cloud provider that stores this snapshot. Atlas returns this parameter when type is replicaSet.'
            cluster_name: '- (Required) The name of the Atlas cluster that contains the snapshots you want to retrieve.'
            created_at: '- UTC ISO 8601 formatted point in time when Atlas took the snapshot.'
            description: '- (Required) Description of the on-demand snapshot.'
            expires_at: '- UTC ISO 8601 formatted point in time when Atlas will delete the snapshot.'
            id: "-\tUnique identifier used for terraform for internal manages."
            master_key_uuid: '- Unique ID of the AWS KMS Customer Master Key used to encrypt the snapshot. Only visible for clusters using Encryption at Rest via Customer KMS.'
            members: '- Block of List of snapshots and the cloud provider where the snapshots are stored. Atlas returns this parameter when type is shardedCluster. See below'
            members.cloud_provider: '- Cloud provider that stores this snapshot.'
            members.id: '- Unique identifier for the sharded cluster snapshot.'
            members.replica_set_name: '- Label given to a shard or config server from which Atlas took this snapshot.'
            mongod_version: '- Version of the MongoDB server.'
            project_id: '- (Required) The unique identifier of the project for the Atlas cluster.'
            replica_set_name: '- Label given to the replica set from which Atlas took this snapshot. Atlas returns this parameter when type is replicaSet.'
            retention_in_days: '- (Required) The number of days that Atlas should retain the on-demand snapshot. Must be at least 1.'
            snapshot_id: '- Unique identifier of the snapshot.'
            snapshot_ids: '- Unique identifiers of the snapshots created for the shards and config server for a sharded cluster. Atlas returns this parameter when type is shardedCluster. These identifiers should match those given in the members[n].id parameters. This allows you to map a snapshot to its shard or config server name.'
            snapshot_type: '- Specified the type of snapshot. Valid values are onDemand and scheduled.'
            status: '- Current status of the snapshot. One of the following values will be returned: queued, inProgress, completed, failed.'
            storage_size_bytes: '- Specifies the size of the snapshot in bytes.'
            type: '- Specifies the type of cluster: replicaSet or shardedCluster.'
        importStatements: []
    mongodbatlas_cloud_backup_snapshot_export_bucket:
        subCategory: ""
        description: Provides a Cloud Backup Snapshot Export Bucket resource.
        name: mongodbatlas_cloud_backup_snapshot_export_bucket
        title: cloud_backup_snapshot_export_bucket
        examples:
            - name: test
              manifest: |-
                {
                  "bucket_name": "example-bucket",
                  "cloud_provider": "AWS",
                  "iam_role_id": "{IAM_ROLE_ID}",
                  "project_id": "{PROJECT_ID}"
                }
        argumentDocs:
            bucket_name: '- (Required) Name of the bucket that the provided role ID is authorized to access. You must also specify the iam_role_id.'
            cloud_provider: '- (Required) Name of the provider of the cloud service where Atlas can access the S3 bucket. Atlas only supports AWS.'
            export_bucket_id: "-\tUnique identifier of the snapshot export bucket."
            iam_role_id: '- (Required) Unique identifier of the role that Atlas can use to access the bucket. You must also specify the bucket_name.'
            project_id: '- (Required) The unique identifier of the project for the Atlas cluster.'
        importStatements: []
    mongodbatlas_cloud_backup_snapshot_export_job:
        subCategory: ""
        description: Provides a Cloud Backup Snapshot Export Job resource.
        name: mongodbatlas_cloud_backup_snapshot_export_job
        title: cloud_backup_snapshot_export_job
        examples:
            - name: test
              manifest: |-
                {
                  "cluster_name": "{CLUSTER_NAME}",
                  "custom_data": [
                    {
                      "key": "exported by",
                      "value": "myName"
                    }
                  ],
                  "export_bucket_id": "${mongodbatlas_cloud_backup_snapshot_export_bucket.test.export_bucket_id}",
                  "project_id": "{PROJECT_ID}",
                  "snapshot_id": "{SNAPSHOT_ID}"
                }
              references:
                export_bucket_id: mongodbatlas_cloud_backup_snapshot_export_bucket.test.export_bucket_id
              dependencies:
                mongodbatlas_cloud_backup_snapshot_export_bucket.test: |-
                    {
                      "bucket_name": "example_bucket",
                      "cloud_provider": "AWS",
                      "iam_role_id": "{IAM_ROLE_ID}",
                      "project_id": "{PROJECT_ID}"
                    }
        argumentDocs:
            Failed: '- indicates that the export job has failed'
            InProgress: '- indicates that the snapshot is being exported'
            Queued: '- indicates that the export job is queued'
            Successful: '- indicates that the export job has completed successfully'
            cluster_name: '- (Required) Name of the Atlas cluster whose snapshot you want to export.'
            components: '- Returned for sharded clusters only. Export job details for each replica set in the sharded cluster.'
            components.export_id: '- Returned for sharded clusters only. Export job details for each replica set in the sharded cluster.'
            components.replica_set_name: '- Returned for sharded clusters only. Unique identifier of the export job for the replica set.'
            created_at: '- Timestamp in ISO 8601 date and time format in UTC when the export job was created.'
            custom_data: '- (Optional) Custom data to include in the metadata file named .complete that Atlas uploads to the bucket when the export job finishes. Custom data can be specified as key and value pairs.'
            err_msg: '- Error message, only if the export job failed.'
            export_bucket_id: '- (Required) Unique identifier of the AWS bucket to export the Cloud Backup snapshot to. If necessary, use the Get All Snapshot Export Buckets API to retrieve the IDs of all available export buckets for a project or use the data source mongodbatlas_cloud_backup_snapshot_export_buckets'
            export_job_id: '- Unique identifier of the export job.'
            export_status: '- Returned for replica set only. Status of the export job.'
            export_status.exported_collections: '- Returned for replica set only. Number of collections that have been exported.'
            export_status.total_collections: '- Returned for replica set only. Total number of collections to export.'
            finished_at: '- Timestamp in ISO 8601 date and time format in UTC when the export job completes.'
            key: '- (Required) Required if you want to include custom data using custom_data in the metadata file uploaded to the bucket. Key to include in the metadata file that Atlas uploads to the bucket when the export job finishes.'
            'prefix ': '- Full path on the cloud provider bucket to the folder where the snapshot is exported. The path is in the following format:/exported_snapshots/{ORG-NAME}/{PROJECT-NAME}/{CLUSTER-NAME}/{SNAPSHOT-INITIATION-DATE}/{TIMESTAMP}'
            project_id: '- (Required) Unique 24-hexadecimal digit string that identifies the project which contains the Atlas cluster whose snapshot you want to export.'
            snapshot_id: '- (Required) Unique identifier of the Cloud Backup snapshot to export. If necessary, use the Get All Cloud Backups API to retrieve the list of snapshot IDs for a cluster or use the data source mongodbatlas_cloud_cloud_backup_snapshots'
            state: '- Status of the export job. Value can be one of the following:'
            value: '- (Required) Required if you specify key.'
        importStatements: []
    mongodbatlas_cloud_backup_snapshot_restore_job:
        subCategory: ""
        description: Provides a Cloud Backup Snapshot Restore Job resource.
        name: mongodbatlas_cloud_backup_snapshot_restore_job
        title: cloud_backup_snapshot_restore_job
        examples:
            - name: test
              manifest: |-
                {
                  "cluster_name": "${mongodbatlas_cloud_provider_snapshot.test.cluster_name}",
                  "delivery_type_config": [
                    {
                      "automated": true,
                      "target_cluster_name": "MyCluster",
                      "target_project_id": "5cf5a45a9ccf6400e60981b6"
                    }
                  ],
                  "project_id": "${mongodbatlas_cloud_provider_snapshot.test.project_id}",
                  "snapshot_id": "${mongodbatlas_cloud_provider_snapshot.test.snapshot_id}"
                }
              references:
                cluster_name: mongodbatlas_cloud_provider_snapshot.test.cluster_name
                project_id: mongodbatlas_cloud_provider_snapshot.test.project_id
                snapshot_id: mongodbatlas_cloud_provider_snapshot.test.snapshot_id
              dependencies:
                mongodbatlas_cloud_provider_snapshot.test: |-
                    {
                      "cluster_name": "${mongodbatlas_cluster.my_cluster.name}",
                      "description": "myDescription",
                      "project_id": "${mongodbatlas_cluster.my_cluster.project_id}",
                      "retention_in_days": 1
                    }
                mongodbatlas_cluster.my_cluster: |-
                    {
                      "cloud_backup": true,
                      "name": "MyCluster",
                      "project_id": "5cf5a45a9ccf6400e60981b6",
                      "provider_instance_size_name": "M10",
                      "provider_name": "AWS",
                      "provider_region_name": "EU_WEST_2"
                    }
            - name: test
              manifest: |-
                {
                  "cluster_name": "${mongodbatlas_cloud_provider_snapshot.test.cluster_name}",
                  "delivery_type_config": [
                    {
                      "download": true
                    }
                  ],
                  "project_id": "${mongodbatlas_cloud_provider_snapshot.test.project_id}",
                  "snapshot_id": "${mongodbatlas_cloud_provider_snapshot.test.snapshot_id}"
                }
              references:
                cluster_name: mongodbatlas_cloud_provider_snapshot.test.cluster_name
                project_id: mongodbatlas_cloud_provider_snapshot.test.project_id
                snapshot_id: mongodbatlas_cloud_provider_snapshot.test.snapshot_id
              dependencies:
                mongodbatlas_cloud_provider_snapshot.test: |-
                    {
                      "cluster_name": "${mongodbatlas_cluster.my_cluster.name}",
                      "description": "myDescription",
                      "project_id": "${mongodbatlas_cluster.my_cluster.project_id}",
                      "retention_in_days": 1
                    }
                mongodbatlas_cluster.my_cluster: |-
                    {
                      "cloud_backup": true,
                      "name": "MyCluster",
                      "project_id": "5cf5a45a9ccf6400e60981b6",
                      "provider_instance_size_name": "M10",
                      "provider_name": "AWS",
                      "provider_region_name": "EU_WEST_2"
                    }
        argumentDocs:
            cancelled: "-\tIndicates whether the restore job was canceled."
            cluster_name: '- (Required) The name of the Atlas cluster whose snapshot you want to restore.'
            created_at: "-\tUTC ISO 8601 formatted point in time when Atlas created the restore job."
            delivery_type_config: '- (Required) Type of restore job to create. Possible configurations are: download, automated, or pointInTime only one must be set it in true.'
            delivery_type_config.automated: '- Set to true to use the automated configuration.'
            delivery_type_config.download: '- Set to true to use the download configuration.'
            delivery_type_config.oplog_inc: '- Optional setting for pointInTime configuration. Oplog operation number from which to you want to restore this snapshot. This is the second part of an Oplog timestamp. Used in conjunction with oplog_ts.'
            delivery_type_config.oplog_ts: '- Optional setting for pointInTime configuration. Timestamp in the number of seconds that have elapsed since the UNIX epoch from which to you want to restore this snapshot. This is the first part of an Oplog timestamp.'
            delivery_type_config.point_in_time_utc_seconds: '- Optional setting for pointInTime configuration. Timestamp in the number of seconds that have elapsed since the UNIX epoch from which you want to restore this snapshot. Used instead of oplog settings.'
            delivery_type_config.pointInTime: '- Set to true to use the pointInTime configuration. If using pointInTime configuration, you must also specify either oplog_ts and oplog_inc, or point_in_time_utc_seconds.'
            delivery_type_config.target_cluster_name: '- Name of the target Atlas cluster to which the restore job restores the snapshot. Required for automated and pointInTime.'
            delivery_type_config.target_project_id: '- Name of the target Atlas cluster to which the restore job restores the snapshot. Required for automated and pointInTime.'
            delivery_url: "-\tOne or more URLs for the compressed snapshot files for manual download. Only visible if deliveryType is download."
            expired: "-\tIndicates whether the restore job expired."
            expires_at: "-\tUTC ISO 8601 formatted point in time when the restore job expires."
            finished_at: "-\tUTC ISO 8601 formatted point in time when the restore job completed."
            id: "-\tThe Terraform's unique identifier used internally for state management."
            links: "-\tOne or more links to sub-resources and/or related resources. The relations between URLs are explained in the Web Linking Specification."
            oplogInc: |-
                - Oplog operation number from which to you want to restore this snapshot. This is the second part of an Oplog timestamp.
                Three conditions apply to this parameter:
            oplogTs: |-
                - Timestamp in the number of seconds that have elapsed since the UNIX epoch from which to you want to restore this snapshot.
                Three conditions apply to this parameter:
            pointInTimeUTCSeconds: |-
                - Timestamp in the number of seconds that have elapsed since the UNIX epoch from which you want to restore this snapshot.
                Two conditions apply to this parameter:
            project_id: '- (Required) The unique identifier of the project for the Atlas cluster whose snapshot you want to restore.'
            snapshot_id: '- (Required) Unique identifier of the snapshot to restore.'
            snapshot_restore_job_id: '- The unique identifier of the restore job.'
            target_cluster_name: "-\tName of the target Atlas cluster to which the restore job restores the snapshot. Only visible if deliveryType is automated."
            target_project_id: "-\tName of the target Atlas project of the restore job. Only visible if deliveryType is automated."
            timestamp: '- Timestamp in ISO 8601 date and time format in UTC when the snapshot associated to snapshotId was taken.'
        importStatements: []
    mongodbatlas_cloud_provider_access_setup:
        subCategory: ""
        description: Provides a Cloud Provider Access settings resource for registration, authorization, and deauthorization
        name: mongodbatlas_cloud_provider_access_setup
        title: mongodbatlas_cloud_provider_access
        examples:
            - name: test_role
              manifest: |-
                {
                  "project_id": "64259ee860c43338194b0f8e",
                  "provider_name": "AWS"
                }
            - name: test_role
              manifest: |-
                {
                  "azure_config": [
                    {
                      "atlas_azure_app_id": "9f2deb0d-be22-4524-a403-df531868bac0",
                      "service_principal_id": "22f1d2a6-d0e9-482a-83a4-b8dd7dddc2c1",
                      "tenant_id": "91402384-d71e-22f5-22dd-759e272cdc1c"
                    }
                  ],
                  "project_id": "64259ee860c43338194b0f8e",
                  "provider_name": "AZURE"
                }
            - name: setup_only
              manifest: |-
                {
                  "project_id": "64259ee860c43338194b0f8e",
                  "provider_name": "AWS"
                }
              dependencies:
                mongodbatlas_cloud_provider_access_authorization.auth_role: |-
                    {
                      "aws": [
                        {
                          "iam_assumed_role_arn": "arn:aws:iam::772401394250:role/test-user-role"
                        }
                      ],
                      "project_id": "${mongodbatlas_cloud_provider_access_setup.setup_only.project_id}",
                      "role_id": "${mongodbatlas_cloud_provider_access_setup.setup_only.role_id}"
                    }
            - name: setup_only
              manifest: |-
                {
                  "azure_config": [
                    {
                      "atlas_azure_app_id": "9f2deb0d-be22-4524-a403-df531868bac0",
                      "service_principal_id": "22f1d2a6-d0e9-482a-83a4-b8dd7dddc2c1",
                      "tenant_id": "91402384-d71e-22f5-22dd-759e272cdc1c"
                    }
                  ],
                  "project_id": "64259ee860c43338194b0f8e",
                  "provider_name": "AZURE"
                }
              dependencies:
                mongodbatlas_cloud_provider_access_authorization.auth_role: |-
                    {
                      "azure": [
                        {
                          "atlas_azure_app_id": "9f2deb0d-be22-4524-a403-df531868bac0",
                          "service_principal_id": "22f1d2a6-d0e9-482a-83a4-b8dd7dddc2c1",
                          "tenant_id": "91402384-d71e-22f5-22dd-759e272cdc1c"
                        }
                      ],
                      "project_id": "${mongodbatlas_cloud_provider_access_setup.setup_only.project_id}",
                      "role_id": "${mongodbatlas_cloud_provider_access_setup.setup_only.role_id}"
                    }
        argumentDocs:
            atlas_assumed_role_external_id: '- Unique external ID Atlas uses when assuming the IAM role in your AWS account.'
            atlas_aws_account_arn: '- ARN associated with the Atlas AWS account used to assume IAM roles in your AWS account.'
            atlas_azure_app_id: '- Azure Active Directory Application ID of Atlas. This property is required when provider_name = "AZURE".'
            authorized_date: '- Date on which this role was authorized.'
            aws_config: '- aws related arn roles'
            azure_config: '- azure related configurations'
            created_date: '- Date on which this role was created.'
            feature_usages: '- Atlas features this AWS IAM role is linked to.'
            iam_assumed_role_arn: '- (Optional) - ARN of the IAM Role that Atlas assumes when accessing resources in your AWS account. This value is required after the creation (register of the role) as part of Set Up Unified AWS Access.'
            id: '- Unique identifier used by terraform for internal management.'
            last_updated_date: '- Date and time when this Azure Service Principal was last updated. This parameter expresses its value in the ISO 8601 timestamp format in UTC.'
            mongodbatlas_cloud_provider_access: |-
                that at provision time sets up all the required configuration for a given provider, then with a subsequent update it can perform the authorize of the role. Note this path requires two terraform apply commands, once for setup and once for auth. This resource supports only AWS.
                WARNING: The resource mongodbatlas_cloud_provider_access is deprecated and will be removed in version v1.14.0, use the Two Resource path instead.
            mongodbatlas_cloud_provider_access_setup: |-
                and mongodbatlas_cloud_provider_access_authorization. The first resource, mongodbatlas_cloud_provider_access_setup, only generates
                the initial configuration (create, delete operations). The second resource, mongodbatlas_cloud_provider_access_authorization, helps to perform the authorization using the role_id of the first resource. This path is helpful in a multi-provider Terraform file, and allows for a single and decoupled apply. See example of this Two Resource path option with AWS Cloud here and AZURE Cloud here.
            project_id: '- (Required) The unique ID for the project'
            provider_name: '- (Required) The cloud provider for which to create a new role. Currently only AWS and AZURE are supported. WARNING Changing the `provider_name`` will result in destruction of the existing resource and the creation of a new resource.'
            role_id: '- Unique ID of this role.'
            service_principal_id: '- UUID string that identifies the Azure Service Principal. This property is required when provider_name = "AZURE".'
            tenant_id: '- UUID String that identifies the Azure Active Directory Tenant ID. This property is required when provider_name = "AZURE".'
        importStatements: []
    mongodbatlas_cloud_provider_snapshot:
        subCategory: ""
        description: Provides an Cloud Backup Snapshot resource.
        name: mongodbatlas_cloud_provider_snapshot
        title: cloud_provider_snapshot
        examples:
            - name: test
              manifest: |-
                {
                  "cluster_name": "${mongodbatlas_cluster.my_cluster.name}",
                  "description": "myDescription",
                  "project_id": "${mongodbatlas_cluster.my_cluster.project_id}",
                  "retention_in_days": 1,
                  "timeout": "10m"
                }
              references:
                cluster_name: mongodbatlas_cluster.my_cluster.name
                project_id: mongodbatlas_cluster.my_cluster.project_id
              dependencies:
                mongodbatlas_cloud_provider_snapshot_restore_job.test: |-
                    {
                      "cluster_name": "${mongodbatlas_cloud_provider_snapshot.test.cluster_name}",
                      "delivery_type": [
                        {
                          "download": true
                        }
                      ],
                      "project_id": "${mongodbatlas_cloud_provider_snapshot.test.project_id}",
                      "snapshot_id": "${mongodbatlas_cloud_provider_snapshot.test.snapshot_id}"
                    }
                mongodbatlas_cluster.my_cluster: |-
                    {
                      "cloud_backup": true,
                      "name": "MyCluster",
                      "project_id": "5cf5a45a9ccf6400e60981b6",
                      "provider_instance_size_name": "M10",
                      "provider_name": "AWS",
                      "provider_region_name": "EU_WEST_2"
                    }
        argumentDocs:
            cluster_name: '- (Required) The name of the Atlas cluster that contains the snapshots you want to retrieve.'
            created_at: '- UTC ISO 8601 formatted point in time when Atlas took the snapshot.'
            description: '- (Required) Description of the on-demand snapshot.'
            expires_at: '- UTC ISO 8601 formatted point in time when Atlas will delete the snapshot.'
            id: "-\tUnique identifier used for terraform for internal manages."
            master_key_uuid: '- Unique ID of the AWS KMS Customer Master Key used to encrypt the snapshot. Only visible for clusters using Encryption at Rest via Customer KMS.'
            mongod_version: '- Version of the MongoDB server.'
            project_id: '- (Required) The unique identifier of the project for the Atlas cluster.'
            retention_in_days: '- (Required) The number of days that Atlas should retain the on-demand snapshot. Must be at least 1.'
            snapshot_id: '- Unique identifier of the snapshot.'
            snapshot_type: '- Specified the type of snapshot. Valid values are onDemand and scheduled.'
            status: '- Current status of the snapshot. One of the following values will be returned: queued, inProgress, completed, failed.'
            storage_size_bytes: '- Specifies the size of the snapshot in bytes.'
            timeout: '- (Optional) The duration of time to wait to finish the on-demand snapshot. The timeout value is defined by a signed sequence of decimal numbers with an time unit suffix such as: 1h45m, 300s, 10m, .... The valid time units are:  ns, us (or µs), ms, s, m, h. Default value for the timeout is 10m'
            type: '- Specifies the type of cluster: replicaSet or shardedCluster.'
        importStatements: []
    mongodbatlas_cloud_provider_snapshot_backup_policy:
        subCategory: ""
        description: Provides a Cloud Backup Snapshot Policy resource.
        name: mongodbatlas_cloud_provider_snapshot_backup_policy
        title: cloud_provider_snapshot_backup_policy
        examples:
            - name: test
              manifest: |-
                {
                  "cluster_name": "${mongodbatlas_cluster.my_cluster.name}",
                  "policies": [
                    {
                      "id": "${mongodbatlas_cluster.my_cluster.snapshot_backup_policy.0.policies.0.id}",
                      "policy_item": [
                        {
                          "frequency_interval": 1,
                          "frequency_type": "hourly",
                          "id": "${mongodbatlas_cluster.my_cluster.snapshot_backup_policy.0.policies.0.policy_item.0.id}",
                          "retention_unit": "days",
                          "retention_value": 1
                        },
                        {
                          "frequency_interval": 1,
                          "frequency_type": "daily",
                          "id": "${mongodbatlas_cluster.my_cluster.snapshot_backup_policy.0.policies.0.policy_item.1.id}",
                          "retention_unit": "days",
                          "retention_value": 2
                        },
                        {
                          "frequency_interval": 4,
                          "frequency_type": "weekly",
                          "id": "${mongodbatlas_cluster.my_cluster.snapshot_backup_policy.0.policies.0.policy_item.2.id}",
                          "retention_unit": "weeks",
                          "retention_value": 3
                        },
                        {
                          "frequency_interval": 5,
                          "frequency_type": "monthly",
                          "id": "${mongodbatlas_cluster.my_cluster.snapshot_backup_policy.0.policies.0.policy_item.3.id}",
                          "retention_unit": "months",
                          "retention_value": 4
                        }
                      ]
                    }
                  ],
                  "project_id": "${mongodbatlas_cluster.my_cluster.project_id}",
                  "reference_hour_of_day": 3,
                  "reference_minute_of_hour": 45,
                  "restore_window_days": 4
                }
              references:
                cluster_name: mongodbatlas_cluster.my_cluster.name
                policies.id: mongodbatlas_cluster.my_cluster.snapshot_backup_policy.0.policies.0.id
                policies.policy_item.id: mongodbatlas_cluster.my_cluster.snapshot_backup_policy.0.policies.0.policy_item.3.id
                project_id: mongodbatlas_cluster.my_cluster.project_id
              dependencies:
                mongodbatlas_cluster.my_cluster: |-
                    {
                      "name": "clusterTest",
                      "project_id": "\u003cPROJECT-ID\u003e",
                      "provider_backup_enabled": true,
                      "provider_instance_size_name": "M10",
                      "provider_name": "AWS",
                      "provider_region_name": "EU_CENTRAL_1"
                    }
            - name: test
              manifest: |-
                {
                  "cluster_name": "${mongodbatlas_cluster.my_cluster.name}",
                  "policies": [
                    {
                      "id": "${mongodbatlas_cluster.my_cluster.snapshot_backup_policy.0.policies.0.id}",
                      "policy_item": [
                        {
                          "frequency_interval": 1,
                          "frequency_type": "hourly",
                          "id": "${mongodbatlas_cluster.my_cluster.snapshot_backup_policy.0.policies.0.policy_item.0.id}",
                          "retention_unit": "days",
                          "retention_value": 1
                        },
                        {
                          "frequency_interval": 1,
                          "frequency_type": "daily",
                          "id": "${mongodbatlas_cluster.my_cluster.snapshot_backup_policy.0.policies.0.policy_item.1.id}",
                          "retention_unit": "days",
                          "retention_value": 2
                        },
                        {
                          "frequency_interval": 5,
                          "frequency_type": "monthly",
                          "id": "${mongodbatlas_cluster.my_cluster.snapshot_backup_policy.0.policies.0.policy_item.3.id}",
                          "retention_unit": "months",
                          "retention_value": 4
                        }
                      ]
                    }
                  ],
                  "project_id": "${mongodbatlas_cluster.my_cluster.project_id}",
                  "reference_hour_of_day": 3,
                  "reference_minute_of_hour": 45,
                  "restore_window_days": 4
                }
              references:
                cluster_name: mongodbatlas_cluster.my_cluster.name
                policies.id: mongodbatlas_cluster.my_cluster.snapshot_backup_policy.0.policies.0.id
                policies.policy_item.id: mongodbatlas_cluster.my_cluster.snapshot_backup_policy.0.policies.0.policy_item.3.id
                project_id: mongodbatlas_cluster.my_cluster.project_id
              dependencies:
                mongodbatlas_cluster.my_cluster: |-
                    {
                      "name": "clusterTest",
                      "project_id": "\u003cPROJECT-ID\u003e",
                      "provider_backup_enabled": true,
                      "provider_instance_size_name": "M10",
                      "provider_name": "AWS",
                      "provider_region_name": "EU_CENTRAL_1"
                    }
            - name: test
              manifest: |-
                {
                  "cluster_name": "${mongodbatlas_cluster.my_cluster.name}",
                  "policies": [
                    {
                      "id": "${mongodbatlas_cluster.my_cluster.snapshot_backup_policy.0.policies.0.id}",
                      "policy_item": [
                        {
                          "frequency_interval": 5,
                          "frequency_type": "monthly",
                          "id": 5,
                          "retention_unit": "months",
                          "retention_value": 4
                        }
                      ]
                    }
                  ],
                  "project_id": "${mongodbatlas_cluster.my_cluster.project_id}",
                  "reference_hour_of_day": 3,
                  "reference_minute_of_hour": 45,
                  "restore_window_days": 4
                }
              references:
                cluster_name: mongodbatlas_cluster.my_cluster.name
                policies.id: mongodbatlas_cluster.my_cluster.snapshot_backup_policy.0.policies.0.id
                project_id: mongodbatlas_cluster.my_cluster.project_id
              dependencies:
                mongodbatlas_cluster.my_cluster: |-
                    {
                      "name": "clusterTest",
                      "project_id": "\u003cPROJECT-ID\u003e",
                      "provider_backup_enabled": true,
                      "provider_instance_size_name": "M10",
                      "provider_name": "AWS",
                      "provider_region_name": "EU_CENTRAL_1"
                    }
        argumentDocs:
            cluster_id: '- Unique identifier of the Atlas cluster.'
            cluster_name: '- (Required) The name of the Atlas cluster that contains the snapshot backup policy you want to retrieve.'
            next_snapshot: '- Timestamp in the number of seconds that have elapsed since the UNIX epoch when Atlas takes the next snapshot.'
            policies: '- (Required) Contains a document for each backup policy item in the desired updated backup policy.'
            policies.#.id: '- (Required) Unique identifier of the backup policy that you want to update. policies.#.id is a value obtained via the mongodbatlas_cluster resource. provider_backup_enabled of the mongodbatlas_cluster resource must be set to true. See the example above for how to refer to the mongodbatlas_cluster resource for policies.#.id'
            policies.#.policy_item: '- (Required) Array of backup policy items.'
            policies.#.policy_item.#.frequency_interval: '- (Required) Desired frequency of the new backup policy item specified by frequencyType.'
            policies.#.policy_item.#.frequency_type: '- (Required) Frequency associated with the backup policy item. One of the following values: hourly, daily, weekly or monthly.'
            policies.#.policy_item.#.id: '- (Required) Unique identifier of the backup policy item. policies.#.policy_item.#.id is a value obtained via the mongodbatlas_cluster resource. provider_backup_enabled of the mongodbatlas_cluster resource must be set to true. See the example above for how to refer to the mongodbatlas_cluster resource for policies.#.policy_item.#.id'
            policies.#.policy_item.#.retention_unit: '- (Required) Scope of the backup policy item: days, weeks, or months.'
            policies.#.policy_item.#.retention_value: '- (Required) Value to associate with retentionUnit.'
            project_id: '- (Required) The unique identifier of the project for the Atlas cluster.'
            reference_hour_of_day: '- (Optional) UTC Hour of day between 0 and 23, inclusive, representing which hour of the day that Atlas takes snapshots for backup policy items.'
            reference_minute_of_hour: '- (Optional) UTC Minutes after referenceHourOfDay that Atlas takes snapshots for backup policy items. Must be between 0 and 59, inclusive.'
            restore_window_days: '- (Optional) Number of days back in time you can restore to with point-in-time accuracy. Must be a positive, non-zero integer.'
            update_snapshots: '- (Optional) Specify true to apply the retention changes in the updated backup policy to snapshots that Atlas took previously.'
        importStatements: []
    mongodbatlas_cloud_provider_snapshot_restore_job:
        subCategory: ""
        description: Provides a Cloud Backup Snapshot Restore Job resource.
        name: mongodbatlas_cloud_provider_snapshot_restore_job
        title: cloud_provider_snapshot_restore_job
        examples:
            - name: test
              manifest: |-
                {
                  "cluster_name": "${mongodbatlas_cloud_provider_snapshot.test.cluster_name}",
                  "delivery_type_config": [
                    {
                      "automated": true,
                      "target_cluster_name": "MyCluster",
                      "target_project_id": "5cf5a45a9ccf6400e60981b6"
                    }
                  ],
                  "depends_on": [
                    "${mongodbatlas_cloud_provider_snapshot.test}"
                  ],
                  "project_id": "${mongodbatlas_cloud_provider_snapshot.test.project_id}",
                  "snapshot_id": "${mongodbatlas_cloud_provider_snapshot.test.snapshot_id}"
                }
              references:
                cluster_name: mongodbatlas_cloud_provider_snapshot.test.cluster_name
                project_id: mongodbatlas_cloud_provider_snapshot.test.project_id
                snapshot_id: mongodbatlas_cloud_provider_snapshot.test.snapshot_id
              dependencies:
                mongodbatlas_cloud_provider_snapshot.test: |-
                    {
                      "cluster_name": "${mongodbatlas_cluster.my_cluster.name}",
                      "description": "myDescription",
                      "project_id": "${mongodbatlas_cluster.my_cluster.project_id}",
                      "retention_in_days": 1
                    }
                mongodbatlas_cluster.my_cluster: |-
                    {
                      "cloud_backup": true,
                      "name": "MyCluster",
                      "project_id": "5cf5a45a9ccf6400e60981b6",
                      "provider_instance_size_name": "M10",
                      "provider_name": "AWS",
                      "provider_region_name": "EU_WEST_2"
                    }
            - name: test
              manifest: |-
                {
                  "cluster_name": "${mongodbatlas_cloud_provider_snapshot.test.cluster_name}",
                  "delivery_type_config": [
                    {
                      "download": true
                    }
                  ],
                  "project_id": "${mongodbatlas_cloud_provider_snapshot.test.project_id}",
                  "snapshot_id": "${mongodbatlas_cloud_provider_snapshot.test.snapshot_id}"
                }
              references:
                cluster_name: mongodbatlas_cloud_provider_snapshot.test.cluster_name
                project_id: mongodbatlas_cloud_provider_snapshot.test.project_id
                snapshot_id: mongodbatlas_cloud_provider_snapshot.test.snapshot_id
              dependencies:
                mongodbatlas_cloud_provider_snapshot.test: |-
                    {
                      "cluster_name": "${mongodbatlas_cluster.my_cluster.name}",
                      "description": "myDescription",
                      "project_id": "${mongodbatlas_cluster.my_cluster.project_id}",
                      "retention_in_days": 1
                    }
                mongodbatlas_cluster.my_cluster: |-
                    {
                      "cloud_backup": true,
                      "name": "MyCluster",
                      "project_id": "5cf5a45a9ccf6400e60981b6",
                      "provider_instance_size_name": "M10",
                      "provider_name": "AWS",
                      "provider_region_name": "EU_WEST_2"
                    }
        argumentDocs:
            cancelled: "-\tIndicates whether the restore job was canceled."
            cluster_name: '- (Required) The name of the Atlas cluster whose snapshot you want to restore.'
            created_at: "-\tUTC ISO 8601 formatted point in time when Atlas created the restore job."
            delivery_type: '- (Required) Type of restore job to create. Possible values are: download or automated, only one must be set it in true.'
            delivery_type_config: '- Type of restore job to create. Possible values are: automated and download.'
            delivery_url: "-\tOne or more URLs for the compressed snapshot files for manual download. Only visible if deliveryType is download."
            expired: "-\tIndicates whether the restore job expired."
            expires_at: "-\tUTC ISO 8601 formatted point in time when the restore job expires."
            finished_at: "-\tUTC ISO 8601 formatted point in time when the restore job completed."
            id: "-\tThe Terraform's unique identifier used internally for state management."
            links: "-\tOne or more links to sub-resources and/or related resources. The relations between URLs are explained in the Web Linking Specification."
            oplogInc: |-
                - Oplog operation number from which to you want to restore this snapshot. This is the second part of an Oplog timestamp.
                Three conditions apply to this parameter:
            oplogTs: |-
                - Timestamp in the number of seconds that have elapsed since the UNIX epoch from which to you want to restore this snapshot.
                Three conditions apply to this parameter:
            pointInTimeUTCSeconds: |-
                - Timestamp in the number of seconds that have elapsed since the UNIX epoch from which you want to restore this snapshot.
                Two conditions apply to this parameter:
            project_id: '- (Required) The unique identifier of the project for the Atlas cluster whose snapshot you want to restore.'
            snapshot_id: '- (Required) Unique identifier of the snapshot to restore.'
            snapshot_restore_job_id: '- The unique identifier of the restore job.'
            target_cluster_name: "- (Required) \tName of the target Atlas cluster to which the restore job restores the snapshot. Only required if deliveryType is automated."
            target_project_id: "- (Required) \tUnique ID of the target Atlas project for the specified targetClusterName. Only required if deliveryType is automated."
            timestamp: '- Timestamp in ISO 8601 date and time format in UTC when the snapshot associated to snapshotId was taken.'
        importStatements: []
    mongodbatlas_cluster:
        subCategory: ""
        description: Provides a Cluster resource.
        name: mongodbatlas_cluster
        title: cluster
        examples:
            - name: cluster-test
              manifest: |-
                {
                  "auto_scaling_disk_gb_enabled": true,
                  "cloud_backup": true,
                  "cluster_type": "REPLICASET",
                  "mongo_db_major_version": "4.2",
                  "name": "cluster-test",
                  "project_id": "\u003cYOUR-PROJECT-ID\u003e",
                  "provider_instance_size_name": "M40",
                  "provider_name": "AWS",
                  "replication_specs": [
                    {
                      "num_shards": 1,
                      "regions_config": [
                        {
                          "electable_nodes": 3,
                          "priority": 7,
                          "read_only_nodes": 0,
                          "region_name": "US_EAST_1"
                        }
                      ]
                    }
                  ]
                }
            - name: test
              manifest: |-
                {
                  "auto_scaling_disk_gb_enabled": true,
                  "cloud_backup": true,
                  "cluster_type": "REPLICASET",
                  "mongo_db_major_version": "4.2",
                  "name": "test",
                  "project_id": "\u003cYOUR-PROJECT-ID\u003e",
                  "provider_disk_type_name": "P6",
                  "provider_instance_size_name": "M30",
                  "provider_name": "AZURE",
                  "replication_specs": [
                    {
                      "num_shards": 1,
                      "regions_config": [
                        {
                          "electable_nodes": 3,
                          "priority": 7,
                          "read_only_nodes": 0,
                          "region_name": "US_EAST"
                        }
                      ]
                    }
                  ]
                }
            - name: test
              manifest: |-
                {
                  "auto_scaling_disk_gb_enabled": true,
                  "cloud_backup": true,
                  "cluster_type": "REPLICASET",
                  "mongo_db_major_version": "4.2",
                  "name": "test",
                  "project_id": "\u003cYOUR-PROJECT-ID\u003e",
                  "provider_instance_size_name": "M30",
                  "provider_name": "GCP",
                  "replication_specs": [
                    {
                      "num_shards": 1,
                      "regions_config": [
                        {
                          "electable_nodes": 3,
                          "priority": 7,
                          "read_only_nodes": 0,
                          "region_name": "EASTERN_US"
                        }
                      ]
                    }
                  ]
                }
            - name: cluster-test
              manifest: |-
                {
                  "cloud_backup": true,
                  "cluster_type": "REPLICASET",
                  "name": "cluster-test-multi-region",
                  "num_shards": 1,
                  "project_id": "\u003cYOUR-PROJECT-ID\u003e",
                  "provider_instance_size_name": "M10",
                  "provider_name": "AWS",
                  "replication_specs": [
                    {
                      "num_shards": 1,
                      "regions_config": [
                        {
                          "electable_nodes": 3,
                          "priority": 7,
                          "read_only_nodes": 0,
                          "region_name": "US_EAST_1"
                        },
                        {
                          "electable_nodes": 2,
                          "priority": 6,
                          "read_only_nodes": 0,
                          "region_name": "US_EAST_2"
                        },
                        {
                          "electable_nodes": 2,
                          "priority": 5,
                          "read_only_nodes": 2,
                          "region_name": "US_WEST_1"
                        }
                      ]
                    }
                  ]
                }
            - name: cluster-test
              manifest: |-
                {
                  "cloud_backup": true,
                  "cluster_type": "GEOSHARDED",
                  "name": "cluster-test-global",
                  "num_shards": 1,
                  "project_id": "\u003cYOUR-PROJECT-ID\u003e",
                  "provider_instance_size_name": "M30",
                  "provider_name": "AWS",
                  "replication_specs": [
                    {
                      "num_shards": 2,
                      "regions_config": [
                        {
                          "electable_nodes": 3,
                          "priority": 7,
                          "read_only_nodes": 0,
                          "region_name": "US_EAST_1"
                        }
                      ],
                      "zone_name": "Zone 1"
                    },
                    {
                      "num_shards": 2,
                      "regions_config": [
                        {
                          "electable_nodes": 3,
                          "priority": 7,
                          "read_only_nodes": 0,
                          "region_name": "EU_CENTRAL_1"
                        }
                      ],
                      "zone_name": "Zone 2"
                    }
                  ]
                }
            - name: cluster-test
              manifest: |-
                {
                  "backing_provider_name": "AWS",
                  "name": "cluster-test-global",
                  "project_id": "\u003cYOUR-PROJECT-ID\u003e",
                  "provider_instance_size_name": "M2",
                  "provider_name": "TENANT",
                  "provider_region_name": "US_EAST_1"
                }
            - name: cluster-test
              manifest: |-
                {
                  "backing_provider_name": "AWS",
                  "name": "cluster-test-global",
                  "project_id": "\u003cYOUR-PROJECT-ID\u003e",
                  "provider_instance_size_name": "M0",
                  "provider_name": "TENANT",
                  "provider_region_name": "US_EAST_1"
                }
        argumentDocs:
            AWS: '- Amazon AWS'
            AZURE: '- Microsoft Azure'
            CONTINUOUS: ':  Atlas creates your cluster using the most recent MongoDB release. Atlas automatically updates your cluster to the latest major and rapid MongoDB releases as they become available.'
            GCP: '- Google Cloud Platform'
            LTS: ': Atlas creates your cluster using the latest patch release of the MongoDB version that you specify in the mongoDBMajorVersion field. Atlas automatically updates your cluster to subsequent patch releases of this MongoDB version. Atlas doesn''t update your cluster to newer rapid or major MongoDB releases as they become available.'
            TENANT: '- A multi-tenant deployment on one of the supported cloud service providers. Only valid when providerSettings.instanceSizeName is either M2 or M5.'
            analytics_nodes: '- (Optional) The number of analytics nodes for Atlas to deploy to the region. Analytics nodes are useful for handling analytic data such as reporting queries from BI Connector for Atlas. Analytics nodes are read-only, and can never become the primary. If you do not specify this option, no analytics nodes are deployed to the region.'
            auto_scaling_disk_gb_enabled: '- (Optional) Specifies whether disk auto-scaling is enabled. The default is true.'
            cloud_backup: ', to enable Cloud Backup.  If you create a new Atlas cluster and set backup_enabled to true, the Provider will respond with an error.  This change doesn’t affect existing clusters that use legacy backups.'
            cluster_id: '- The cluster ID.'
            connection_strings: '- Set of connection strings that your applications use to connect to this cluster. More info in Connection-strings. Use the parameters in this object to connect your applications to this cluster. To learn more about the formats of connection strings, see Connection String Options. NOTE: Atlas returns the contents of this object after the cluster is operational, not while it builds the cluster.'
            connection_strings.aws_private_link: '-  Private-endpoint-aware mongodb://connection strings for each interface VPC endpoint you configured to connect to this cluster. Returned only if you created a AWS PrivateLink connection to this cluster. DEPRECATED Use connection_strings.private_endpoint[n].connection_string instead.'
            connection_strings.aws_private_link_srv: '- Private-endpoint-aware mongodb+srv://connection strings for each interface VPC endpoint you configured to connect to this cluster. Returned only if you created a AWS PrivateLink connection to this cluster. Use this URI format if your driver supports it. If it doesn’t, use connectionStrings.awsPrivateLink. DEPRECATED Use connection_strings.private_endpoint[n].srv_connection_string instead.'
            connection_strings.private: '-   Network-peering-endpoint-aware mongodb://connection strings for each interface VPC endpoint you configured to connect to this cluster. Returned only if you created a network peering connection to this cluster.'
            connection_strings.private_endpoint: '- Private endpoint connection strings. Each object describes the connection strings you can use to connect to this cluster through a private endpoint. Atlas returns this parameter only if you deployed a private endpoint to all regions to which you deployed this cluster''s nodes.'
            connection_strings.private_endpoint.#.connection_string: '- Private-endpoint-aware mongodb://connection string for this private endpoint.'
            connection_strings.private_endpoint.#.endpoints: '- Private endpoint through which you connect to Atlas when you use connection_strings.private_endpoint[n].connection_string or connection_strings.private_endpoint[n].srv_connection_string'
            connection_strings.private_endpoint.#.endpoints.#.endpoint_id: '- Unique identifier of the private endpoint.'
            connection_strings.private_endpoint.#.endpoints.#.provider_name: '- Cloud provider to which you deployed the private endpoint. Atlas returns AWS or AZURE.'
            connection_strings.private_endpoint.#.endpoints.#.region: '- Region to which you deployed the private endpoint.'
            connection_strings.private_endpoint.#.srv_connection_string: '- Private-endpoint-aware mongodb+srv:// connection string for this private endpoint. The mongodb+srv protocol tells the driver to look up the seed list of hosts in DNS . Atlas synchronizes this list with the nodes in a cluster. If the connection string uses this URI format, you don''t need to: Append the seed list or Change the URI if the nodes change. Use this URI format if your driver supports it. If it doesn''t, use connection_strings.private_endpoint[n].connection_string'
            connection_strings.private_endpoint.#.srv_shard_optimized_connection_string: '- Private endpoint-aware connection string optimized for sharded clusters that uses the mongodb+srv:// protocol to connect to MongoDB Cloud through a private endpoint. If the connection string uses this Uniform Resource Identifier (URI) format, you don''t need to change the Uniform Resource Identifier (URI) if the nodes change. Use this Uniform Resource Identifier (URI) format if your application and Atlas cluster supports it. If it doesn''t, use and consult the documentation for connectionStrings.privateEndpoint[n].srvConnectionString.'
            connection_strings.private_endpoint.#.type: '- Type of MongoDB process that you connect to with the connection strings. Atlas returns MONGOD for replica sets, or MONGOS for sharded clusters.'
            connection_strings.private_srv: '-  Network-peering-endpoint-aware mongodb+srv://connection strings for each interface VPC endpoint you configured to connect to this cluster. Returned only if you created a network peering connection to this cluster.'
            connection_strings.standard: '-   Public mongodb:// connection string for this cluster.'
            connection_strings.standard_srv: '- Public mongodb+srv:// connection string for this cluster. The mongodb+srv protocol tells the driver to look up the seed list of hosts in DNS. Atlas synchronizes this list with the nodes in a cluster. If the connection string uses this URI format, you don’t need to append the seed list or change the URI if the nodes change. Use this URI format if your driver supports it. If it doesn’t  , use connectionStrings.standard.'
            container_id: '- The Container ID is the id of the container created when the first cluster in the region (AWS/Azure) or project (GCP) was created.'
            default_read_concern: '- (Optional) Default level of acknowledgment requested from MongoDB for read operations set for this cluster. MongoDB 4.4 clusters default to available.'
            default_write_concern: '- (Optional) Default level of acknowledgment requested from MongoDB for write operations set for this cluster. MongoDB 4.4 clusters default to 1.'
            disk_gb_enabled.auto_scaling_compute_enabled: '- (Optional) Specifies whether cluster tier auto-scaling is enabled. The default is false.'
            disk_gb_enabled.auto_scaling_compute_enabled.REPLICASET: |-
                Replica set
                - SHARDED	Sharded cluster
                - GEOSHARDED Global Cluster
            disk_gb_enabled.auto_scaling_compute_enabled.auto_scaling_compute_scale_down_enabled: '- (Optional) Set to true to enable the cluster tier to scale down. This option is only available if autoScaling.compute.enabled is true.'
            disk_gb_enabled.auto_scaling_compute_enabled.backing_provider_name: '- (Optional) Cloud service provider on which the server for a multi-tenant cluster is provisioned.'
            disk_gb_enabled.auto_scaling_compute_enabled.backup_enabled: |-
                - (Optional) Legacy Backup - Set to true to enable Atlas legacy backups for the cluster.
                Important - MongoDB deprecated the Legacy Backup feature. Clusters that use Legacy Backup can continue to use it. MongoDB recommends using Cloud Backups.
            disk_gb_enabled.auto_scaling_compute_enabled.bi_connector: '- (Optional) Specifies BI Connector for Atlas configuration on this cluster. BI Connector for Atlas is only available for M10+ clusters. See BI Connector below for more details. DEPRECATED Use bi_connector_config instead.'
            disk_gb_enabled.auto_scaling_compute_enabled.bi_connector_config: '- (Optional) Specifies BI Connector for Atlas configuration on this cluster. BI Connector for Atlas is only available for M10+ clusters. See BI Connector below for more details.'
            disk_gb_enabled.auto_scaling_compute_enabled.cloud_backup: '- (Optional) Flag indicating if the cluster uses Cloud Backup for backups.'
            disk_gb_enabled.auto_scaling_compute_enabled.cluster_type: '- (Required) Specifies the type of the cluster that you want to modify. You cannot convert a sharded cluster deployment to a replica set deployment.'
            disk_gb_enabled.auto_scaling_compute_enabled.disk_size_gb: '- (Optional - GCP/AWS Only) Capacity, in gigabytes, of the host’s root volume. Increase this number to add capacity, up to a maximum possible value of 4096 (i.e., 4 TB). This value must be a positive integer.'
            disk_gb_enabled.auto_scaling_compute_enabled.encryption_at_rest_provider: '- (Optional) Possible values are AWS, GCP, AZURE or NONE.  Only needed if you desire to manage the keys, see Encryption at Rest using Customer Key Management for complete documentation.  You must configure encryption at rest for the Atlas project before enabling it on any cluster in the project. For complete documentation on configuring Encryption at Rest, see Encryption at Rest using Customer Key Management. Requires M10 or greater. and for legacy backups, backup_enabled, to be false or omitted. Note: Atlas encrypts all cluster storage and snapshot volumes, securing all cluster data on disk: a concept known as encryption at rest, by default.'
            disk_gb_enabled.auto_scaling_compute_enabled.mongo_db_major_version: '- (Optional) Version of the cluster to deploy. Atlas supports the following MongoDB versions for M10+ clusters: 4.2, 4.4, 5.0, or 6.0. If omitted, Atlas deploys a cluster that runs MongoDB 5.0. If provider_instance_size_name: M0, M2 or M5, Atlas deploys MongoDB 5.0. Atlas always deploys the cluster with the latest stable release of the specified version. See Release Notes for latest Current Stable Release.'
            disk_gb_enabled.auto_scaling_compute_enabled.num_shards: '- (Optional) Selects whether the cluster is a replica set or a sharded cluster. If you use the replicationSpecs parameter, you must set num_shards.'
            disk_gb_enabled.auto_scaling_compute_enabled.paused: |-
                (Optional) - Flag that indicates whether the cluster is paused or not. You can pause M10 or larger clusters.  You cannot initiate pausing for a shared/tenant tier cluster.  See Considerations for Paused Clusters
                NOTE Pause lasts for up to 30 days. If you don't resume the cluster within 30 days, Atlas resumes the cluster.  When the cluster resumption happens Terraform will flag the changed state.  If you wish to keep the cluster paused, reapply your Terraform configuration.   If you prefer to allow the automated change of state to unpaused use:
                lifecycle { ignore_changes = [paused] }
            disk_gb_enabled.auto_scaling_compute_enabled.pit_enabled: '- (Optional) - Flag that indicates if the cluster uses Continuous Cloud Backup. If set to true, cloud_backup must also be set to true.'
            disk_gb_enabled.auto_scaling_compute_enabled.provider_auto_scaling_compute_max_instance_size: '- (Optional) Maximum instance size to which your cluster can automatically scale (e.g., M40). Required if autoScaling.compute.enabled is true.'
            disk_gb_enabled.auto_scaling_compute_enabled.provider_auto_scaling_compute_min_instance_size: '- (Optional) Minimum instance size to which your cluster can automatically scale (e.g., M10). Required if autoScaling.compute.scaleDownEnabled is true.'
            disk_gb_enabled.auto_scaling_compute_enabled.provider_backup_enabled: '-  (Optional) Flag indicating if the cluster uses Cloud Backup for backups. Deprecated use cloud_backup instead.'
            disk_gb_enabled.auto_scaling_compute_enabled.provider_disk_iops: '- (Optional - AWS Only) The maximum input/output operations per second (IOPS) the system can perform. The possible values depend on the selected provider_instance_size_name and disk_size_gb.  This setting requires that provider_instance_size_name to be M30 or greater and cannot be used with clusters with local NVMe SSDs.  The default value for provider_disk_iops is the same as the cluster tier''s Standard IOPS value, as viewable in the Atlas console.  It is used in cases where a higher number of IOPS is needed and possible.  If a value is submitted that is lower or equal to the default IOPS value for the cluster tier Atlas ignores the requested value and uses the default.  More details available under the providerSettings.diskIOPS parameter: MongoDB API Clusters'
            disk_gb_enabled.auto_scaling_compute_enabled.provider_disk_type_name: '- (Optional - Azure Only) Azure disk type of the server’s root volume. If omitted, Atlas uses the default disk type for the selected providerSettings.instanceSizeName.  Example disk types and associated storage sizes: P4 - 32GB, P6 - 64GB, P10 - 128GB, P15 - 256GB, P20 - 512GB, P30 - 1024GB, P40 - 2048GB, P50 - 4095GB.  More information and the most update to date disk types/storage sizes can be located at https://docs.atlas.mongodb.com/reference/api/clusters-create-one/.'
            disk_gb_enabled.auto_scaling_compute_enabled.provider_encrypt_ebs_volume: '- (Deprecated) The Flag is always true. Flag that indicates whether the Amazon EBS encryption feature encrypts the host''s root volume for both data at rest within the volume and for data moving between the volume and the cluster. Note: This setting is always enabled for clusters with local NVMe SSDs. Atlas encrypts all cluster storage and snapshot volumes, securing all cluster data on disk: a concept known as encryption at rest, by default..'
            disk_gb_enabled.auto_scaling_compute_enabled.provider_region_name: |-
                - (Optional) Physical location of your MongoDB cluster. The region you choose can affect network latency for clients accessing your databases.  Requires the Atlas region name, see the reference list for AWS, GCP, Azure.
                Do not specify this field when creating a multi-region cluster using the replicationSpec document or a Global Cluster with the replicationSpecs array.
            disk_gb_enabled.auto_scaling_compute_enabled.provider_volume_type: |-
                - (AWS - Optional) The type of the volume. The possible values are: STANDARD and PROVISIONED.  PROVISIONED is ONLY required if setting IOPS higher than the default instance IOPS.
                -> NOTE: STANDARD is not available for NVME clusters.
            disk_gb_enabled.auto_scaling_compute_enabled.replication_factor: '- (Deprecated) Number of replica set members. Each member keeps a copy of your databases, providing high availability and data redundancy. The possible values are 3, 5, or 7. The default value is 3.'
            disk_gb_enabled.auto_scaling_compute_enabled.replication_specs: '- Configuration for cluster regions.  See Replication Spec below for more details.'
            disk_gb_enabled.auto_scaling_compute_enabled.retain_backups_enabled: '- (Optional) Set to true to retain backup snapshots for the deleted cluster. M10 and above only.'
            disk_gb_enabled.auto_scaling_compute_enabled.termination_protection_enabled: '- Flag that indicates whether termination protection is enabled on the cluster. If set to true, MongoDB Cloud won''t delete the cluster. If set to false, MongoDB Cloud will delete the cluster.'
            disk_gb_enabled.auto_scaling_compute_enabled.timeouts: '- (Optional) The duration of time to wait for Cluster to be created, updated, or deleted. The timeout value is defined by a signed sequence of decimal numbers with an time unit suffix such as: 1h45m, 300s, 10m, .... The valid time units are:  ns, us (or µs), ms, s, m, h. The default timeout for Cluster create & delete is 3h. Learn more about timeouts here.'
            disk_gb_enabled.auto_scaling_compute_enabled.version_release_system: '- (Optional) - Release cadence that Atlas uses for this cluster. This parameter defaults to LTS. If you set this field to CONTINUOUS, you must omit the mongo_db_major_version field. Atlas accepts:'
            electable_nodes: '- (Optional) Number of electable nodes for Atlas to deploy to the region. Electable nodes can become the primary and can facilitate local reads.'
            enabled: '- (Optional) Specifies whether or not BI Connector for Atlas is enabled on the cluster.l'
            fail_index_key_too_long: '- (Optional) When true, documents can only be updated or inserted if, for all indexed fields on the target collection, the corresponding index entries do not exceed 1024 bytes. When false, mongod writes documents that exceed the limit but does not index them.'
            "false": to disable disk auto-scaling.
            id: '- (Optional) Unique identifer of the replication document for a zone in a Global Cluster.'
            javascript_enabled: '- (Optional) When true, the cluster allows execution of operations that perform server-side executions of JavaScript. When false, the cluster disables execution of those operations.'
            key: '- The key that you want to write.'
            minimum_enabled_tls_protocol: '- (Optional) Sets the minimum Transport Layer Security (TLS) version the cluster accepts for incoming connections.Valid values are:'
            mongo_db_version: '- Version of MongoDB the cluster runs, in major-version.minor-version format.'
            mongo_uri: '- Base connection string for the cluster. Atlas only displays this field after the cluster is operational, not while it builds the cluster.'
            mongo_uri_updated: '- Lists when the connection string was last updated. The connection string changes, for example, if you change a replica set to a sharded cluster.'
            mongo_uri_with_options: '- connection string for connecting to the Atlas cluster. Includes the replicaSet, ssl, and authSource query parameters in the connection string with values appropriate for the cluster.'
            mongodbatlas_privatelink_endpoint_service: |-
                resources are fully applied. Add a depends_on = [mongodbatlas_privatelink_endpoint_service.example] to ensure connection_strings are available following terraform apply.
                If the expected connection string(s) do not contain a value, a terraform refresh may need to be performed to obtain the value. One can also view the status of the peered connection in the Atlas UI.
            name: '- (Required) Name of the cluster as it appears in Atlas. Once the cluster is created, its name cannot be changed. WARNING Changing the name will result in destruction of the existing cluster and the creation of a new cluster.'
            no_table_scan: '- (Optional) When true, the cluster disables the execution of any query that requires a collection scan to return results. When false, the cluster allows the execution of those operations.'
            num_shards: '- (Required) Number of shards to deploy in the specified zone, minimum 1.'
            oplog_min_retention_hours: '- (Optional) Minimum retention window for cluster''s oplog expressed in hours. A value of null indicates that the cluster uses the default minimum oplog window that MongoDB Cloud calculates.'
            oplog_size_mb: '- (Optional) The custom oplog size of the cluster. Without a value that indicates that the cluster uses the default oplog size calculated by Atlas.'
            priority: is 0.
            project_id: '- (Required) The unique ID for the project to create the database user.'
            provider_instance_size_name: '- (Required) Atlas provides different instance sizes, each with a default storage capacity and RAM size. The instance size you select is used for all the data-bearing servers in your cluster. See Create a Cluster providerSettings.instanceSizeName for valid values and default resources.'
            provider_name: '- (Required) Cloud service provider on which the servers are provisioned.'
            read_only_nodes: '- (Optional) Number of read-only nodes for Atlas to deploy to the region. Read-only nodes can never become the primary, but can facilitate local-reads. Specify 0 if you do not want any read-only nodes in the region.'
            read_preference: '- (Optional) Specifies the read preference to be used by BI Connector for Atlas on the cluster. Each BI Connector for Atlas read preference contains a distinct combination of readPreference and readPreferenceTags options. For details on BI Connector for Atlas read preferences, refer to the BI Connector Read Preferences Table.'
            region_name: '- (Optional) Physical location of your MongoDB cluster. The region you choose can affect network latency for clients accessing your databases.  Requires the Atlas region name, see the reference list for AWS, GCP, Azure.'
            regions_config: '- (Optional) Physical location of the region. Each regionsConfig document describes the region’s priority in elections and the number and type of MongoDB nodes Atlas deploys to the region. You must order each regionsConfigs document by regionsConfig.priority, descending. See Region Config below for more details.'
            sample_refresh_interval_bi_connector: '- (Optional) Interval in seconds at which the mongosqld process re-samples data to create its relational schema. The default value is 300. The specified value must be a positive integer. Available only for Atlas deployments in which BI Connector for Atlas is enabled.'
            sample_size_bi_connector: '- (Optional) Number of documents per database to sample when gathering schema information. Defaults to 100. Available only for Atlas deployments in which BI Connector for Atlas is enabled.'
            snapshot_backup_policy: '- current snapshot schedule and retention settings for the cluster.'
            snapshot_backup_policy.#.cluster_id: '- Unique identifier of the Atlas cluster.'
            snapshot_backup_policy.#.cluster_name: '- Name of the Atlas cluster that contains the snapshot backup policy.'
            snapshot_backup_policy.#.next_snapshot: '- UTC ISO 8601 formatted point in time when Atlas will take the next snapshot.'
            snapshot_backup_policy.#.policies: '- A list of policy definitions for the cluster.'
            snapshot_backup_policy.#.policies.#.id: '- Unique identifier of the backup policy.'
            snapshot_backup_policy.#.policies.#.policy_item: '- A list of specifications for a policy.'
            snapshot_backup_policy.#.policies.#.policy_item.#.frequency_interval: '- The frequency interval for a set of snapshots.'
            snapshot_backup_policy.#.policies.#.policy_item.#.frequency_type: '- A type of frequency (hourly, daily, weekly, monthly).'
            snapshot_backup_policy.#.policies.#.policy_item.#.id: '- Unique identifier for this policy item.'
            snapshot_backup_policy.#.policies.#.policy_item.#.retention_unit: '- The unit of time in which snapshot retention is measured (days, weeks, months).'
            snapshot_backup_policy.#.policies.#.policy_item.#.retention_value: '- The number of days, weeks, or months the snapshot is retained.'
            snapshot_backup_policy.#.reference_hour_of_day: '- UTC Hour of day between 0 and 23 representing which hour of the day that Atlas takes a snapshot.'
            snapshot_backup_policy.#.reference_minute_of_hour: '- UTC Minute of day between 0 and 59 representing which minute of the referenceHourOfDay that Atlas takes the snapshot.'
            snapshot_backup_policy.#.restore_window_days: '- Specifies a restore window in days for the cloud provider backup to maintain.'
            snapshot_backup_policy.#.update_snapshots: '- Specifies it''s true to apply the retention changes in the updated backup policy to snapshots that Atlas took previously.'
            srv_address: '- Connection string for connecting to the Atlas cluster. The +srv modifier forces the connection to use TLS/SSL. See the mongoURI for additional options.'
            state_name: '- Current state of the cluster. The possible states are:'
            transaction_lifetime_limit_seconds: '- (Optional) Lifetime, in seconds, of multi-document transactions. Defaults to 60 seconds.'
            "true": to enable disk auto-scaling.
            value: '- The value that you want to write.'
            zone_name: '- (Optional) Name for the zone in a Global Cluster.'
        importStatements: []
    mongodbatlas_cluster_outage_simulation:
        subCategory: ""
        description: Provides a Cluster Outage Simulation resource.
        name: mongodbatlas_cluster_outage_simulation
        title: cluster_outage_simulation
        examples:
            - name: outage_simulation
              manifest: |-
                {
                  "cluster_name": "Cluster0",
                  "outage_filters": [
                    {
                      "cloud_provider": "AWS",
                      "region_name": "US_EAST_1"
                    },
                    {
                      "cloud_provider": "AWS",
                      "region_name": "US_EAST_2"
                    }
                  ],
                  "project_id": "64707f06c519c20c3a2b1b03"
                }
        argumentDocs:
            COMPLETE: '- MongoDB Cloud has completed the cluster outage simulation.'
            RECOVERING: '- MongoDB Cloud is recovering the cluster from the simulated outage.'
            RECOVERY_REQUESTED: '- User has requested recovery from the simulated outage.'
            REGION: '- Simulates a cluster outage for a region'
            SIMULATING: '- MongoDB Cloud is simulating cluster outage.'
            START_REQUESTED: '- User has requested cluster outage simulation.'
            STARTING: '- MongoDB Cloud is starting cluster outage simulation.'
            cloud_provider: '- (Required) The cloud provider of the region that undergoes the outage simulation. Following values are supported:'
            cluster_name: '- (Required) Name of the Atlas Cluster that is/will undergoing outage simulation.'
            id: '- The Terraform''s unique identifier used internally for state management.'
            outage_filters: '- (Minimum one required) List of settings that specify the type of cluster outage simulation.'
            project_id: '- (Required) The unique ID for the project that contains the cluster that is/will undergoing outage simulation.'
            region_name: '- (Required) The Atlas name of the region to undergo an outage simulation.'
            simulation_id: '- Unique 24-hexadecimal character string that identifies the outage simulation.'
            start_request_date: '- Date and time when MongoDB Cloud started the regional outage simulation.'
            state: '- Current phase of the outage simulation:'
            type: '- The type of cluster outage simulation. Following values are supported:'
        importStatements: []
    mongodbatlas_custom_db_role:
        subCategory: ""
        description: Provides a Custom DB Role resource.
        name: mongodbatlas_custom_db_role
        title: custom_db_role
        examples:
            - name: test_role
              manifest: |-
                {
                  "actions": [
                    {
                      "action": "UPDATE",
                      "resources": [
                        {
                          "collection_name": "",
                          "database_name": "anyDatabase"
                        }
                      ]
                    },
                    {
                      "action": "INSERT",
                      "resources": [
                        {
                          "collection_name": "",
                          "database_name": "anyDatabase"
                        }
                      ]
                    },
                    {
                      "action": "REMOVE",
                      "resources": [
                        {
                          "collection_name": "",
                          "database_name": "anyDatabase"
                        }
                      ]
                    }
                  ],
                  "project_id": "\u003cPROJECT-ID\u003e",
                  "role_name": "myCustomRole"
                }
            - name: inherited_role_one
              manifest: |-
                {
                  "actions": [
                    {
                      "action": "INSERT",
                      "resources": [
                        {
                          "collection_name": "",
                          "database_name": "anyDatabase"
                        }
                      ]
                    }
                  ],
                  "project_id": "\u003cPROJECT-ID\u003e",
                  "role_name": "insertRole"
                }
            - name: inherited_role_two
              manifest: |-
                {
                  "actions": [
                    {
                      "action": "SERVER_STATUS",
                      "resources": [
                        {
                          "cluster": true
                        }
                      ]
                    }
                  ],
                  "project_id": "${mongodbatlas_custom_db_role.inherited_role_one.project_id}",
                  "role_name": "statusServerRole"
                }
              references:
                project_id: mongodbatlas_custom_db_role.inherited_role_one.project_id
            - name: test_role
              manifest: |-
                {
                  "actions": [
                    {
                      "action": "UPDATE",
                      "resources": [
                        {
                          "collection_name": "",
                          "database_name": "anyDatabase"
                        }
                      ]
                    },
                    {
                      "action": "REMOVE",
                      "resources": [
                        {
                          "collection_name": "",
                          "database_name": "anyDatabase"
                        }
                      ]
                    }
                  ],
                  "inherited_roles": [
                    {
                      "database_name": "admin",
                      "role_name": "${mongodbatlas_custom_db_role.inherited_role_one.role_name}"
                    },
                    {
                      "database_name": "admin",
                      "role_name": "${mongodbatlas_custom_db_role.inherited_role_two.role_name}"
                    }
                  ],
                  "project_id": "${mongodbatlas_custom_db_role.inherited_role_one.project_id}",
                  "role_name": "myCustomRole"
                }
              references:
                inherited_roles.role_name: mongodbatlas_custom_db_role.inherited_role_two.role_name
                project_id: mongodbatlas_custom_db_role.inherited_role_one.project_id
        argumentDocs:
            action: |-
                - (Required) Name of the privilege action. For a complete list of actions available in the Atlas API, see Custom Role Actions
                -> Note: The privilege actions available to the Custom Roles API resource represent a subset of the privilege actions available in the Atlas Custom Roles UI.
            actions.resources.cluster: field.
            actions.resources.collection: and actions.resources.db fields.
            database_name: (Required) Database on which the inherited role is granted.
            id: '- Unique identifier used for terraform for internal manages and can be used to import.'
            project_id: '- (Required) The unique ID for the project to create the database user.'
            resources: '- (Required) Contains information on where the action is granted. Each object in the array either indicates a database and collection on which the action is granted, or indicates that the action is granted on the cluster resource.'
            resources.#.cluster: (Optional) Set to true to indicate that the action is granted on the cluster resource.
            resources.#.collection_name: '- (Optional) Collection on which the action is granted. If this value is an empty string, the action is granted on all collections within the database specified in the actions.resources.db field.'
            resources.#.database_name: Database on which the action is granted.
            role_name: '- (Required) Name of the custom role.'
        importStatements: []
    mongodbatlas_custom_dns_configuration_cluster_aws:
        subCategory: ""
        description: Provides a Custom DNS Configuration for Atlas Clusters on AWS resource.
        name: mongodbatlas_custom_dns_configuration_cluster_aws
        title: custom_dns_configuration_cluster_aws
        examples:
            - name: test
              manifest: |-
                {
                  "enabled": true,
                  "project_id": "\u003cPROJECT-ID\u003e"
                }
        argumentDocs:
            enabled: '- (Required) Indicates whether the project''s clusters deployed to AWS use custom DNS. If true, the Get All Clusters and Get One Cluster endpoints return the connectionStrings.private and connectionStrings.privateSrv fields for clusters deployed to AWS .'
            project_id: "- Required \tUnique identifier for the project."
        importStatements: []
    mongodbatlas_data_lake:
        subCategory: ""
        description: Provides a Data Lake resource.
        name: mongodbatlas_data_lake
        title: data_lake
        examples:
            - name: basic_ds
              manifest: |-
                {
                  "aws": [
                    {
                      "role_id": "${mongodbatlas_cloud_provider_access.test.role_id}",
                      "test_s3_bucket": "TEST S3 BUCKET NAME"
                    }
                  ],
                  "name": "DATA LAKE NAME",
                  "project_id": "${mongodbatlas_project.test.id}"
                }
              references:
                aws.role_id: mongodbatlas_cloud_provider_access.test.role_id
                project_id: mongodbatlas_project.test.id
              dependencies:
                mongodbatlas_cloud_provider_access.test: |-
                    {
                      "iam_assumed_role_arn": "AWS ROLE ID",
                      "project_id": "${mongodbatlas_project.test.id}",
                      "provider_name": "AWS"
                    }
                mongodbatlas_project.test: |-
                    {
                      "name": "NAME OF THE PROJECT",
                      "org_id": "ORGANIZATION ID"
                    }
        argumentDocs:
            ACTIVE: '- The Data Lake is active and verified. You can query the data stores associated with the Atlas Data Lake.'
            DUBLIN_IRL: (eu-west-1)
            FRANKFURT_DEU: (eu-central-1)
            LONDON_GBR: (eu-west-2)
            OREGON_USA: (us-west-2)
            SYDNEY_AUS: (ap-southeast-2)
            VIRGINIA_USA: (us-east-1)
            aws: '- (Required) AWS provider of the cloud service where Data Lake can access the S3 Bucket.'
            aws.0.external_id: '- Unique identifier associated with the IAM Role that Data Lake assumes when accessing the data stores.'
            aws.0.iam_assumed_role_arn: '- Amazon Resource Name (ARN) of the IAM Role that Data Lake assumes when accessing S3 Bucket data stores. The IAM Role must support the following actions against each S3 bucket:'
            aws.0.iam_user_arn: '- Amazon Resource Name (ARN) of the user that Data Lake assumes when accessing S3 Bucket data stores.'
            aws.0.role_id: '- (Required) Unique identifier of the role that Data Lake can use to access the data stores. If necessary, use the Atlas UI or API to retrieve the role ID. You must also specify the aws.0.test_s3_bucket.'
            aws.0.test_s3_bucket: '- (Required) Name of the S3 data bucket that the provided role ID is authorized to access. You must also specify the aws.0.role_id.'
            data_process_region: '- (Optional) The cloud provider region to which Atlas Data Lake routes client connections for data processing. Set to null to direct Atlas Data Lake to route client connections to the region nearest to the client based on DNS resolution.'
            data_process_region.0.cloud_provider: '- (Required) Name of the cloud service provider. Atlas Data Lake only supports AWS.'
            data_process_region.0.region: '- (Required). Name of the region to which Data Lake routes client connections for data processing. Atlas Data Lake only supports the following regions:'
            hostnames: '- The list of hostnames assigned to the Atlas Data Lake. Each string in the array is a hostname assigned to the Atlas Data Lake.'
            id: '- The Terraform''s unique identifier used internally for state management.'
            name: '- (Required) Name of the Atlas Data Lake.'
            project_id: '- (Required) The unique ID for the project to create a data lake.'
            state: '- Current state of the Atlas Data Lake:'
            storage_databases: '- Configuration details for mapping each data store to queryable databases and collections. For complete documentation on this object and its nested fields, see databases. An empty object indicates that the Data Lake has no mapping configuration for any data store.'
            storage_databases.#.collections: '-     Array of objects where each object represents a collection and data sources that map to a stores data store.'
            storage_databases.#.collections.#.data_sources: '-     Array of objects where each object represents a stores data store to map with the collection.'
            storage_databases.#.collections.#.data_sources.#.default_format: '- Default format that Data Lake assumes if it encounters a file without an extension while searching the storeName.'
            storage_databases.#.collections.#.data_sources.#.path: '- Controls how Atlas Data Lake searches for and parses files in the storeName before mapping them to the <collection>.'
            storage_databases.#.collections.#.data_sources.#.store_name: '-     Name of a data store to map to the <collection>. Must match the name of an object in the stores array.'
            storage_databases.#.collections.#.name: '- Name of the collection.'
            storage_databases.#.name: '- Name of the database to which Data Lake maps the data contained in the data store.'
            storage_databases.#.views: '-     Array of objects where each object represents an aggregation pipeline on a collection. To learn more about views, see Views.'
            storage_databases.#.views.#.name: '- Name of the view.'
            storage_databases.#.views.#.pipeline: '- Aggregation pipeline stage(s) to apply to the source collection.'
            storage_databases.#.views.#.source: '-  Name of the source collection for the view.'
            storage_stores: '- Each object in the array represents a data store. Data Lake uses the storage.databases configuration details to map data in each data store to queryable databases and collections. For complete documentation on this object and its nested fields, see stores. An empty object indicates that the Data Lake has no configured data stores.'
            storage_stores.#.bucket: '- Name of the AWS S3 bucket.'
            storage_stores.#.delimiter: '- The delimiter that separates storage_databases.#.collections.#.data_sources.#.path segments in the data store.'
            storage_stores.#.include_tags: '- Determines whether or not to use S3 tags on the files in the given path as additional partition attributes.'
            storage_stores.#.name: '- Name of the data store.'
            storage_stores.#.prefix: '- Prefix Data Lake applies when searching for files in the S3 bucket .'
            storage_stores.#.provider: '- Defines where the data is stored.'
            storage_stores.#.region: '- Name of the AWS region in which the S3 bucket is hosted.'
        importStatements: []
    mongodbatlas_data_lake_pipeline:
        subCategory: ""
        description: Provides a Data Lake Pipeline resource.
        name: mongodbatlas_data_lake_pipeline
        title: data_lake
        examples:
            - name: pipeline
              manifest: |-
                {
                  "name": "DataLakePipelineName",
                  "project_id": "${mongodbatlas_project.projectTest.project_id}",
                  "sink": [
                    {
                      "partition_fields": [
                        {
                          "name": "access",
                          "order": 0
                        }
                      ],
                      "type": "DLS"
                    }
                  ],
                  "source": [
                    {
                      "cluster_name": "${mongodbatlas_cluster.automated_backup_test.name}",
                      "collection_name": "listingsAndReviews",
                      "database_name": "sample_airbnb",
                      "type": "ON_DEMAND_CPS"
                    }
                  ],
                  "transformations": [
                    {
                      "field": "test",
                      "type": "EXCLUDE"
                    },
                    {
                      "field": "test22",
                      "type": "EXCLUDE"
                    }
                  ]
                }
              references:
                project_id: mongodbatlas_project.projectTest.project_id
                source.cluster_name: mongodbatlas_cluster.automated_backup_test.name
              dependencies:
                mongodbatlas_advanced_cluster.automated_backup_test: |-
                    {
                      "cloud_backup": true,
                      "mongo_db_major_version": "6.0",
                      "name": "automated-backup-test",
                      "project_id": "63f4d4a47baeac59406dc131",
                      "provider_instance_size_name": "M10",
                      "provider_name": "GCP",
                      "provider_region_name": "US_EAST_4"
                    }
                mongodbatlas_project.projectTest: |-
                    {
                      "name": "NAME OF THE PROJECT",
                      "org_id": "ORGANIZATION ID"
                    }
        argumentDocs:
            cluster_name: '- Human-readable name that identifies the cluster.'
            collection_name: '- Human-readable name that identifies the collection.'
            created_date: '- Timestamp that indicates when the Data Lake Pipeline was created.'
            database_name: '- Human-readable name that identifies the database.'
            id: '-  Unique 24-hexadecimal digit string that identifies the Data Lake Pipeline.'
            ingestion_schedules: '- List of backup schedule policy items that you can use as a Data Lake Pipeline source.'
            ingestion_schedules.#.frequency_interval: '- Number that indicates the frequency interval for a set of snapshots.'
            ingestion_schedules.#.frequency_type: '- Human-readable label that identifies the frequency type associated with the backup policy.'
            ingestion_schedules.#.id: '- Unique 24-hexadecimal digit string that identifies this backup policy item.'
            ingestion_schedules.#.retention_unit: '- Unit of time in which MongoDB Atlas measures snapshot retention.'
            ingestion_schedules.#.retention_value: '- Duration in days, weeks, or months that MongoDB Atlas retains the snapshot.'
            last_updated_date: '- Timestamp that indicates the last time that the Data Lake Pipeline was updated.'
            name: '- (Required) Name of the Atlas Data Lake Pipeline.'
            partition_fields: '- Ordered fields used to physically organize data in the destination.'
            partition_fields.#.field_name: '- Human-readable label that identifies the field name used to partition data.'
            partition_fields.#.order: '- Sequence in which MongoDB Atlas slices the collection data to create partitions. The resource expresses this sequence starting with zero.'
            policyItemId: '- Unique 24-hexadecimal character string that identifies a policy item.'
            project_id: '- (Required) The unique ID for the project to create a data lake pipeline.'
            provider: '- Target cloud provider for this Data Lake Pipeline.'
            region: '- Target cloud provider region for this Data Lake Pipeline. Supported cloud provider regions.'
            snapshots: '- List of backup snapshots that you can use to trigger an on demand pipeline run.'
            snapshots.#.copy_region: '- List that identifies the regions to which MongoDB Atlas copies the snapshot.'
            snapshots.#.created_at: '- Date and time when MongoDB Atlas took the snapshot.'
            snapshots.#.expires_at: '- Date and time when MongoDB Atlas deletes the snapshot.'
            snapshots.#.frequency_type: '- Human-readable label that identifies how often this snapshot triggers.'
            snapshots.#.id: '- Unique 24-hexadecimal digit string that identifies the snapshot.'
            snapshots.#.master_key: '- Unique string that identifies the Amazon Web Services (AWS) Key Management Service (KMS) Customer Master Key (CMK) used to encrypt the snapshot.'
            snapshots.#.mongod_version: '- Version of the MongoDB host that this snapshot backs up.'
            snapshots.#.policies: '- List that contains unique identifiers for the policy items.'
            snapshots.#.provider: '- Human-readable label that identifies the cloud provider that stores this snapshot.'
            snapshots.#.replica_set_name: '- Human-readable label that identifies the replica set from which MongoDB Atlas took this snapshot.'
            snapshots.#.size: '- List of backup snapshots that you can use to trigger an on demand pipeline run.'
            snapshots.#.snapshot_type: '- Human-readable label that identifies when this snapshot triggers.'
            snapshots.#.status: '- Human-readable label that indicates the stage of the backup process for this snapshot.'
            snapshots.#.type: '- Human-readable label that categorizes the cluster as a replica set or sharded cluster.'
            state: '- State of this Data Lake Pipeline.'
            transformations: '- Fields to be excluded for this Data Lake Pipeline.'
            transformations.#.field: '- Key in the document.'
            transformations.#.type: '- Type of transformation applied during the export of the namespace in a Data Lake Pipeline.'
            type: '- Type of ingestion destination of this Data Lake Pipeline.'
        importStatements: []
    mongodbatlas_database_user:
        subCategory: ""
        description: Provides a Database User resource.
        name: mongodbatlas_database_user
        title: database_user
        examples:
            - name: test
              manifest: |-
                {
                  "auth_database_name": "admin",
                  "labels": [
                    {
                      "key": "My Key",
                      "value": "My Value"
                    }
                  ],
                  "password": "test-acc-password",
                  "project_id": "\u003cPROJECT-ID\u003e",
                  "roles": [
                    {
                      "database_name": "dbforApp",
                      "role_name": "readWrite"
                    },
                    {
                      "database_name": "admin",
                      "role_name": "readAnyDatabase"
                    }
                  ],
                  "scopes": [
                    {
                      "name": "My cluster name",
                      "type": "CLUSTER"
                    },
                    {
                      "name": "My second cluster name",
                      "type": "CLUSTER"
                    }
                  ],
                  "username": "test-acc-username"
                }
            - name: test
              manifest: |-
                {
                  "auth_database_name": "$external",
                  "labels": [
                    {
                      "key": "%s",
                      "value": "%s"
                    }
                  ],
                  "project_id": "\u003cPROJECT-ID\u003e",
                  "roles": [
                    {
                      "database_name": "admin",
                      "role_name": "readAnyDatabase"
                    }
                  ],
                  "scopes": [
                    {
                      "name": "My cluster name",
                      "type": "CLUSTER"
                    }
                  ],
                  "username": "test-acc-username",
                  "x509_type": "MANAGED"
                }
            - name: test
              manifest: |-
                {
                  "auth_database_name": "$external",
                  "aws_iam_type": "ROLE",
                  "labels": [
                    {
                      "key": "%s",
                      "value": "%s"
                    }
                  ],
                  "project_id": "\u003cPROJECT-ID\u003e",
                  "roles": [
                    {
                      "database_name": "admin",
                      "role_name": "readAnyDatabase"
                    }
                  ],
                  "scopes": [
                    {
                      "name": "My cluster name",
                      "type": "CLUSTER"
                    }
                  ],
                  "username": "${aws_iam_role.test.arn}"
                }
              references:
                username: aws_iam_role.test.arn
            - name: test
              manifest: |-
                {
                  "auth_database_name": "admin",
                  "oidc_auth_type": "IDP_GROUP",
                  "project_id": "6414908c207f4d22f4d8f232",
                  "roles": [
                    {
                      "database_name": "admin",
                      "role_name": "readWriteAnyDatabase"
                    }
                  ],
                  "username": "64d613677e1ad50839cce4db/testUserOr"
                }
        argumentDocs:
            $external: if x509_type is MANAGED or CUSTOMER or aws_iam_type is USER or ROLE.
            CUSTOMER: '-  The user is being created for use with Self-Managed X.509. Users created with this x509Type require a Common Name (CN) in the username field. Externally authenticated users can only be created on the $external database.'
            GROUP: '- LDAP server authenticates this user using their LDAP user and authorizes this user using their LDAP group. To learn more about LDAP security, see Set up User Authentication and Authorization with LDAP. username must also be a fully qualified distinguished name, as defined in RFC-2253.'
            IDP_GROUP: '- Create a OIDC federated authentication user. To learn more about OIDC federated authentication, see Set up Workforce Identity Federation with OIDC.'
            MANAGED: '- The user is being created for use with Atlas-managed X.509.Externally authenticated users can only be created on the $external database.'
            NONE: "-\tThe user does not use X.509 authentication."
            ROLE: '-  New database user has credentials associated with an AWS IAM role.'
            USER: '- New database user has AWS IAM user credentials.'
            admin: if x509_type and aws_iam_type are omitted or NONE.
            auth_database_name: |-
                - (Required) Database against which Atlas authenticates the user. A user must provide both a username and authentication database to log into MongoDB.
                Accepted values include:
            aws_iam_type: '- (Optional) If this value is set, the new database user authenticates with AWS IAM credentials. If no value is given, Atlas uses the default value of NONE. The accepted types are:'
            collection_name: '- (Optional) Collection for which the role applies. You can specify a collection for the read and readWrite roles. If you do not specify a collection for read and readWrite, the role applies to all collections in the database (excluding some collections in the system. database).'
            database_name: '- (Required) Database on which the user has the specified role. A role on the admin database can include privileges that apply to the other databases.'
            id: '- The database user''s name.'
            key: '- The key that you want to write.'
            ldap_auth_type: '- (Optional) Method by which the provided username is authenticated. If no value is given, Atlas uses the default value of NONE.'
            name: '- (Required) Name of the cluster or Atlas Data Lake that the user has access to.'
            oidc_auth_type: '- (Optional) Human-readable label that indicates whether the new database user authenticates with OIDC (OpenID Connect) federated authentication. If no value is given, Atlas uses the default value of NONE. The accepted types are:'
            password: '- (Required) User''s initial password. A value is required to create the database user, however the argument but may be removed from your Terraform configuration after user creation without impacting the user, password or Terraform management. IMPORTANT --- Passwords may show up in Terraform related logs and it will be stored in the Terraform state file as plain-text. Password can be changed after creation using your preferred method, e.g. via the MongoDB Atlas UI, to ensure security.  If you do change management of the password to outside of Terraform be sure to remove the argument from the Terraform configuration so it is not inadvertently updated to the original password.'
            project_id: '- (Required) The unique ID for the project to create the database user.'
            role_name: '- (Required) Name of the role to grant. See Create a Database User roles.roleName for valid values and restrictions.'
            roles: "- (Required) \tList of user’s roles and the databases / collections on which the roles apply. A role allows the user to perform particular actions on the specified database. A role on the admin database can include privileges that apply to the other databases as well. See Roles below for more details."
            type: '- (Required) Type of resource that the user has access to. Valid values are: CLUSTER and DATA_LAKE'
            username: '- (Required) Username for authenticating to MongoDB. USER_ARN or ROLE_ARN if aws_iam_type is USER or ROLE.'
            value: '- The value that you want to write.'
            x509_type: '- (Optional) X.509 method by which the provided username is authenticated. If no value is given, Atlas uses the default value of NONE. The accepted types are:'
        importStatements: []
    mongodbatlas_encryption_at_rest:
        subCategory: ""
        description: Provides an Encryption At Rest resource.
        name: mongodbatlas_encryption_at_rest
        title: encryption_at_rest
        examples:
            - name: test
              manifest: |-
                {
                  "aws_kms_config": [
                    {
                      "customer_master_key_id": "5ce83906-6563-46b7-8045-11c20e3a5766",
                      "enabled": true,
                      "region": "US_EAST_1",
                      "role_id": "60815e2fe01a49138a928ebb"
                    }
                  ],
                  "azure_key_vault_config": [
                    {
                      "azure_environment": "AZURE",
                      "client_id": "g54f9e2-89e3-40fd-8188-EXAMPLEID",
                      "enabled": true,
                      "key_identifier": "https://EXAMPLEKeyVault.vault.azure.net/keys/EXAMPLEKey/d891821e3d364e9eb88fbd3d11807b86",
                      "key_vault_name": "EXAMPLEKeyVault",
                      "resource_group_name": "ExampleRGName",
                      "secret": "EXAMPLESECRET",
                      "subscription_id": "0ec944e3-g725-44f9-a147-EXAMPLEID",
                      "tenant_id": "e8e4b6ba-ff32-4c88-a9af-EXAMPLEID"
                    }
                  ],
                  "google_cloud_kms_config": [
                    {
                      "enabled": true,
                      "key_version_resource_id": "projects/my-project-common-0/locations/us-east4/keyRings/my-key-ring-0/cryptoKeys/my-key-0/cryptoKeyVersions/1",
                      "service_account_key": "{\"type\": \"service_account\",\"project_id\": \"my-project-common-0\",\"private_key_id\": \"e120598ea4f88249469fcdd75a9a785c1bb3\",\"private_key\": \"-----BEGIN PRIVATE KEY-----\\nMIIEuwIBA(truncated)SfecnS0mT94D9\\n-----END PRIVATE KEY-----\\n\",\"client_email\": \"my-email-kms-0@my-project-common-0.iam.gserviceaccount.com\",\"client_id\": \"10180967717292066\",\"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\"token_uri\": \"https://accounts.google.com/o/oauth2/token\",\"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\"client_x509_cert_url\": \"https://www.googleapis.com/robot/v1/metadata/x509/my-email-kms-0%40my-project-common-0.iam.gserviceaccount.com\"}"
                    }
                  ],
                  "project_id": "\u003cPROJECT-ID\u003e"
                }
            - name: default
              manifest: '{}'
            - name: example
              manifest: |-
                {
                  "azure_key_vault_config": [
                    {
                      "azure_environment": "AZURE",
                      "client_id": "g54f9e2-89e3-40fd-8188-EXAMPLEID",
                      "enabled": true,
                      "key_identifier": "https://EXAMPLEKeyVault.vault.azure.net/keys/EXAMPLEKey/d891821e3d364e9eb88fbd3d11807b86",
                      "key_vault_name": "EXAMPLEKeyVault",
                      "resource_group_name": "ExampleRGName",
                      "secret": "EXAMPLESECRET",
                      "subscription_id": "0ec944e3-g725-44f9-a147-EXAMPLEID",
                      "tenant_id": "e8e4b6ba-ff32-4c88-a9af-EXAMPLEID"
                    }
                  ],
                  "project_id": "\u003cPROJECT-ID\u003e"
                }
              dependencies:
                mongodbatlas_cluster.example_cluster: |-
                    {
                      "cluster_type": "REPLICASET",
                      "encryption_at_rest_provider": "AZURE",
                      "mongo_db_major_version": "4.4",
                      "name": "CLUSTER NAME",
                      "project_id": "${mongodbatlas_encryption_at_rest.example.project_id}",
                      "provider_instance_size_name": "M10",
                      "provider_name": "AZURE",
                      "replication_specs": [
                        {
                          "num_shards": 1,
                          "regions_config": [
                            {
                              "electable_nodes": 3,
                              "priority": 7,
                              "read_only_nodes": 0,
                              "region_name": "REGION"
                            }
                          ]
                        }
                      ]
                    }
        argumentDocs:
            aws_kms: '- (Required) Specifies AWS KMS configuration details and whether Encryption at Rest is enabled for an Atlas project.'
            azure_environment: '- The Azure environment where the Azure account credentials reside. Valid values are the following: AZURE, AZURE_CHINA, AZURE_GERMANY'
            azure_key_vault: '- (Required) Specifies Azure Key Vault configuration details and whether Encryption at Rest is enabled for an Atlas project.'
            client_id: '- The client ID, also known as the application ID, for an Azure application associated with the Azure AD tenant.'
            customer_master_key_id: '- The AWS customer master key used to encrypt and decrypt the MongoDB master keys.'
            enabled: '- Specifies whether Encryption at Rest is enabled for an Atlas project, To disable Encryption at Rest, pass only this parameter with a value of false, When you disable Encryption at Rest, Atlas also removes the configuration details.'
            google_cloud_kms: '- (Required) Specifies GCP KMS configuration details and whether Encryption at Rest is enabled for an Atlas project.'
            key_identifier: '- The unique identifier of a key in an Azure Key Vault.'
            key_vault_name: '- The name of an Azure Key Vault containing your key.'
            key_version_resource_id: '- The Key Version Resource ID from your GCP account.'
            project_id: '- (Required) The unique identifier for the project.'
            region: '- The AWS region in which the AWS customer master key exists: CA_CENTRAL_1, US_EAST_1, US_EAST_2, US_WEST_1, US_WEST_2, SA_EAST_1'
            resource_group_name: '- The name of the Azure Resource group that contains an Azure Key Vault.'
            role_id: '- ID of an AWS IAM role authorized to manage an AWS customer master key. To find the ID for an existing IAM role check the role_id attribute of the mongodbatlas_cloud_provider_access resource.'
            secret: '- The secret associated with the Azure Key Vault specified by azureKeyVault.tenantID.'
            service_account_key: '- String-formatted JSON object containing GCP KMS credentials from your GCP account.'
            subscription_id: '- The unique identifier associated with an Azure subscription.'
            tenant_id: '- The unique identifier for an Azure AD tenant within an Azure subscription.'
        importStatements: []
    mongodbatlas_event_trigger:
        subCategory: ""
        description: Provides a Event Trigger resource.
        name: mongodbatlas_event_trigger
        title: event_trigger
        examples:
            - name: test
              manifest: |-
                {
                  "app_id": "APPLICATION ID",
                  "config_collection": "COLLECTION NAME",
                  "config_database": "DATABASE NAME",
                  "config_full_document": false,
                  "config_full_document_before": false,
                  "config_match": "{\n  \"updateDescription.updatedFields\": {\n    \"status\": \"blocked\"\n  }\n}\n",
                  "config_operation_types": [
                    "INSERT",
                    "UPDATE"
                  ],
                  "config_project": "{\"updateDescription.updatedFields\":{\"status\":\"blocked\"}}",
                  "config_service_id": "SERVICE ID",
                  "disabled": false,
                  "event_processors": [
                    {
                      "aws_eventbridge": [
                        {
                          "config_account_id": "AWS ACCOUNT ID",
                          "config_region": "AWS REGIOn"
                        }
                      ]
                    }
                  ],
                  "function_id": "FUNCTION ID",
                  "name": "NAME OF THE TRIGGER",
                  "project_id": "PROJECT ID",
                  "type": "DATABASE"
                }
            - name: test
              manifest: |-
                {
                  "app_id": "APPLICATION ID",
                  "config_collection": "COLLECTION NAME",
                  "config_database": "DATABASE NAME",
                  "config_full_document": false,
                  "config_full_document_before": false,
                  "config_match": "{\"updateDescription.updatedFields\":{\"status\":\"blocked\"}}",
                  "config_operation_type": "LOGIN",
                  "config_operation_types": [
                    "INSERT",
                    "UPDATE"
                  ],
                  "config_project": "{\"updateDescription.updatedFields\":{\"status\":\"blocked\"}}",
                  "config_providers": [
                    "anon-user"
                  ],
                  "config_schedule": "*",
                  "config_service_id": "1",
                  "disabled": false,
                  "event_processors": [
                    {
                      "aws_eventbridge": [
                        {
                          "config_account_id": "AWS ACCOUNT ID",
                          "config_region": "AWS REGIOn"
                        }
                      ]
                    }
                  ],
                  "name": "NAME OF THE TRIGGER",
                  "project_id": "PROJECT ID",
                  "type": "DATABASE",
                  "unordered": false
                }
            - name: test
              manifest: |-
                {
                  "app_id": "APPLICATION ID",
                  "config_operation_type": "LOGIN",
                  "config_providers": [
                    "anon-user"
                  ],
                  "disabled": false,
                  "function_id": "1",
                  "name": "NAME OF THE TRIGGER",
                  "project_id": "PROJECT ID",
                  "type": "AUTHENTICATION"
                }
            - name: test
              manifest: |-
                {
                  "app_id": "APPLICATION ID",
                  "config_schedule": "*",
                  "disabled": false,
                  "function_id": "1",
                  "name": "NAME OF THE TRIGGER",
                  "project_id": "PROJECT ID",
                  "type": "SCHEDULED"
                }
        argumentDocs:
            app_id: '- (Required) The ObjectID of your application.'
            config_collection: '- (Optional) Required for DATABASE type. The name of the MongoDB collection that the trigger watches for change events. The collection must be part of the specified database.'
            config_database: '- (Optional) Required for DATABASE type. The name of the MongoDB database that contains the watched collection.'
            config_full_document: '- (Optional) Optional for DATABASE type. If true, indicates that UPDATE change events should include the most current majority-committed version of the modified document in the fullDocument field.'
            config_match: '- (Optional) Optional for DATABASE type. A $match expression document that MongoDB Realm includes in the underlying change stream pipeline for the trigger. This is useful when you want to filter change events beyond their operation type. The trigger will only fire if the expression evaluates to true for a given change event.'
            config_operation_type: '- (Optional) Required for AUTHENTICATION type. The authentication operation type to listen for. Possible Values: LOGIN, CREATE, DELETE'
            config_operation_types: '- (Optional) Required for DATABASE type. The database event operation types to listen for. This must contain at least one value. Possible Values: INSERT, UPDATE, REPLACE, DELETE'
            config_project: '- (Optional) Optional for DATABASE type. A $project expression document that Realm uses to filter the fields that appear in change event objects.'
            config_providers: '- (Optional) Required for AUTHENTICATION type. A list of one or more authentication provider id values. The trigger will only listen for authentication events produced by these providers.'
            config_schedule: '- (Optional) Required for SCHEDULED type. A cron expression that defines the trigger schedule.'
            config_service_id: '- (Optional) Required for DATABASE type. The ID of the MongoDB Service associated with the trigger.'
            disabled: '- (Optional) Default: false If true, the trigger is disabled.'
            event_processors: '- (Optional) An object where each field name is an event processor ID and each value is an object that configures its corresponding event processor. The following event processors are supported: AWS_EVENTBRIDGE For an example configuration object, see Send Trigger Events to AWS EventBridge.'
            event_processors.0.aws_eventbridge.config_account_id: '- (Optional) AWS Account ID.'
            event_processors.0.aws_eventbridge.config_region: '- (Optional) Region of AWS Account.'
            function_id: '- (Optional) The ID of the function associated with the trigger.'
            function_name: '- The name of the function associated with the trigger.'
            id: '- Terraform''s unique identifier used internally for state management.'
            name: '- (Required) The name of the trigger.'
            project_id: '- (Required) The unique ID for the project to create the trigger.'
            trigger_id: '- The unique ID of the trigger.'
            type: '- (Required) The type of the trigger. Possible Values: DATABASE, AUTHENTICATION,SCHEDULED'
            unordered: '- Only Available for Database Triggers. If true, event ordering is disabled and this trigger can process events in parallel. If false, event ordering is enabled and the trigger executes serially.'
        importStatements: []
    mongodbatlas_federated_database_instance:
        subCategory: ""
        description: Provides a Federated Database Instance resource.
        name: mongodbatlas_federated_database_instance
        title: federated_database_instance
        examples:
            - name: test
              manifest: |-
                {
                  "name": "TENANT NAME OF THE FEDERATED DATABASE INSTANCE",
                  "project_id": "PROJECT ID",
                  "storage_databases": [
                    {
                      "collections": [
                        {
                          "data_sources": [
                            {
                              "collection": "COLLECTION IN THE CLUSTER",
                              "database": "DB IN THE CLUSTER",
                              "store_name": "CLUSTER NAME"
                            }
                          ],
                          "name": "NAME OF THE COLLECTION"
                        }
                      ],
                      "name": "VirtualDatabase0"
                    }
                  ],
                  "storage_stores": [
                    {
                      "cluster_name": "CLUSTER NAME",
                      "name": "STORE 1 NAME",
                      "project_id": "PROJECT ID",
                      "provider": "atlas",
                      "read_preference": [
                        {
                          "mode": "secondary"
                        }
                      ]
                    }
                  ]
                }
            - name: test
              manifest: |-
                {
                  "cloud_provider_config": [
                    {
                      "aws": [
                        {
                          "role_id": "AWS ROLE ID",
                          "test_s3_bucket": "S3 BUCKET NAME"
                        }
                      ]
                    }
                  ],
                  "name": "TENANT NAME OF THE FEDERATED DATABASE INSTANCE",
                  "project_id": "PROJECT ID",
                  "storage_databases": [
                    {
                      "collections": [
                        {
                          "data_sources": [
                            {
                              "collection": "COLLECTION IN THE CLUSTER",
                              "database": "DB IN THE CLUSTER",
                              "store_name": "CLUSTER NAME"
                            },
                            {
                              "path": "S3 BUCKET PATH",
                              "store_name": "S3 BUCKET NAME"
                            }
                          ],
                          "name": "NAME OF THE COLLECTION"
                        }
                      ],
                      "name": "VirtualDatabase0"
                    }
                  ],
                  "storage_stores": [
                    {
                      "cluster_name": "CLUSTER NAME",
                      "name": "STORE 1 NAME",
                      "project_id": "PROJECT ID",
                      "provider": "atlas",
                      "read_preference": [
                        {
                          "mode": "secondary"
                        }
                      ]
                    },
                    {
                      "bucket": "STORE 2 NAME",
                      "delimiter": "/",
                      "name": "S3 BUCKET NAME",
                      "prefix": "S3 BUCKET PREFIX",
                      "provider": "s3",
                      "region": "AWS REGION"
                    }
                  ]
                }
        argumentDocs:
            ACTIVE: '- The Federated Database Instance is active and verified. You can query the data stores associated with the Federated Database Instance.'
            DELETED: '- The Federated Database Instance was deleted.'
            cloud_provider: '- (Required) Name of the cloud service provider. Atlas Federated Database only supports AWS.'
            external_id: '- Unique identifier associated with the IAM Role that the Federated Database Instance assumes when accessing the data stores.'
            hostnames: '- The list of hostnames assigned to the Federated Database Instance. Each string in the array is a hostname assigned to the Federated Database Instance.'
            iam_assumed_role_arn: '- Amazon Resource Name (ARN) of the IAM Role that the Federated Database Instance assumes when accessing S3 Bucket data stores. The IAM Role must support the following actions against each S3 bucket:'
            iam_user_arn: '- Amazon Resource Name (ARN) of the user that the Federated Database Instance assumes when accessing S3 Bucket data stores.'
            id: '- The Terraform''s unique identifier used internally for state management.'
            name: |-
                - (Required) Name of the Atlas Federated Database Instance.
                cloud_provider_config - (Optional) Cloud provider linked to this data federated instance.
                aws - (Required) AWS provider of the cloud service where the Federated Database Instance can access the S3 Bucket. Note this parameter is only required if using cloud_provider_config since AWS is currently the only supported Cloud vendor on this feature at this time.


                data_process_region - (Optional) The cloud provider region to which the Federated Instance routes client connections for data processing.
            project_id: '- (Required) The unique ID for the project to create a Federated Database Instance.'
            region: '- (Required) Name of the region to which the Federanted Instnace routes client connections for data processing. See the documention for the available region.'
            role_id: '- (Required) Unique identifier of the role that the Federated Instance can use to access the data stores. If necessary, use the Atlas UI or API to retrieve the role ID. You must also specify the test_s3_bucket.'
            state: '- Current state of the Federated Database Instance:'
            storage_databases: '- Configuration details for mapping each data store to queryable databases and collections. For complete documentation on this object and its nested fields, see databases. An empty object indicates that the Federated Database Instance has no mapping configuration for any data store.'
            storage_databases.#.collections: '-     Array of objects where each object represents a collection and data sources that map to a stores data store.'
            storage_databases.#.collections.#.data_sources: '-     Array of objects where each object represents a stores data store to map with the collection.'
            storage_databases.#.collections.#.data_sources.#.allow_insecure: '- Flag that validates the scheme in the specified URLs. If true, allows insecure HTTP scheme, doesn''t verify the server''s certificate chain and hostname, and accepts any certificate with any hostname presented by the server. If false, allows secure HTTPS scheme only.'
            storage_databases.#.collections.#.data_sources.#.collection: '- Human-readable label that identifies the collection in the database.'
            storage_databases.#.collections.#.data_sources.#.collection_regex: '- Regex pattern to use for creating the wildcard (*) collection.'
            storage_databases.#.collections.#.data_sources.#.database: '- Human-readable label that identifies the database, which contains the collection in the cluster.'
            storage_databases.#.collections.#.data_sources.#.database_regex: '- Regex pattern to use for creating the wildcard database.'
            storage_databases.#.collections.#.data_sources.#.dataset_name: '-     Human-readable label that identifies the dataset that Atlas generates for an ingestion pipeline run or Online Archive.'
            storage_databases.#.collections.#.data_sources.#.default_format: '- Default format that Federated Database assumes if it encounters a file without an extension while searching the storeName.'
            storage_databases.#.collections.#.data_sources.#.path: '- File path that controls how MongoDB Cloud searches for and parses files in the storeName before mapping them to a collection. Specify / to capture all files and folders from the prefix path.'
            storage_databases.#.collections.#.data_sources.#.provenance_field_name: '- Name for the field that includes the provenance of the documents in the results.'
            storage_databases.#.collections.#.data_sources.#.store_name: '-     Name of a data store to map to the <collection>. Must match the name of an object in the stores array.'
            storage_databases.#.collections.#.data_sources.#.storeName: '- Human-readable label that identifies the data store that MongoDB Cloud maps to the collection.'
            storage_databases.#.collections.#.data_sources.#.urls: '- URLs of the publicly accessible data files. You can''t specify URLs that require authentication.'
            storage_databases.#.collections.#.name: '- Name of the collection.'
            storage_databases.#.name: '- Name of the database to which the Federated Database Instance maps the data contained in the data store.'
            storage_databases.#.views: '-     Array of objects where each object represents an aggregation pipeline on a collection. To learn more about views, see Views.'
            storage_databases.#.views.#.name: '- Name of the view.'
            storage_databases.#.views.#.pipeline: '- Aggregation pipeline stage(s) to apply to the source collection.'
            storage_databases.#.views.#.source: '-  Name of the source collection for the view.'
            storage_stores: '- Each object in the array represents a data store. Federated Database uses the storage.databases configuration details to map data in each data store to queryable databases and collections. For complete documentation on this object and its nested fields, see stores. An empty object indicates that the Federated Database Instance has no configured data stores.'
            storage_stores.#.allow_insecure: '- Flag that validates the scheme in the specified URLs.'
            storage_stores.#.bucket: '- Name of the AWS S3 bucket.'
            storage_stores.#.cluster_id: '- ID of the Cluster the Online Archive belongs to.'
            storage_stores.#.cluster_name: '- Human-readable label of the MongoDB Cloud cluster on which the store is based.'
            storage_stores.#.default_format: '- Default format that Data Lake assumes if it encounters a file without an extension while searching the storeName.'
            storage_stores.#.delimiter: '- The delimiter that separates storage_databases.#.collections.#.data_sources.#.path segments in the data store.'
            storage_stores.#.include_tags: '- Determines whether or not to use S3 tags on the files in the given path as additional partition attributes.'
            storage_stores.#.name: '- Name of the data store.'
            storage_stores.#.prefix: '- Prefix the Federated Database Instance applies when searching for files in the S3 bucket.'
            storage_stores.#.provider: '- Defines where the data is stored.'
            storage_stores.#.public: '- Flag that indicates whether the bucket is public.'
            storage_stores.#.read_preference: '- MongoDB Cloud cluster read preference, which describes how to route read requests to the cluster.'
            storage_stores.#.read_preference.maxStalenessSeconds: '- Maximum replication lag, or staleness, for reads from secondaries.'
            storage_stores.#.read_preference.mode: '- Read preference mode that specifies to which replica set member to route the read requests.'
            storage_stores.#.read_preference.tag_sets: '- List that contains tag sets or tag specification documents.'
            storage_stores.#.read_preference.tags: '- List of all tags within a tag set'
            storage_stores.#.read_preference.tags.name: '- Human-readable label of the tag.'
            storage_stores.#.read_preference.tags.value: '- Value of the tag.'
            storage_stores.#.region: '- Name of the AWS region in which the S3 bucket is hosted.'
            storage_stores.#.urls: '- Comma-separated list of publicly accessible HTTP URLs where data is stored.'
            test_s3_bucket: '- (Required) Name of the S3 data bucket that the provided role ID is authorized to access. You must also specify the role_id.'
        importStatements: []
    mongodbatlas_federated_settings_identity_provider:
        subCategory: ""
        description: Provides a federated settings Identity Provider resource.
        name: mongodbatlas_federated_settings_identity_provider
        title: mongodbatlas_federated_settings_identity_provider
        examples:
            - name: identity_provider
              manifest: |-
                {
                  "associated_domains": [
                    "yourdomain.com"
                  ],
                  "federation_settings_id": "627a9687f7f7f7f774de306f14",
                  "issuer_uri": "http://www.okta.com/exk17q7f7f7f7fp50h8",
                  "name": "mongodb_federation_test",
                  "request_binding": "HTTP-POST",
                  "response_signature_algorithm": "SHA-256",
                  "sso_debug_enabled": true,
                  "sso_url": "https://mysso.oktapreview.com/app/mysso_terraformtestsso/exk17q7f7f7f7f50h8/sso/saml",
                  "status": "ACTIVE"
                }
        argumentDocs:
            associated_domains: '- (Required) List that contains the domains associated with the identity provider.'
            federation_settings_id: '- (Required) Unique 24-hexadecimal digit string that identifies the federated authentication configuration.'
            issuer_uri: '- (Required) Unique string that identifies the issuer of the SAML'
            name: '- (Required) Human-readable label that identifies the identity provider.'
            okta_idp_id: '- Unique 20-hexadecimal digit string that identifies the IdP.'
            request_binding: '- (Required) SAML Authentication Request Protocol HTTP method binding (POST or REDIRECT) that Federated Authentication uses to send the authentication request. Atlas supports the following binding values:'
            response_signature_algorithm: '- (Required) Signature algorithm that Federated Authentication uses to encrypt the identity provider signature.  Valid values include SHA-1 and SHA-256.'
            sso_debug_enabled: '- (Required) Flag that indicates whether the identity provider has SSO debug enabled.'
            sso_url: '- (Required) Unique string that identifies the intended audience of the SAML assertion.'
            status: '- (Required) String enum that indicates whether the identity provider is active or not. Accepted values are ACTIVE or INACTIVE.'
        importStatements: []
    mongodbatlas_federated_settings_org_config:
        subCategory: ""
        description: Provides a federated settings Organization Configuration.
        name: mongodbatlas_federated_settings_org_config
        title: mongodbatlas_federated_settings_org_config
        examples:
            - name: org_connection
              manifest: |-
                {
                  "domain_allow_list": [
                    "mydomain.com"
                  ],
                  "domain_restriction_enabled": false,
                  "federation_settings_id": "627a9687f7f7f7f774de306f14",
                  "identity_provider_id": "0oad4fas87jL7f75Xnk1297",
                  "org_id": "627a9683ea7ff7f74de306f14",
                  "post_auth_role_grants": [
                    "ORG_MEMBER"
                  ]
                }
        argumentDocs:
            domain_allow_list: '- List that contains the approved domains from which organization users can log in.'
            domain_restriction_enabled: '- (Required) Flag that indicates whether domain restriction is enabled for the connected organization.'
            federation_settings_id: '- (Required) Unique 24-hexadecimal digit string that identifies the federated authentication configuration.'
            identity_provider_id: '- (Required) Unique 24-hexadecimal digit string that identifies the federated authentication configuration.'
            org_id: '- (Required) Unique 24-hexadecimal digit string that identifies the organization that contains your projects.'
            post_auth_role_grants: '- (Optional) List that contains the default roles granted to users who authenticate through the IdP in a connected organization.'
        importStatements: []
    mongodbatlas_federated_settings_org_role_mapping:
        subCategory: ""
        description: Provides a federated settings Role Mapping resource.
        name: mongodbatlas_federated_settings_org_role_mapping
        title: mongodbatlas_federated_settings_org_role_mapping
        examples:
            - name: org_group_role_mapping_import
              manifest: |-
                {
                  "external_group_name": "myGrouptest",
                  "federation_settings_id": "627a9687f7f7f7f774de306f14",
                  "org_id": "627a9683e7f7f7ff7fe306f14",
                  "role_assignments": [
                    {
                      "org_id": "627a9683e7f7f7ff7fe306f14",
                      "roles": [
                        "ORG_MEMBER",
                        "ORG_GROUP_CREATOR",
                        "ORG_BILLING_ADMIN"
                      ]
                    },
                    {
                      "group_id": "628aa20d7f7f7f7f7098b81b8",
                      "roles": [
                        "GROUP_OWNER",
                        "GROUP_DATA_ACCESS_ADMIN",
                        "GROUP_SEARCH_INDEX_EDITOR",
                        "GROUP_DATA_ACCESS_READ_ONLY"
                      ]
                    },
                    {
                      "group_id": "628aa20d7f7f7f7f7078b81b8",
                      "roles": [
                        "GROUP_OWNER",
                        "GROUP_DATA_ACCESS_ADMIN",
                        "GROUP_SEARCH_INDEX_EDITOR",
                        "GROUP_DATA_ACCESS_READ_ONLY",
                        "GROUP_DATA_ACCESS_READ_WRITE"
                      ]
                    }
                  ]
                }
        argumentDocs:
            external_group_name: '- Unique human-readable label that identifies the identity provider group to which this role mapping applies.'
            federation_settings_id: '- (Required) Unique 24-hexadecimal digit string that identifies the federated authentication configuration.'
            group_id: '- Unique identifier of the project to which you want the role mapping to apply.'
            id: '- Unique 24-hexadecimal digit string that identifies this role mapping.'
            org_id: '- Unique 24-hexadecimal digit string that identifies the organization that contains your projects.'
            role_assignments: '- Atlas roles and the unique identifiers of the groups and organizations associated with each role.'
            roles: |-
                - Specifies the Roles that are attached to the Role Mapping. Available role IDs can be found on the User Roles
                Reference.
        importStatements: []
    mongodbatlas_global_cluster_config:
        subCategory: ""
        description: Provides a Global Cluster Configuration resource.
        name: mongodbatlas_global_cluster_config
        title: global_cluster_config
        examples:
            - name: config
              manifest: |-
                {
                  "cluster_name": "${mongodbatlas_cluster.test.name}",
                  "custom_zone_mappings": [
                    {
                      "location": "CA",
                      "zone": "Zone 1"
                    }
                  ],
                  "managed_namespaces": [
                    {
                      "collection": "publishers",
                      "custom_shard_key": "city",
                      "db": "mydata",
                      "is_custom_shard_key_hashed": false,
                      "is_shard_key_unique": false
                    }
                  ],
                  "project_id": "${mongodbatlas_cluster.test.project_id}"
                }
              references:
                cluster_name: mongodbatlas_cluster.test.name
                project_id: mongodbatlas_cluster.test.project_id
              dependencies:
                mongodbatlas_cluster.test: |-
                    {
                      "cloud_backup": true,
                      "cluster_type": "GEOSHARDED",
                      "name": "\u003cCLUSTER-NAME\u003e",
                      "project_id": "\u003cYOUR-PROJECT-ID\u003e",
                      "provider_instance_size_name": "M30",
                      "provider_name": "AWS",
                      "replication_specs": [
                        {
                          "num_shards": 1,
                          "regions_config": [
                            {
                              "electable_nodes": 3,
                              "priority": 7,
                              "read_only_nodes": 0,
                              "region_name": "EU_CENTRAL_1"
                            }
                          ],
                          "zone_name": "Zone 1"
                        },
                        {
                          "num_shards": 1,
                          "regions_config": [
                            {
                              "electable_nodes": 3,
                              "priority": 7,
                              "read_only_nodes": 0,
                              "region_name": "US_EAST_2"
                            }
                          ],
                          "zone_name": "Zone 2"
                        }
                      ]
                    }
            - name: config
              manifest: |-
                {
                  "cluster_name": "${mongodbatlas_cluster.test.name}",
                  "custom_zone_mappings": [
                    {
                      "location": "CA",
                      "zone": "Zone 1"
                    }
                  ],
                  "managed_namespaces": [
                    {
                      "collection": "publishers",
                      "custom_shard_key": "city",
                      "db": "mydata"
                    }
                  ],
                  "project_id": "${mongodbatlas_cluster.test.project_id}"
                }
              references:
                cluster_name: mongodbatlas_cluster.test.name
                project_id: mongodbatlas_cluster.test.project_id
              dependencies:
                mongodbatlas_cluster.cluster-test: |-
                    {
                      "auto_scaling_disk_gb_enabled": true,
                      "backup_enabled": true,
                      "cluster_type": "REPLICASET",
                      "mongo_db_major_version": "4.0",
                      "name": "cluster-test",
                      "project_id": "\u003cYOUR-PROJECT-ID\u003e",
                      "provider_instance_size_name": "M40",
                      "provider_name": "AWS",
                      "replication_specs": [
                        {
                          "num_shards": 1,
                          "regions_config": [
                            {
                              "electable_nodes": 3,
                              "priority": 7,
                              "read_only_nodes": 0,
                              "region_name": "US_EAST_1"
                            }
                          ]
                        }
                      ]
                    }
        argumentDocs:
            cluster_name: '- (Required) The name of the Global Cluster.'
            collection: "-\t(Required) The name of the collection associated with the managed namespace."
            custom_shard_key: "- (Required)\tThe custom shard key for the collection. Global Clusters require a compound shard key consisting of a location field and a user-selected second key, the custom shard key."
            custom_zone_mapping: '- A map of all custom zone mappings defined for the Global Cluster. Atlas automatically maps each location code to the closest geographical zone. Custom zone mappings allow administrators to override these automatic mappings. If your Global Cluster does not have any custom zone mappings, this document is empty.'
            custom_zone_mappings: '- (Optional) Each element in the list maps one ISO location code to a zone in your Global Cluster. See Custom Zone Mapping below for more details.'
            db: '- (Required) The name of the database containing the collection.'
            id: '- The Terraform''s unique identifier used internally for state management.'
            is_custom_shard_key_hashed: '- (Optional) Specifies whether the custom shard key for the collection is hashed. If omitted, defaults to false. If false, Atlas uses ranged sharding. This is only available for Atlas clusters with MongoDB v4.4 and later.'
            is_shard_key_unique: '- (Optional) Specifies whether the underlying index enforces a unique constraint. If omitted, defaults to false. You cannot specify true when using hashed shard keys.'
            location: '- (Required) The ISO location code to which you want to map a zone in your Global Cluster. You can find a list of all supported location codes here.'
            managed_namespaces: '- (Optional) Add a managed namespaces to a Global Cluster. For more information about managed namespaces, see Global Clusters. See Managed Namespace below for more details.'
            project_id: '- (Required) The unique ID for the project to create the database user.'
            zone: '- (Required) The name of the zone in your Global Cluster that you want to map to location.'
        importStatements: []
    mongodbatlas_maintenance_window:
        subCategory: ""
        description: Provides an Maintenance Window resource.
        name: mongodbatlas_maintenance_window
        title: maintenance_window
        examples:
            - name: test
              manifest: |-
                {
                  "day_of_week": 3,
                  "hour_of_day": 4,
                  "project_id": "\u003cyour-project-id\u003e"
                }
            - name: test
              manifest: |-
                {
                  "defer": true,
                  "project_id": "\u003cyour-project-id\u003e"
                }
        argumentDocs:
            auto_defer: '- Defer any scheduled maintenance for the given project for one week.'
            auto_defer_once_enabled: '- Flag that indicates whether you want to defer all maintenance windows one week they would be triggered.'
            day_of_week: '- Day of the week when you would like the maintenance window to start as a 1-based integer: S=1, M=2, T=3, W=4, T=5, F=6, S=7.'
            defer: '- Defer the next scheduled maintenance for the given project for one week.'
            hour_of_day: '- Hour of the day when you would like the maintenance window to start. This parameter uses the 24-hour clock, where midnight is 0, noon is 12 (Time zone is UTC).'
            number_of_deferrals: '- Number of times the current maintenance event for this project has been deferred, you can set a maximum of 2 deferrals.'
            project_id: '- The unique identifier of the project for the Maintenance Window.'
            start_asap: '- Flag indicating whether project maintenance has been directed to start immediately. If you request that maintenance begin immediately, this field returns true from the time the request was made until the time the maintenance event completes.'
        importStatements: []
    mongodbatlas_network_container:
        subCategory: ""
        description: Provides a Network Peering resource.
        name: mongodbatlas_network_container
        title: network_container
        examples:
            - name: test
              manifest: |-
                {
                  "atlas_cidr_block": "10.8.0.0/21",
                  "project_id": "\u003cYOUR-PROJECT-ID\u003e",
                  "provider_name": "AWS",
                  "region_name": "US_EAST_1"
                }
            - name: test
              manifest: |-
                {
                  "atlas_cidr_block": "10.8.0.0/21",
                  "project_id": "\u003cYOUR-PROJECT-ID\u003e",
                  "provider_name": "GCP",
                  "regions": [
                    "US_EAST_4",
                    "US_WEST_3"
                  ]
                }
            - name: test
              manifest: |-
                {
                  "atlas_cidr_block": "10.8.0.0/21",
                  "project_id": "\u003cYOUR-PROJECT-ID\u003e",
                  "provider_name": "AZURE",
                  "region": "US_EAST_2"
                }
        argumentDocs:
            atlas_cidr_block: '- (Required) CIDR block that Atlas uses for the Network Peering containers in your project.  Atlas uses the specified CIDR block for all other Network Peering connections created in the project. The Atlas CIDR block must be at least a /24 and at most a /21 in one of the following private networks:'
            azure_subscription_id: '- Unique identifier of the Azure subscription in which the VNet resides.'
            container_id: '- The Network Peering Container ID.'
            gcp_project_id: '- Unique identifier of the GCP project in which the network peer resides. Returns null. This value is populated once you create a new network peering connection with the network peering resource.'
            id: '- Terraform''s unique identifier used internally for state management.'
            network_name: '- Unique identifier of the Network Peering connection in the Atlas project. Returns null. This value is populated once you create a new network peering connection with the network peering resource.'
            project_id: '- (Required) Unique identifier for the Atlas project for this Network Peering Container.'
            provider_name: '- (Required GCP and AZURE, Optional but recommended for AWS) Cloud provider for this Network Peering connection.  Accepted values are GCP, AWS, AZURE. If omitted, Atlas sets this parameter to AWS.'
            provisioned: '- Indicates whether the project has Network Peering connections deployed in the container.'
            region: '- (Required AZURE only) Atlas region where the container resides, see the reference list for Atlas Azure region names Azure.'
            region_name: '- (Required AWS only) The Atlas AWS region name for where this container will exist, see the reference list for Atlas AWS region names AWS.'
            regions: '- (Optional GCP only) Atlas regions where the container resides. Provide this field only if you provide an atlas_cidr_block smaller than /18. GCP Regions values.'
            vnet_name: "- \tThe name of the Azure VNet. Returns null. This value is populated once you create a new network peering connection with the network peering resource."
            vpc_id: '- Unique identifier of Atlas'' AWS VPC.'
        importStatements: []
    mongodbatlas_network_peering:
        subCategory: ""
        description: Provides a Network Peering resource.
        name: mongodbatlas_network_peering
        title: network_peering
        examples:
            - name: test
              manifest: |-
                {
                  "accepter_region_name": "us-east-1",
                  "aws_account_id": "abc123abc123",
                  "container_id": "507f1f77bcf86cd799439011",
                  "project_id": "${local.project_id}",
                  "provider_name": "AWS",
                  "route_table_cidr_block": "192.168.0.0/24",
                  "vpc_id": "vpc-abc123abc123"
                }
              references:
                project_id: local.project_id
              dependencies:
                aws_vpc_peering_connection_accepter.peer: |-
                    {
                      "auto_accept": true,
                      "vpc_peering_connection_id": "${mongodbatlas_network_peering.test.connection_id}"
                    }
                mongodbatlas_network_container.test: |-
                    {
                      "atlas_cidr_block": "10.8.0.0/21",
                      "project_id": "${local.project_id}",
                      "provider_name": "AWS",
                      "region_name": "US_EAST_1"
                    }
            - name: test
              manifest: |-
                {
                  "container_id": "${mongodbatlas_network_container.test.container_id}",
                  "gcp_project_id": "${local.GCP_PROJECT_ID}",
                  "network_name": "default",
                  "project_id": "${local.project_id}",
                  "provider_name": "GCP"
                }
              references:
                container_id: mongodbatlas_network_container.test.container_id
                gcp_project_id: local.GCP_PROJECT_ID
                project_id: local.project_id
              dependencies:
                google_compute_network_peering.peering: |-
                    {
                      "name": "peering-gcp-terraform-test",
                      "network": "${data.google_compute_network.default.self_link}",
                      "peer_network": "https://www.googleapis.com/compute/v1/projects/${mongodbatlas_network_peering.test.atlas_gcp_project_id}/global/networks/${mongodbatlas_network_peering.test.atlas_vpc_name}"
                    }
                mongodbatlas_cluster.test: |-
                    {
                      "auto_scaling_disk_gb_enabled": true,
                      "cluster_type": "REPLICASET",
                      "depends_on": [
                        "google_compute_network_peering.peering"
                      ],
                      "mongo_db_major_version": "4.2",
                      "name": "terraform-manually-test",
                      "num_shards": 1,
                      "project_id": "${local.project_id}",
                      "provider_instance_size_name": "M10",
                      "provider_name": "GCP",
                      "replication_specs": [
                        {
                          "num_shards": 1,
                          "regions_config": [
                            {
                              "electable_nodes": 3,
                              "priority": 7,
                              "read_only_nodes": 0,
                              "region_name": "US_EAST_4"
                            }
                          ]
                        }
                      ]
                    }
                mongodbatlas_network_container.test: |-
                    {
                      "atlas_cidr_block": "10.8.0.0/21",
                      "project_id": "${local.project_id}",
                      "provider_name": "GCP"
                    }
            - name: test
              manifest: |-
                {
                  "azure_directory_id": "${local.AZURE_DIRECTORY_ID}",
                  "azure_subscription_id": "${local.AZURE_SUBSCRIPTION_ID}",
                  "container_id": "${mongodbatlas_network_container.test.container_id}",
                  "project_id": "${local.project_id}",
                  "provider_name": "AZURE",
                  "resource_group_name": "${local.AZURE_RESOURCES_GROUP_NAME}",
                  "vnet_name": "${local.AZURE_VNET_NAME}"
                }
              references:
                azure_directory_id: local.AZURE_DIRECTORY_ID
                azure_subscription_id: local.AZURE_SUBSCRIPTION_ID
                container_id: mongodbatlas_network_container.test.container_id
                project_id: local.project_id
                resource_group_name: local.AZURE_RESOURCES_GROUP_NAME
                vnet_name: local.AZURE_VNET_NAME
              dependencies:
                mongodbatlas_cluster.test: |-
                    {
                      "auto_scaling_disk_gb_enabled": true,
                      "cluster_type": "REPLICASET",
                      "depends_on": [
                        "mongodbatlas_network_peering.test"
                      ],
                      "mongo_db_major_version": "4.2",
                      "name": "terraform-manually-test",
                      "project_id": "${local.project_id}",
                      "provider_disk_type_name": "P4",
                      "provider_instance_size_name": "M10",
                      "provider_name": "AZURE",
                      "replication_specs": [
                        {
                          "num_shards": 1,
                          "regions_config": [
                            {
                              "electable_nodes": 3,
                              "priority": 7,
                              "read_only_nodes": 0,
                              "region_name": "US_EAST_2"
                            }
                          ]
                        }
                      ]
                    }
                mongodbatlas_network_container.test: |-
                    {
                      "atlas_cidr_block": "${local.ATLAS_CIDR_BLOCK}",
                      "project_id": "${local.project_id}",
                      "provider_name": "AZURE",
                      "region": "US_EAST_2"
                    }
            - name: mongo_peer
              manifest: |-
                {
                  "accepter_region_name": "us-east-2",
                  "aws_account_id": "${local.AWS_ACCOUNT_ID}",
                  "container_id": "${mongodbatlas_cluster.test.container_id}",
                  "project_id": "${local.project_id}",
                  "provider_name": "AWS",
                  "route_table_cidr_block": "172.31.0.0/16",
                  "vpc_id": "${aws_default_vpc.default.id}"
                }
              references:
                aws_account_id: local.AWS_ACCOUNT_ID
                container_id: mongodbatlas_cluster.test.container_id
                project_id: local.project_id
                vpc_id: aws_default_vpc.default.id
              dependencies:
                aws_default_vpc.default: |-
                    {
                      "tags": {
                        "Name": "Default VPC"
                      }
                    }
                aws_vpc_peering_connection_accepter.aws_peer: |-
                    {
                      "auto_accept": true,
                      "tags": {
                        "Side": "Accepter"
                      },
                      "vpc_peering_connection_id": "${mongodbatlas_network_peering.mongo_peer.connection_id}"
                    }
                mongodbatlas_cluster.test: |-
                    {
                      "auto_scaling_disk_gb_enabled": false,
                      "cluster_type": "REPLICASET",
                      "mongo_db_major_version": "4.2",
                      "name": "terraform-test",
                      "project_id": "${local.project_id}",
                      "provider_instance_size_name": "M10",
                      "provider_name": "AWS",
                      "replication_specs": [
                        {
                          "num_shards": 1,
                          "regions_config": [
                            {
                              "electable_nodes": 3,
                              "priority": 7,
                              "read_only_nodes": 0,
                              "region_name": "US_EAST_2"
                            }
                          ]
                        }
                      ]
                    }
            - name: test
              manifest: |-
                {
                  "atlas_cidr_block": "192.168.0.0/18",
                  "container_id": "${mongodbatlas_cluster.test.container_id}",
                  "gcp_project_id": "${local.GCP_PROJECT_ID}",
                  "network_name": "default",
                  "project_id": "${local.project_id}",
                  "provider_name": "GCP"
                }
              references:
                container_id: mongodbatlas_cluster.test.container_id
                gcp_project_id: local.GCP_PROJECT_ID
                project_id: local.project_id
              dependencies:
                google_compute_network_peering.peering: |-
                    {
                      "name": "peering-gcp-terraform-test",
                      "network": "${data.google_compute_network.default.self_link}",
                      "peer_network": "https://www.googleapis.com/compute/v1/projects/${mongodbatlas_network_peering.test.atlas_gcp_project_id}/global/networks/${mongodbatlas_network_peering.test.atlas_vpc_name}"
                    }
                mongodbatlas_cluster.test: |-
                    {
                      "auto_scaling_disk_gb_enabled": true,
                      "cluster_type": "REPLICASET",
                      "mongo_db_major_version": "4.2",
                      "name": "terraform-manually-test",
                      "project_id": "${local.project_id}",
                      "provider_instance_size_name": "M10",
                      "provider_name": "GCP",
                      "replication_specs": [
                        {
                          "num_shards": 1,
                          "regions_config": [
                            {
                              "electable_nodes": 3,
                              "priority": 7,
                              "read_only_nodes": 0,
                              "region_name": "US_EAST_2"
                            }
                          ]
                        }
                      ]
                    }
            - name: test
              manifest: |-
                {
                  "azure_directory_id": "${local.AZURE_DIRECTORY_ID}",
                  "azure_subscription_id": "${local.AZURE_SUBSCRIPTION_ID}",
                  "container_id": "${mongodbatlas_cluster.test.container_id}",
                  "project_id": "${local.project_id}",
                  "provider_name": "AZURE",
                  "resource_group_name": "${local.AZURE_RESOURCE_GROUP_NAME}",
                  "vnet_name": "${local.AZURE_VNET_NAME}"
                }
              references:
                azure_directory_id: local.AZURE_DIRECTORY_ID
                azure_subscription_id: local.AZURE_SUBSCRIPTION_ID
                container_id: mongodbatlas_cluster.test.container_id
                project_id: local.project_id
                resource_group_name: local.AZURE_RESOURCE_GROUP_NAME
                vnet_name: local.AZURE_VNET_NAME
              dependencies:
                mongodbatlas_cluster.test: |-
                    {
                      "auto_scaling_disk_gb_enabled": false,
                      "cluster_type": "REPLICASET",
                      "mongo_db_major_version": "4.2",
                      "name": "cluster-azure",
                      "project_id": "${local.project_id}",
                      "provider_instance_size_name": "M10",
                      "provider_name": "AZURE",
                      "replication_specs": [
                        {
                          "num_shards": 1,
                          "regions_config": [
                            {
                              "electable_nodes": 3,
                              "priority": 7,
                              "read_only_nodes": 0,
                              "region_name": "US_EAST_2"
                            }
                          ]
                        }
                      ]
                    }
        argumentDocs:
            accepter_region_name: '- (Required - AWS) Specifies the AWS region where the peer VPC resides. For complete lists of supported regions, see Amazon Web Services.'
            atlas_gcp_project_id: '- The Atlas GCP Project ID for the GCP VPC used by your atlas cluster that it is need to set up the reciprocal connection.'
            aws_account_id: '- (Required - AWS) AWS Account ID of the owner of the peer VPC.'
            azure_directory_id: '- (Required - AZURE) Unique identifier for an Azure AD directory.'
            azure_subscription_id: '- (Required - AZURE) Unique identifier of the Azure subscription in which the VNet resides.'
            connection_id: '-  Unique identifier of the Atlas network peering container.'
            container_id: '- (Required) Unique identifier of the MongoDB Atlas container for the provider (GCP) or provider/region (AWS, AZURE). You can create an MongoDB Atlas container using the network_container resource or it can be obtained from the cluster returned values if a cluster has been created before the first container.'
            error_message: '- When "status" : "FAILED", Atlas provides a description of the error.'
            error_state: '- Description of the Atlas error when status is Failed, Otherwise, Atlas returns null.'
            error_state_name: '- Error state, if any. The VPC peering connection error state value can be one of the following: REJECTED, EXPIRED, INVALID_ARGUMENT.'
            gcp_project_id: '- (Required - GCP) GCP project ID of the owner of the network peer.'
            id: '- Terraform''s unique identifier used internally for state management.'
            network_name: '- (Required - GCP) Name of the network peer to which Atlas connects.'
            peer_id: '- Unique identifier of the Atlas network peer.'
            project_id: '- (Required) The unique ID for the MongoDB Atlas project to create the database user.'
            provider_name: '- (Required) Cloud provider to whom the peering connection is being made. (Possible Values AWS, AZURE, GCP).'
            resource_group_name: '- (Required - AZURE) Name of your Azure resource group.'
            route_table_cidr_block: '- (Required - AWS) AWS VPC CIDR block or subnet.'
            status: '- Status of the Atlas network peering connection.  Azure/GCP: ADDING_PEER, AVAILABLE, FAILED, DELETING GCP Only:  WAITING_FOR_USER.'
            status_name: '- (AWS Only) The VPC peering connection status value can be one of the following: INITIATING, PENDING_ACCEPTANCE, FAILED, FINALIZING, AVAILABLE, TERMINATING.'
            vnet_name: '- (Required - AZURE) Name of your Azure VNet.'
            vpc_id: '- (Required) Unique identifier of the AWS peer VPC (Note: this is not the same as the Atlas AWS VPC that is returned by the network_container resource).'
        importStatements: []
    mongodbatlas_online_archive:
        subCategory: ""
        description: Provides a Online Archive resource for creation, update, and delete
        name: mongodbatlas_online_archive
        title: mongodbatlas_online_archive
        examples:
            - name: test
              manifest: |-
                {
                  "cluster_name": "${var.cluster_name}",
                  "coll_name": "${var.collection_name}",
                  "criteria": [
                    {
                      "date_field": "created",
                      "expire_after_days": 5,
                      "type": "DATE"
                    }
                  ],
                  "db_name": "${var.database_name}",
                  "partition_fields": [
                    {
                      "field_name": "firstName",
                      "order": 0
                    },
                    {
                      "field_name": "lastName",
                      "order": 1
                    }
                  ],
                  "project_id": "${var.project_id}",
                  "schedule": [
                    {
                      "end_hour": 1,
                      "end_minute": 1,
                      "start_hour": 1,
                      "start_minute": 1,
                      "type": "DAILY"
                    }
                  ]
                }
              references:
                cluster_name: var.cluster_name
                coll_name: var.collection_name
                db_name: var.database_name
                project_id: var.project_id
            - name: test
              manifest: |-
                {
                  "cluster_name": "${var.cluster_name}",
                  "coll_name": "${var.collection_name}",
                  "criteria": [
                    {
                      "query": "{ \"department\": \"engineering\" }",
                      "type": "CUSTOM"
                    }
                  ],
                  "db_name": "${var.database_name}",
                  "partition_fields": [
                    {
                      "field_name": "firstName",
                      "order": 0
                    },
                    {
                      "field_name": "secondName",
                      "order": 1
                    }
                  ],
                  "project_id": "${var.project_id}"
                }
              references:
                cluster_name: var.cluster_name
                coll_name: var.collection_name
                db_name: var.database_name
                project_id: var.project_id
        argumentDocs:
            DATE: is selected, the partition_fields.field_name must be completed with the date_field value
            archive_id: '- ID of the online archive.'
            cluster_name: '-  (Required) Name of the cluster that contains the collection.'
            coll_name: '-  (Required) Name of the collection.'
            collection_type: '-  Classification of MongoDB database collection that you want to return, "TIMESERIES" or "STANDARD". Default is "STANDARD".'
            criteria: '-  (Required) Criteria to use for archiving data.'
            date_field: '- Indexed database parameter that stores the date that determines when data moves to the online archive. MongoDB Cloud archives the data when the current date exceeds the date in this database parameter plus the number of days specified through the expireAfterDays parameter.'
            date_format: '- Syntax used to write the date after which data moves to the online archive. Date can be expressed as ISO 8601 or Epoch timestamps. The Epoch timestamp can be expressed as nanoseconds, milliseconds, or seconds. You must set type to DATE if collectionType is TIMESERIES. Valid values:  ISODATE (default), EPOCH_SECONDS, EPOCH_MILLIS, EPOCH_NANOSECONDS.'
            day_of_month: '- Day of the month when the scheduled archive starts. This field should be provided only when schedule type is MONTHLY.'
            day_of_week: '- Day of the week when the scheduled archive starts. The week starts with Monday (1) and ends with Sunday (7). This field should be provided only when schedule type is WEEKLY.'
            db_name: '-  (Required) Name of the database that contains the collection.'
            end_hour: '- Hour of the day when the scheduled window to run one online archive ends.'
            end_minute: '- Minute of the hour when the scheduled window to run one online archive ends.'
            expire_after_days: '- Number of days after the value in the criteria.dateField when MongoDB Cloud archives data in the specified cluster.'
            field_name: '- Human-readable label that identifies the parameter that MongoDB Cloud uses to partition data. To specify a nested parameter, use the dot notation.'
            field_type: '- Data type of the parameter that that MongoDB Cloud uses to partition data. Partition parameters of type UUID must be of binary subtype 4. MongoDB Cloud skips partition parameters of type UUID with subtype 3. Valid values: date, int, long, objectId, string, uuid.'
            order: '- Sequence in which MongoDB Cloud slices the collection data to create partitions. The resource expresses this sequence starting with zero. The value of the criteria.dateField parameter defaults as the first item in the partition sequence.'
            partition_fields: '-  (Recommended) Fields to use to partition data. You can specify up to two frequently queried fields to use for partitioning data. Note that queries that don’t contain the specified fields will require a full collection scan of all archived documents, which will take longer and increase your costs. To learn more about how partition improves query performance, see Data Structure in S3. The value of a partition field can be up to a maximum of 700 characters. Documents with values exceeding 700 characters are not archived.'
            paused: '- (Optional) State of the online archive. This is required for pausing an active or resume a paused online archive. The resume request will fail if the collection has another active online archive.'
            project_id: '-  (Required) The unique ID for the project'
            query: '- JSON query to use to select documents for archiving. Atlas uses the specified query with the db.collection.find(query) command. The empty document {} to return all documents is not supported.'
            start_hour: '- Hour of the day when the when the scheduled window to run one online archive starts.'
            start_minute: '- Minute of the hour when the scheduled window to run one online archive starts.'
            state: '- Status of the online archive. Valid values are: Pending, Archiving, Idle, Pausing, Paused, Orphaned and Deleted'
            type: '- Type of criteria (DATE, CUSTOM)'
        importStatements: []
    mongodbatlas_org_invitation:
        subCategory: ""
        description: Provides an Atlas Organization Invitation resource.
        name: mongodbatlas_org_invitation
        title: org_invitation
        examples:
            - name: test0
              manifest: |-
                {
                  "org_id": "\u003cORG-ID\u003e",
                  "roles": [
                    "ORG_OWNER"
                  ],
                  "username": "test0-acc-username"
                }
            - name: test0
              manifest: |-
                {
                  "org_id": "\u003cORG-ID\u003e",
                  "roles": [
                    "ORG_MEMBER",
                    "ORG_BILLING_ADMIN"
                  ],
                  "username": "test0-acc-username"
                }
            - name: test1
              manifest: |-
                {
                  "org_id": "\u003cORG-ID\u003e",
                  "roles": [
                    "ORG_MEMBER"
                  ],
                  "teams_ids": [
                    "\u003cTEAM-0-ID\u003e",
                    "\u003cTEAM-1-ID\u003e"
                  ],
                  "username": "test1-acc-username"
                }
        argumentDocs:
            created_at: '- Timestamp in ISO 8601 date and time format in UTC when Atlas sent the invitation.'
            expires_at: '- Timestamp in ISO 8601 date and time format in UTC when the invitation expires. Users have 30 days to accept an invitation.'
            id: '- Autogenerated unique string that identifies this resource.'
            invitation_id: '- Unique 24-hexadecimal digit string that identifies the invitation in Atlas.'
            inviter_username: '- Atlas user who invited username to the organization.'
            org_id: '- (Required) Unique 24-hexadecimal digit string that identifies the organization to which you want to invite a user.'
            roles: '- (Required) Atlas roles to assign to the invited user. If the user accepts the invitation, Atlas assigns these roles to them. The MongoDB Documentation describes the roles a user can have.'
            teams_ids: '- (Optional) An array of unique 24-hexadecimal digit strings that identify the teams that the user was invited to join.'
            username: '- (Required) Email address of the invited user. This is the address to which Atlas sends the invite. If the user accepts the invitation, they log in to Atlas with this username.'
        importStatements: []
    mongodbatlas_organization:
        subCategory: ""
        description: Provides a Organization resource.
        name: mongodbatlas_organization
        title: organization
        examples:
            - name: test
              manifest: |-
                {
                  "description": "test API key from Org Creation Test",
                  "name": "testCreateORG",
                  "org_owner_id": "6205e5fffff79cde6f",
                  "role_names": [
                    "ORG_OWNER"
                  ]
                }
        argumentDocs:
            description: '- Programmatic API Key description'
            federation_settings_id: '- (Optional) Unique 24-hexadecimal digit string that identifies the federation to link the newly created organization to. If specified, the proposed Organization Owner of the new organization must have the Organization Owner role in an organization associated with the federation.'
            isDeleted: '- (computed) Flag that indicates whether this organization has been deleted.'
            name: '- (Required) The name of the organization you want to create. (Cannot be changed via this Provider after creation.)'
            org_id: '- The organization id.'
            org_owner_id: '- (Required) Unique 24-hexadecimal digit string that identifies the Atlas user that you want to assign the Organization Owner role. This user must be a member of the same organization as the calling API key.  This is only required when authenticating with Programmatic API Keys. MongoDB Atlas Admin API - Get User By Username'
            private_key: '- Redacted private key returned for this organization API key. This key displays unredacted when first created and is saved within the Terraform state file.'
            public_key: '- Public API key value set for the specified organization API key.'
            role_names: '- (Required) List of Organization roles that the Programmatic API key needs to have. Ensure that you provide at least one role and ensure all roles are valid for the Organization.  You must specify an array even if you are only associating a single role with the Programmatic API key. The MongoDB Documentation describes the roles that you can assign to a Programmatic API key.'
        importStatements: []
    mongodbatlas_private_endpoint_regional_mode:
        subCategory: ""
        description: Provides a Private Endpoint Regional Mode resource
        name: mongodbatlas_private_endpoint_regional_mode
        title: private_endpoint_regional_mode
        examples:
            - name: test
              manifest: |-
                {
                  "enabled": true,
                  "project_id": "${var.atlasprojectid}"
                }
              references:
                project_id: var.atlasprojectid
              dependencies:
                aws_vpc_endpoint.test_west: |-
                    {
                      "provider": "${aws.west}",
                      "security_group_ids": [
                        "sg-3f238186"
                      ],
                      "service_name": "${mongodbatlas_privatelink_endpoint.test_west.endpoint_service_name}",
                      "subnet_ids": [
                        "subnet-de0406d2"
                      ],
                      "vpc_endpoint_type": "Interface",
                      "vpc_id": "vpc-7fc0a543"
                    }
                mongodbatlas_cluster.cluster-atlas: |-
                    {
                      "auto_scaling_disk_gb_enabled": true,
                      "cloud_backup": true,
                      "cluster_type": "GEOSHARDED",
                      "depends_on": [
                        "${mongodbatlas_privatelink_endpoint_service.test_west}",
                        "${mongodbatlas_privatelink_endpoint_service.test_east}",
                        "${mongodbatlas_private_endpoint_regional_mode.test}"
                      ],
                      "mongo_db_major_version": "5.0",
                      "name": "${var.cluster_name}",
                      "project_id": "${var.atlasprojectid}",
                      "provider_instance_size_name": "M30",
                      "provider_name": "AWS",
                      "replication_specs": [
                        {
                          "num_shards": 2,
                          "regions_config": [
                            {
                              "electable_nodes": 3,
                              "priority": 7,
                              "read_only_nodes": 0,
                              "region_name": "${var.atlas_region_east}"
                            },
                            {
                              "electable_nodes": 2,
                              "priority": 6,
                              "read_only_nodes": 0,
                              "region_name": "${var.atlas_region_west}"
                            }
                          ],
                          "zone_name": "Zone 1"
                        }
                      ]
                    }
                mongodbatlas_privatelink_endpoint.test_east: |-
                    {
                      "project_id": "var.atlasprojectid"
                    }
                mongodbatlas_privatelink_endpoint.test_west: |-
                    {
                      "project_id": "${var.atlasprojectid}",
                      "provider_name": "AWS",
                      "region": "US_WEST_1"
                    }
                mongodbatlas_privatelink_endpoint_service.test_west: |-
                    {
                      "endpoint_service_id": "${aws_vpc_endpoint.test_west.id}",
                      "private_link_id": "${mongodbatlas_privatelink_endpoint.test_west.private_link_id}",
                      "project_id": "${mongodbatlas_privatelink_endpoint.test_west.project_id}",
                      "provider_name": "AWS"
                    }
        argumentDocs:
            enabled: '- (Optional) Flag that indicates whether the regionalized private endpoint setting is enabled for the project.   Set this value to true to create more than one private endpoint in a cloud provider region to connect to multi-region and global Atlas sharded clusters. You can enable this setting only if your Atlas project contains no replica sets. You can''t disable this setting if you have:'
            mongodbatlas_cluster.cluster-atlas.connection_strings: will differ based on the value of mongodbatlas_private_endpoint_regional_mode.test.enabled.
            mongodbatlas_cluster.cluster-atlas.depends_on: '- Make your cluster dependent on the project''s mongodbatlas_private_endpoint_regional_mode as well as any relevant mongodbatlas_privatelink_endpoint_service resources.  See an example.'
            project_id: '- (Required) Unique identifier for the project.'
            timeouts: '- (Optional) The duration of time to wait for Cluster to be created, updated, or deleted. The timeout value is defined by a signed sequence of decimal numbers with an time unit suffix such as: 1h45m, 300s, 10m, .... The valid time units are:  ns, us (or µs), ms, s, m, h. The default timeout for Private Endpoint Regional Mode operations is 3h. Learn more about timeouts here.'
        importStatements: []
    mongodbatlas_private_ip_mode:
        subCategory: ""
        description: Provides a Private IP Mode resource.
        name: mongodbatlas_private_ip_mode
        title: private_ip_mode
        examples:
            - name: my_private_ip_mode
              manifest: |-
                {
                  "enabled": false,
                  "project_id": "\u003cYOUR PROJECT ID\u003e"
                }
        argumentDocs:
            enabled: '- (Required) Indicates whether Connect via Peering Only mode is enabled or disabled for an Atlas project'
            id: '- The project id.'
            project_id: '- (Required) The unique ID for the project to enable Only Private IP Mode.'
        importStatements: []
    mongodbatlas_privatelink_endpoint:
        subCategory: ""
        description: Provides a Private Endpoint resource.
        name: mongodbatlas_privatelink_endpoint
        title: private_endpoint
        examples:
            - name: test
              manifest: |-
                {
                  "project_id": "\u003cPROJECT-ID\u003e",
                  "provider_name": "AWS/AZURE",
                  "region": "US_EAST_1",
                  "timeouts": [
                    {
                      "create": "30m",
                      "delete": "20m"
                    }
                  ]
                }
        argumentDocs:
            AVAILABLE: Atlas is creating the network load balancer and VPC endpoint service.
            DELETING: |-
                The AWS PrivateLink connection is being deleted.
                AZURE:
            FAILED: A system failure has occurred.
            INITIATING: Atlas is creating the load balancer and the Private Link Service.
            WAITING_FOR_USER: The Atlas network load balancer and VPC endpoint service are created and ready to receive connection requests. When you receive this status, create an interface endpoint to continue configuring the AWS PrivateLink connection.
            endpoint_group_names: '- GCP network endpoint groups corresponding to the Private Service Connect endpoint service.'
            endpoint_service_name: '- Name of the PrivateLink endpoint service in AWS. Returns null while the endpoint service is being created.'
            error_message: |-
                - Error message pertaining to the AWS PrivateLink connection. Returns null if there are no errors.
                AWS:
            id: '- The Terraform''s unique identifier used internally for state management.'
            interface_endpoints: |-
                - Unique identifiers of the interface endpoints in your VPC that you added to the AWS PrivateLink connection.
                AZURE:
            private_endpoints: '- All private endpoints that you have added to this Azure Private Link Service.'
            private_link_id: '- Unique identifier of the AWS PrivateLink connection.'
            private_link_service_name: |-
                - Name of the Azure Private Link Service that Atlas manages.
                GCP:
            project_id: "- Required \tUnique identifier for the project."
            provider_name: '- (Required) Name of the cloud provider for which you want to create the private endpoint service. Atlas accepts AWS, AZURE or GCP.'
            region: |-
                - (Required) Cloud provider region in which you want to create the private endpoint connection.
                Accepted values are: AWS regions, AZURE regions and GCP regions
            region_name: '- GCP region for the Private Service Connect endpoint service.'
            service_attachment_names: '- Unique alphanumeric and special character strings that identify the service attachments associated with the GCP Private Service Connect endpoint service. Returns an empty list while Atlas creates the service attachments.'
            status: |-
                - Status of the AWS PrivateLink connection or Status of the Azure Private Link Service. Atlas returns one of the following values:
                AWS:
            timeouts: '- (Optional) The duration of time to wait for Private Endpoint to be created or deleted. The timeout value is defined by a signed sequence of decimal numbers with an time unit suffix such as: 1h45m, 300s, 10m, .... The valid time units are:  ns, us (or µs), ms, s, m, h. The default timeout for Private Endpoint create & delete is 1h. Learn more about timeouts here.'
        importStatements: []
    mongodbatlas_privatelink_endpoint_serverless:
        subCategory: ""
        description: Describes a Serverless PrivateLink Endpoint
        name: mongodbatlas_privatelink_endpoint_serverless
        title: privatelink_endpoint_serverless
        examples:
            - name: test
              manifest: |-
                {
                  "instance_name": "${mongodbatlas_serverless_instance.test.name}",
                  "project_id": "\u003cPROJECT_ID\u003e",
                  "provider_name": "AWS"
                }
              references:
                instance_name: mongodbatlas_serverless_instance.test.name
              dependencies:
                mongodbatlas_serverless_instance.test: |-
                    {
                      "continuous_backup_enabled": true,
                      "name": "test-db",
                      "project_id": "\u003cPROJECT_ID\u003e",
                      "provider_settings_backing_provider_name": "AWS",
                      "provider_settings_provider_name": "SERVERLESS",
                      "provider_settings_region_name": "US_EAST_1"
                    }
        argumentDocs:
            cloud_provider_endpoint_id: '- Unique string that identifies the private endpoint''s network interface.'
            comment: '- Human-readable string to associate with this private endpoint.'
            endpoint_id: '- Unique 24-hexadecimal digit string that identifies the private endpoint.'
            endpoint_service_name: '- Unique string that identifies the PrivateLink endpoint service.'
            instance_name: '- (Required) Human-readable label that identifies the serverless instance.'
            private_link_service_resource_id: '- Root-relative path that identifies the Azure Private Link Service that MongoDB Cloud manages.'
            project_id: '- (Required) Unique 24-digit hexadecimal string that identifies the project.'
            provider_name: '- (Required) Cloud provider name; AWS is currently supported'
            status: '- Human-readable label that indicates the current operating status of the private endpoint. Values include: RESERVATION_REQUESTED, RESERVED, INITIATING, AVAILABLE, FAILED, DELETING.'
            timeouts: '- (Optional) The duration of time to wait for Private Endpoint Service to be created or deleted. The timeout value is defined by a signed sequence of decimal numbers with an time unit suffix such as: 1h45m, 300s, 10m, .... The valid time units are:  ns, us (or µs), ms, s, m, h. The default timeout for Private Endpoint create & delete is 2h. Learn more about timeouts here.'
        importStatements: []
    mongodbatlas_privatelink_endpoint_service_adl:
        subCategory: ""
        description: Provides an Atlas Data Lake and Online Archive PrivateLink endpoint.
        name: mongodbatlas_privatelink_endpoint_service_adl
        title: privatelink_endpoint_service_adl
        examples:
            - name: adl_test
              manifest: |-
                {
                  "comment": "comments for private link endpoint adl",
                  "endpoint_id": "\u003cENDPOINT_ID\u003e",
                  "project_id": "\u003cPROJECT_ID\u003e",
                  "provider_name": "AWS",
                  "type": "DATA_LAKE"
                }
        argumentDocs:
            comment: '- Human-readable string to associate with this private endpoint.'
            endpoint_id: '- (Required) Unique 22-character alphanumeric string that identifies the private endpoint. Atlas supports AWS private endpoints using the |aws| PrivateLink feature.'
            project_id: '- (Required) Unique 24-digit hexadecimal string that identifies the project.'
            provider_name: '- (Required) Human-readable label that identifies the cloud provider for this endpoint. Atlas supports AWS only. If empty, defaults to AWS.'
            type: '- (Required) Human-readable label that identifies the type of resource to associate with this private endpoint. Atlas supports DATA_LAKE only. If empty, defaults to DATA_LAKE.'
        importStatements: []
    mongodbatlas_privatelink_endpoint_service_data_federation_online_archive:
        subCategory: ""
        description: Provides a Privatelink Endpoint Service Data Federation Online Archive resource.
        name: mongodbatlas_privatelink_endpoint_service_data_federation_online_archive
        title: mongodbatlas_privatelink_endpoint_service_data_federation_online_archive
        examples:
            - name: test
              manifest: |-
                {
                  "comment": "Test",
                  "endpoint_id": "\u003cPRIVATE-ENDPOINT-SERVICE-ID\u003e",
                  "project_id": "${mongodbatlas_project.atlas-project.id}",
                  "provider_name": "AWS"
                }
              references:
                project_id: mongodbatlas_project.atlas-project.id
              dependencies:
                mongodbatlas_project.atlas-project: |-
                    {
                      "name": "${var.atlas_project_name}",
                      "org_id": "${var.atlas_org_id}"
                    }
        argumentDocs:
            comment: '- Human-readable string to associate with this private endpoint.'
            endpoint_id: (Required) - Unique 22-character alphanumeric string that identifies the private endpoint. See Atlas Data Lake supports Amazon Web Services private endpoints using the AWS PrivateLink feature.
            project_id: (Required) - Unique 24-hexadecimal digit string that identifies your project.
            provider_name: (Required) - Human-readable label that identifies the cloud service provider.
            timeouts: '- (Optional) The duration of time to wait for Private Endpoint Service to be created or deleted. The timeout value is definded by a signed sequence of decimal numbers with an time unit suffix such as: 1h45m, 300s, 10m, .... The valid time units are:  ns, us (or µs), ms, s, m, h. The default timeout for Private Endpoint create & delete is 2h. Learn more about timeouts here.'
            type: '- Human-readable label that identifies the resource type associated with this private endpoint.'
        importStatements: []
    mongodbatlas_privatelink_endpoint_service_serverless:
        subCategory: ""
        description: Describes a Serverless PrivateLink Endpoint Service
        name: mongodbatlas_privatelink_endpoint_service_serverless
        title: privatelink_endpoint_service_serverless
        examples:
            - name: test
              manifest: |-
                {
                  "cloud_provider_endpoint_id": "${aws_vpc_endpoint.ptfe_service.id}",
                  "comment": "New serverless endpoint",
                  "endpoint_id": "${mongodbatlas_privatelink_endpoint_serverless.test.endpoint_id}",
                  "instance_name": "${mongodbatlas_serverless_instance.test.name}",
                  "project_id": "\u003cPROJECT_ID\u003e",
                  "provider_name": "AWS"
                }
              references:
                cloud_provider_endpoint_id: aws_vpc_endpoint.ptfe_service.id
                endpoint_id: mongodbatlas_privatelink_endpoint_serverless.test.endpoint_id
                instance_name: mongodbatlas_serverless_instance.test.name
              dependencies:
                aws_vpc_endpoint.ptfe_service: |-
                    {
                      "security_group_ids": [
                        "sg-3f238186"
                      ],
                      "service_name": "${mongodbatlas_privatelink_endpoint_serverless.test.endpoint_service_name}",
                      "subnet_ids": [
                        "subnet-de0406d2"
                      ],
                      "vpc_endpoint_type": "Interface",
                      "vpc_id": "vpc-7fc0a543"
                    }
                mongodbatlas_privatelink_endpoint_serverless.test: |-
                    {
                      "instance_name": "${mongodbatlas_serverless_instance.test.name}",
                      "project_id": "\u003cPROJECT_ID\u003e",
                      "provider_name": "AWS"
                    }
                mongodbatlas_serverless_instance.test: |-
                    {
                      "continuous_backup_enabled": true,
                      "name": "test-db",
                      "project_id": "\u003cPROJECT_ID\u003e",
                      "provider_settings_backing_provider_name": "AWS",
                      "provider_settings_provider_name": "SERVERLESS",
                      "provider_settings_region_name": "US_EAST_1"
                    }
            - name: test
              manifest: |-
                {
                  "cloud_provider_endpoint_id": "${azurerm_private_endpoint.test.id}",
                  "comment": "test",
                  "endpoint_id": "${mongodbatlas_privatelink_endpoint_serverless.test.endpoint_id}",
                  "instance_name": "${mongodbatlas_serverless_instance.test.name}",
                  "private_endpoint_ip_address": "${azurerm_private_endpoint.test.private_service_connection.0.private_ip_address}",
                  "project_id": "${mongodbatlas_privatelink_endpoint_serverless.test.project_id}",
                  "provider_name": "AZURE"
                }
              references:
                cloud_provider_endpoint_id: azurerm_private_endpoint.test.id
                endpoint_id: mongodbatlas_privatelink_endpoint_serverless.test.endpoint_id
                instance_name: mongodbatlas_serverless_instance.test.name
                private_endpoint_ip_address: azurerm_private_endpoint.test.private_service_connection.0.private_ip_address
                project_id: mongodbatlas_privatelink_endpoint_serverless.test.project_id
              dependencies:
                azurerm_private_endpoint.test: |-
                    {
                      "location": "${data.azurerm_resource_group.test.location}",
                      "name": "endpoint-test",
                      "private_service_connection": [
                        {
                          "is_manual_connection": true,
                          "name": "${mongodbatlas_privatelink_endpoint_serverless.test.private_link_service_name}",
                          "private_connection_resource_id": "${mongodbatlas_privatelink_endpoint_serverless.test.private_link_service_resource_id}",
                          "request_message": "Azure Private Link test"
                        }
                      ],
                      "resource_group_name": "${var.resource_group_name}",
                      "subnet_id": "${azurerm_subnet.test.id}"
                    }
                mongodbatlas_privatelink_endpoint_serverless.test: |-
                    {
                      "project_id": "${var.project_id}",
                      "provider_name": "AZURE"
                    }
                mongodbatlas_serverless_instance.test: |-
                    {
                      "continuous_backup_enabled": true,
                      "name": "test-db",
                      "project_id": "\u003cPROJECT_ID\u003e",
                      "provider_settings_backing_provider_name": "AZURE",
                      "provider_settings_provider_name": "SERVERLESS",
                      "provider_settings_region_name": "US_EAST"
                    }
        argumentDocs:
            cloud_provider_endpoint_id: '- (Optional) Unique string that identifies the private endpoint''s network interface.'
            comment: '- (Optional) Human-readable string to associate with this private endpoint.'
            endpoint_id: '- (Required) Unique 24-hexadecimal digit string that identifies the private endpoint.'
            endpoint_service_name: '- Unique string that identifies the PrivateLink endpoint service.'
            error_message: '- Human-readable error message that indicates the error condition associated with establishing the private endpoint connection.'
            instance_name: '- (Required) Human-readable label that identifies the serverless instance.'
            private_endpoint_ip_address: '- (Optional) IPv4 address of the private endpoint in your Azure VNet that someone added to this private endpoint service.'
            private_link_service_resource_id: '- Root-relative path that identifies the Azure Private Link Service that MongoDB Cloud manages.'
            project_id: '- (Required) Unique 24-digit hexadecimal string that identifies the project.'
            provider_name: '- (Required) Cloud provider for which you want to create a private endpoint. Atlas accepts AWS, AZURE.'
            status: '- Human-readable label that indicates the current operating status of the private endpoint. Values include: RESERVATION_REQUESTED, RESERVED, INITIATING, AVAILABLE, FAILED, DELETING.'
            timeouts: '- (Optional) The duration of time to wait for Private Endpoint Service to be created or deleted. The timeout value is defined by a signed sequence of decimal numbers with an time unit suffix such as: 1h45m, 300s, 10m, .... The valid time units are:  ns, us (or µs), ms, s, m, h. The default timeout for Private Endpoint create & delete is 2h. Learn more about timeouts here.'
        importStatements: []
    mongodbatlas_project:
        subCategory: ""
        description: Provides a Project resource.
        name: mongodbatlas_project
        title: project
        examples:
            - name: test
              manifest: |-
                {
                  "api_keys": [
                    {
                      "api_key_id": "61003b299dda8d54a9d7d10c",
                      "role_names": [
                        "GROUP_READ_ONLY"
                      ]
                    }
                  ],
                  "is_collect_database_specifics_statistics_enabled": true,
                  "is_data_explorer_enabled": true,
                  "is_extended_storage_sizes_enabled": true,
                  "is_performance_advisor_enabled": true,
                  "is_realtime_performance_panel_enabled": true,
                  "is_schema_advisor_enabled": true,
                  "limits": [
                    {
                      "name": "atlas.project.deployment.clusters",
                      "value": 26
                    },
                    {
                      "name": "atlas.project.deployment.nodesPerPrivateLinkRegion",
                      "value": 51
                    }
                  ],
                  "name": "project-name",
                  "org_id": "${data.mongodbatlas_roles_org_id.test.org_id}",
                  "project_owner_id": "\u003cOWNER_ACCOUNT_ID\u003e",
                  "teams": [
                    {
                      "role_names": [
                        "GROUP_OWNER"
                      ],
                      "team_id": "5e0fa8c99ccf641c722fe645"
                    },
                    {
                      "role_names": [
                        "GROUP_READ_ONLY",
                        "GROUP_DATA_ACCESS_READ_WRITE"
                      ],
                      "team_id": "5e1dd7b4f2a30ba80a70cd4rw"
                    }
                  ]
                }
              references:
                org_id: data.mongodbatlas_roles_org_id.test.org_id
        argumentDocs:
            api_key_id: '- (Required) The unique identifier of the Programmatic API key you want to associate with the Project.  The Programmatic API key and Project must share the same parent organization.  Note: this is not the publicKey of the Programmatic API key but the id of the key. See Programmatic API Keys for more.'
            cluster_count: '- The number of Atlas clusters deployed in the project..'
            created: '- The ISO-8601-formatted timestamp of when Atlas created the project..'
            id: '- The project id.'
            is_collect_database_specifics_statistics_enabled: '- (Optional) Flag that indicates whether to enable statistics in cluster metrics collection for the project.'
            is_data_explorer_enabled: '- (Optional) Flag that indicates whether to enable Data Explorer for the project. If enabled, you can query your database with an easy to use interface.  When Data Explorer is disabled, you cannot terminate slow operations from the Real-Time Performance Panel or create indexes from the Performance Advisor. You can still view Performance Advisor recommendations, but you must create those indexes from mongosh.'
            is_extended_storage_sizes_enabled: '- (Optional) Flag that indicates whether to enable extended storage sizes for the specified project. Clusters with extended storage sizes must be on AWS or GCP, and cannot span multiple regions. When extending storage size, initial syncs and cross-project snapshot restores will be slow. This setting should only be used as a measure of temporary relief; consider sharding if more storage is required.'
            is_performance_advisor_enabled: '- (Optional) Flag that indicates whether to enable Performance Advisor and Profiler for the project. If enabled, you can analyze database logs to recommend performance improvements.'
            is_realtime_performance_panel_enabled: '- (Optional) Flag that indicates whether to enable Real Time Performance Panel for the project. If enabled, you can see real time metrics from your MongoDB database.'
            is_schema_advisor_enabled: '- (Optional) Flag that indicates whether to enable Schema Advisor for the project. If enabled, you receive customized recommendations to optimize your data model and enhance performance. Disable this setting to disable schema suggestions in the Performance Advisor and the Data Explorer.'
            name: '- (Required) The name of the project you want to create.'
            org_id: '- (Required) The ID of the organization you want to create the project within.'
            project_owner_id: '- (Optional) Unique 24-hexadecimal digit string that identifies the Atlas user account to be granted the Project Owner role on the specified project. If you set this parameter, it overrides the default value of the oldest Organization Owner.'
            region_usage_restrictions: '- (Optional - set value to GOV_REGIONS_ONLY) Designates that this project can be used for government regions only.  If not set the project will default to standard regions.   You cannot deploy clusters across government and standard regions in the same project. AWS is the only cloud provider for AtlasGov.  For more information see MongoDB Atlas for Government.'
            role_names: '- (Required) Each string in the array represents a project role you want to assign to the team. Every user associated with the team inherits these roles. You must specify an array even if you are only associating a single role with the team. The MongoDB Documentation describes the roles a user can have.'
            team_id: '- (Required) The unique identifier of the team you want to associate with the project. The team and project must share the same parent organization.'
            value: '- (Required) Amount to set the limit to. Use the Project Limit Documentation under limitName parameter to verify the override limits.'
            with_default_alerts_settings: '- (Optional) It allows users to disable the creation of the default alert settings. By default, this flag is set to true.'
        importStatements: []
    mongodbatlas_project_api_key:
        subCategory: ""
        description: Creates and assigns the specified Atlas Organization API Key to the specified Project. Users with the Project Owner role in the project associated with the API key can use the organization API key to access the resources.
        name: mongodbatlas_project_api_key
        title: project_api_key
        examples:
            - name: test
              manifest: |-
                {
                  "description": "Description of your API key",
                  "project_id": "64259ee860c43338194b0f8e",
                  "role_names": [
                    "GROUP_OWNER"
                  ]
                }
            - name: test
              manifest: |-
                {
                  "description": "Description of your API key",
                  "project_assignment": [
                    {
                      "project_id": "64259ee860c43338194b0f8e",
                      "role_names": [
                        "GROUP_READ_ONLY",
                        "GROUP_OWNER"
                      ]
                    },
                    {
                      "project_id": "74259ee860c43338194b0f8e",
                      "role_names": [
                        "GROUP_READ_ONLY"
                      ]
                    }
                  ],
                  "project_id": "64259ee860c43338194b0f8e"
                }
        argumentDocs:
            api_key_id: '- Unique identifier for this Project API key.'
            description: '- Description of this Project API key.'
            project_id: -Unique 24-hexadecimal digit string that identifies your project.
            role_names: '-  List of Project roles that the Programmatic API key needs to have. Ensure you provide: at least one role and ensure all roles are valid for the Project.  You must specify an array even if you are only associating a single role with the Programmatic API key. The MongoDB Documentation describes the valid roles that can be assigned. DEPRECATED Use project_assignment instead.'
        importStatements: []
    mongodbatlas_project_invitation:
        subCategory: ""
        description: Provides an Atlas Project Invitation resource.
        name: mongodbatlas_project_invitation
        title: project_invitation
        examples:
            - name: test
              manifest: |-
                {
                  "project_id": "\u003cPROJECT-ID\u003e",
                  "roles": [
                    "GROUP_DATA_ACCESS_READ_WRITE"
                  ],
                  "username": "test-acc-username"
                }
            - name: test
              manifest: |-
                {
                  "project_id": "\u003cPROJECT-ID\u003e",
                  "roles": [
                    "GROUP_READ_ONLY",
                    "GROUP_DATA_ACCESS_READ_ONLY"
                  ],
                  "username": "test-acc-username"
                }
        argumentDocs:
            created_at: '- Timestamp in ISO 8601 date and time format in UTC when Atlas sent the invitation.'
            expires_at: '- Timestamp in ISO 8601 date and time format in UTC when the invitation expires. Users have 30 days to accept an invitation.'
            id: '- Autogenerated Unique ID for this resource.'
            invitation_id: '- Unique 24-hexadecimal digit string that identifies the invitation in Atlas.'
            inviter_username: '- Atlas user who invited username to the project.'
            project_id: '- (Required) Unique 24-hexadecimal digit string that identifies the project to which you want to invite a user.'
            roles: '- (Required) List of Atlas roles to assign to the invited user. If the user accepts the invitation, Atlas assigns these roles to them. Refer to the MongoDB Documentation for information on valid roles.'
            username: '- (Required) Email address to which Atlas sent the invitation. The user uses this email address as their Atlas username if they accept this invitation.'
        importStatements: []
    mongodbatlas_project_ip_access_list:
        subCategory: ""
        description: Provides an IP Access List resource.
        name: mongodbatlas_project_ip_access_list
        title: project_ip_access_list
        examples:
            - name: test
              manifest: |-
                {
                  "cidr_block": "1.2.3.4/32",
                  "comment": "cidr block for tf acc testing",
                  "project_id": "\u003cPROJECT-ID\u003e"
                }
            - name: test
              manifest: |-
                {
                  "comment": "ip address for tf acc testing",
                  "ip_address": "2.3.4.5",
                  "project_id": "\u003cPROJECT-ID\u003e"
                }
            - name: test
              manifest: |-
                {
                  "aws_security_group": "sg-0026348ec11780bd1",
                  "comment": "TestAcc for awsSecurityGroup",
                  "depends_on": [
                    "mongodbatlas_network_peering.test"
                  ],
                  "project_id": "\u003cPROJECT-ID\u003e"
                }
              dependencies:
                mongodbatlas_network_container.test: |-
                    {
                      "atlas_cidr_block": "192.168.208.0/21",
                      "project_id": "\u003cPROJECT-ID\u003e",
                      "provider_name": "AWS",
                      "region_name": "US_EAST_1"
                    }
                mongodbatlas_network_peering.test: |-
                    {
                      "accepter_region_name": "us-east-1",
                      "aws_account_id": "232589400519",
                      "container_id": "${mongodbatlas_network_container.test.container_id}",
                      "project_id": "\u003cPROJECT-ID\u003e",
                      "provider_name": "AWS",
                      "route_table_cidr_block": "172.31.0.0/16",
                      "vpc_id": "vpc-0d93d6f69f1578bd8"
                    }
        argumentDocs:
            aws_security_group: '- (Optional) Unique identifier of the AWS security group to add to the access list. Your access list entry can include only one awsSecurityGroup, one cidrBlock, or one ipAddress.'
            cidr_block: '- (Optional) Range of IP addresses in CIDR notation to be added to the access list. Your access list entry can include only one awsSecurityGroup, one cidrBlock, or one ipAddress.'
            comment: '- (Optional) Comment to add to the access list entry.'
            id: '- Unique identifier used for terraform for internal manages and can be used to import.'
            ip_address: '- (Optional) Single IP address to be added to the access list. Mutually exclusive with awsSecurityGroup and cidrBlock.'
            project_id: '- (Required) Unique identifier for the project to which you want to add one or more access list entries.'
        importStatements: []
    mongodbatlas_teams:
        subCategory: ""
        description: Provides a Team resource.
        name: mongodbatlas_teams
        title: teams
        examples:
            - name: test
              manifest: |-
                {
                  "name": "myNewTeam",
                  "org_id": "\u003cORGANIZATION-ID\u003e",
                  "usernames": [
                    "user1@email.com",
                    "user2@email.com",
                    "user3@email.com"
                  ]
                }
        argumentDocs:
            id: "-\tThe Terraform's unique identifier used internally for state management."
            name: '- (Required) The name of the team you want to create.'
            org_id: '- (Required) The unique identifier for the organization you want to associate the team with.'
            team_id: '- The unique identifier for the team.'
            usernames: '- (Required) The Atlas usernames (email address). You can only add Atlas users who are part of the organization. Users who have not accepted an invitation to join the organization cannot be added as team members. There is a maximum of 250 Atlas users per team.'
        importStatements: []
    mongodbatlas_third_party_integration:
        subCategory: ""
        description: Provides a Third-Party Integration Settings resource.
        name: mongodbatlas_third_party_integration
        title: third_party_integration
        examples:
            - name: test_flowdock
              manifest: |-
                {
                  "api_token": "\u003cAPI-TOKEN\u003e",
                  "flow_name": "\u003cFLOW-NAME\u003e",
                  "org_name": "\u003cORG-NAME\u003e",
                  "project_id": "\u003cPROJECT-ID\u003e",
                  "type": "FLOWDOCK"
                }
        argumentDocs:
            account_id: '- Unique identifier of your New Relic account.'
            api_key: '- Your API Key.'
            api_token: '- Your API Token.'
            enabled: '- Whether your cluster has Prometheus enabled.'
            flow_name: '- Your Flowdock Flow name.'
            id: '- Unique identifier used by terraform for internal management, which can also be used to import.'
            license_key: '- Your License Key.'
            microsoft_teams_webhook_url: '-  Your Microsoft Teams incoming webhook URL.'
            org_name: '- Your Flowdock organization name.'
            password: '- Your Prometheus password.'
            project_id: '- (Required) The unique ID for the project to get all Third-Party service integrations'
            read_token: '- Your Insights Query Key.'
            region: (Required) - PagerDuty region that indicates the API Uniform Resource Locator (URL) to use, either "US" or "EU". PagerDuty will use "US" by default.
            routing_key: '- An optional field for your Routing Key.'
            scheme: '- Your Prometheus protocol scheme configured for requests.'
            secret: '- An optional field for your webhook secret.'
            service_discovery: '- Indicates which service discovery method is used, either file or http.'
            service_key: '- Your Service Key.'
            type: '- (Required) Third-Party Integration Settings type'
            url: '- Your webhook URL.'
            user_name: '- Your Prometheus username.'
            write_token: '- Your Insights Insert Key.'
        importStatements: []
    mongodbatlas_x509_authentication_database_user:
        subCategory: ""
        description: Provides a X509 Authentication Database User resource.
        name: mongodbatlas_x509_authentication_database_user
        title: x509_authentication_database_user
        examples:
            - name: test
              manifest: |-
                {
                  "months_until_expiration": 2,
                  "project_id": "${mongodbatlas_database_user.user.project_id}",
                  "username": "${mongodbatlas_database_user.user.username}"
                }
              references:
                project_id: mongodbatlas_database_user.user.project_id
                username: mongodbatlas_database_user.user.username
              dependencies:
                mongodbatlas_database_user.user: |-
                    {
                      "database_name": "$external",
                      "labels": [
                        {
                          "key": "My Key",
                          "value": "My Value"
                        }
                      ],
                      "project_id": "64b926dd56206839b1c8bae9",
                      "roles": [
                        {
                          "database_name": "admin",
                          "role_name": "atlasAdmin"
                        }
                      ],
                      "username": "myUsername",
                      "x509_type": "MANAGED"
                    }
            - name: test
              manifest: |-
                {
                  "customer_x509_cas": "-----BEGIN CERTIFICATE-----\nMIICmTCCAgICCQDZnHzklxsT9TANBgkqhkiG9w0BAQsFADCBkDELMAkGA1UEBhMC\nVVMxDjAMBgNVBAgMBVRleGFzMQ8wDQYDVQQHDAZBdXN0aW4xETAPBgNVBAoMCHRl\nc3QuY29tMQ0wCwYDVQQLDARUZXN0MREwDwYDVQQDDAh0ZXN0LmNvbTErMCkGCSqG\nSIb3DQEJARYcbWVsaXNzYS5wbHVua2V0dEBtb25nb2RiLmNvbTAeFw0yMDAyMDQy\nMDQ2MDFaFw0yMTAyMDMyMDQ2MDFaMIGQMQswCQYDVQQGEwJVUzEOMAwGA1UECAwF\nVGV4YXMxDzANBgNVBAcMBkF1c3RpbjERMA8GA1UECgwIdGVzdC5jb20xDTALBgNV\nBAsMBFRlc3QxETAPBgNVBAMMCHRlc3QuY29tMSswKQYJKoZIhvcNAQkBFhxtZWxp\nc3NhLnBsdW5rZXR0QG1vbmdvZGIuY29tMIGfMA0GCSqGSIb3DQEBAQUAA4GNADCB\niQKBgQCf1LRqr1zftzdYx2Aj9G76tb0noMPtj6faGLlPji1+m6Rn7RWD9L0ntWAr\ncURxvypa9jZ9MXFzDtLevvd3tHEmfrUT3ukNDX6+Jtc4kWm+Dh2A70Pd+deKZ2/O\nFh8audEKAESGXnTbeJCeQa1XKlIkjqQHBNwES5h1b9vJtFoLJwIDAQABMA0GCSqG\nSIb3DQEBCwUAA4GBADMUncjEPV/MiZUcVNGmktP6BPmEqMXQWUDpdGW2+Tg2JtUA\n7MMILtepBkFzLO+GlpZxeAlXO0wxiNgEmCRONgh4+t2w3e7a8GFijYQ99FHrAC5A\niul59bdl18gVqXia1Yeq/iK7Ohfy/Jwd7Hsm530elwkM/ZEkYDjBlZSXYdyz\n-----END CERTIFICATE-----\"\n",
                  "project_id": "\u003cPROJECT-ID\u003e"
                }
              dependencies:
                mongodbatlas_database_user.user: |-
                    {
                      "database_name": "$external",
                      "labels": [
                        {
                          "key": "My Key",
                          "value": "My Value"
                        }
                      ],
                      "project_id": "64b926dd56206839b1c8bae9",
                      "roles": [
                        {
                          "database_name": "admin",
                          "role_name": "atlasAdmin"
                        }
                      ],
                      "username": "myUsername",
                      "x509_type": "CUSTOMER"
                    }
        argumentDocs:
            certificates: '- Array of objects where each details one unexpired database user certificate.'
            certificates.#.created_at: '- Timestamp in ISO 8601 date and time format in UTC when Atlas created this X.509 certificate.'
            certificates.#.group_id: '- Unique identifier of the Atlas project to which this certificate belongs.'
            certificates.#.id: '- Serial number of this certificate.'
            certificates.#.not_after: '- Timestamp in ISO 8601 date and time format in UTC when this certificate expires.'
            certificates.#.subject: '- Fully distinguished name of the database user to which this certificate belongs. To learn more, see RFC 2253.'
            current_certificate: '- Contains the last X.509 certificate and private key created for a database user.'
            customer_x509_cas: '- (Optional) PEM string containing one or more customer CAs for database user authentication.'
            months_until_expiration: '- (Required) A number of months that the created certificate is valid for before expiry, up to 24 months. By default is 3.'
            project_id: '- (Required) Identifier for the Atlas project associated with the X.509 configuration.'
            username: '- (Optional) Username of the database user to create a certificate for.'
        importStatements: []
    private_endpoint_link:
        subCategory: ""
        description: Provides a Private Endpoint Link resource.
        name: private_endpoint_link
        title: private_endpoint_link
        argumentDocs:
            AVAILABLE: '- Atlas VPC resources are connected to the VPC endpoint in your VPC. You can connect to Atlas clusters in this region using AWS PrivateLink.'
            DELETING: '- Atlas is removing the interface endpoint from the private endpoint connection.'
            FAILED: '- Atlas failed to accept the connection your private endpoint.'
            INITIATING: '- Atlas has not yet accepted the connection to your private endpoint.'
            NONE: '- Atlas created the network load balancer and VPC endpoint service, but AWS hasn’t yet created the VPC endpoint.'
            PENDING: '- AWS is establishing the connection between your VPC endpoint and the Atlas VPC endpoint service.'
            PENDING_ACCEPTANCE: '- AWS has received the connection request from your VPC endpoint to the Atlas VPC endpoint service.'
            REJECTED: '- AWS failed to establish a connection between Atlas VPC resources to the VPC endpoint in your VPC.'
            aws_connection_status: |-
                - Status of the interface endpoint for AWS.
                Returns one of the following values:
            azure_status: |-
                - Status of the interface endpoint for AZURE.
                Returns one of the following values:
            delete_requested: '- Indicates if Atlas received a request to remove the interface endpoint from the private endpoint connection.'
            endpoint_group_name: '- (Optional) Unique identifier of the endpoint group. The endpoint group encompasses all of the endpoints that you created in GCP.'
            endpoint_service_id: '- (Required) Unique identifier of the interface endpoint you created in your VPC with the AWS, AZURE or GCP resource.'
            endpoints: '- (Optional) Collection of individual private endpoints that comprise your endpoint group. Only for GCP. See below.'
            endpoints.endpoint_name: '- (Optional) Forwarding rule that corresponds to the endpoint you created in GCP.'
            endpoints.ip_address: '- (Optional) Private IP address of the endpoint you created in GCP.'
            error_message: '- Error message pertaining to the interface endpoint. Returns null if there are no errors.'
            gcp_project_id: '- (Optional) Unique identifier of the GCP project in which you created your endpoints. Only for GCP.'
            gcp_status: |-
                - Status of the interface endpoint for GCP.
                Returns one of the following values:
            id: '- The Terraform''s unique identifier used internally for state management.'
            interface_endpoint_id: '- Unique identifier of the interface endpoint.'
            private_endpoint_connection_name: '- Name of the connection for this private endpoint that Atlas generates.'
            private_endpoint_ip_address: '- (Optional) Private IP address of the private endpoint network interface you created in your Azure VNet. Only for AZURE.'
            private_endpoint_resource_id: '- Unique identifier of the private endpoint.'
            private_link_id: '- (Required) Unique identifier of the AWS or AZURE PrivateLink connection which is created by mongodbatlas_privatelink_endpoint resource.'
            project_id: '- (Required) Unique identifier for the project.'
            provider_name: '- (Required) Cloud provider for which you want to create a private endpoint. Atlas accepts AWS, AZURE or GCP.'
            service_attachment_name: '- Unique alphanumeric and special character strings that identify the service attachment associated with the endpoint.'
            status: '- Status of the endpoint. Atlas returns one of the values shown above.'
            timeouts: '- (Optional) The duration of time to wait for Private Endpoint Service to be created or deleted. The timeout value is defined by a signed sequence of decimal numbers with an time unit suffix such as: 1h45m, 300s, 10m, .... The valid time units are:  ns, us (or µs), ms, s, m, h. The default timeout for Private Endpoint create & delete is 2h. Learn more about timeouts here.'
        importStatements: []
    search index:
        subCategory: ""
        description: Provides a Search Index resource.
        name: search index
        title: search index
        argumentDocs:
            '<original> : <replacement>': "Example\nanalyzers = <<-EOF [{\n  \"name\":\"name_analyzer\",        \n  \"type\": \"mapping\",\n  \"mappings\":  \n  {\n     \"\\\\\" : \"/\"\n  }\n  }]\n  EOF"
            analyzer: '- Analyzer to use when creating the index. Defaults to lucene.standard'
            analyzers: '- Custom analyzers to use in this index. This is an array of JSON objects.'
            charFilters: '- Array containing zero or more character filters. Always require a type field, and some take additional options as well'
            cluster_name: '- (Required) The name of the cluster where you want to create the search index within.'
            collection_name: '- (Required) Name of the collection the index is on.'
            database: '- (Required) Name of the database the collection is in.'
            "false": '- to be case-sensitive and remove only tokens that exactly match the specified case'
            german2: (Alternative German language stemmer. Handles the umlaut by expanding ü to ue in most contexts.)
            group: '- (Required) Index of the character group within the matching expression to extract into tokens. Use 0 to extract all character groups.'
            ignoreCase: '- The flag that indicates whether or not to ignore case of stop words when filtering the tokens to remove. The value can be one of the following:'
            ignoredTags: '- a list of HTML tags to exclude from filtering'
            include: '- to include the original tokens with the encoded tokens in the output of the token filter. We recommend this value if you want queries on both the original tokens as well as the encoded forms.'
            kp: (Kraaij-Pohlmann stemmer, an alternative stemmer for Dutch.)
            lovins: (The first-ever published "Lovins JB" stemming algorithm.)
            mappings_dynamic: '- Indicates whether the index uses dynamic or static mapping. For dynamic mapping, set the value to true. For static mapping, specify the fields to index using mappings_fields'
            mappings_fields: '- attribute is required when mappings_dynamic is false. This field needs to be a JSON string in order to be decoded correctly.'
            matches: '- (Required) Acceptable values are:'
            max: '- The maximum length of a token. Must be greater than or equal to min.'
            maxGram: '- (Required) Number of characters to include in the longest token created.'
            maxShingleSize: '- (Required) Maximum number of tokens per shingle. Must be greater than or equal to minShingleSize.'
            maxTokenLength: '- Maximum length for a single token. Tokens greater than this length are split at maxTokenLength into multiple tokens.'
            min: '- The minimum length of a token. Must be less than or equal to max.'
            minGram: '- (Required) Number of characters to include in the shortest token created.'
            minShingleSize: '- (Required) Minimum number of tokens per shingle. Must be less than or equal to maxShingleSize.'
            name: '- (Required) The name of the search index you want to create.'
            nfc: (Canonical Decomposition, followed by Canonical Composition)
            nfd: (Canonical Decomposition)
            nfkc: (Compatibility Decomposition, followed by Canonical Composition)
            nfkd: (Compatibility Decomposition)
            normalizationForm: '- Normalization form to apply. Accepted values are:'
            omit: '- to omit the original tokens and include only the encoded tokens in the output of the token filter. Use this value if you want to only query on the encoded forms of the original tokens.'
            originalTokens: '- Specifies whether to include or omit the original tokens in the output of the token filter. Value can be one of the following:'
            pattern: '- (Required) A regular expression to match against.'
            porter: (The original Porter English stemming algorithm.)
            project_id: '- (Required) The ID of the organization or project you want to create the search index within.'
            replacement: '- (Required) Replacement string to substitute wherever a matching pattern occurs.'
            search_analyzer: '- Analyzer to use when searching the index. Defaults to lucene.standard'
            source_collection: '- (Required) Name of the source MongoDB collection for the synonyms. Documents in this collection must be in the format described in the Synonyms Source Collection Documents.'
            stemmerName: '- (Required) The following values are valid:'
            synonyms: '- Synonyms mapping definition to use in this index.'
            termNotInBounds: '- Accepted values are:'
            termsNotInBounds: '- Accepted values are:'
            timeouts: '- (Optional) The duration of time to wait for Search Index to be created, updated, or deleted. The timeout value is defined by a signed sequence of decimal numbers with an time unit suffix such as: 1h45m, 300s, 10m, .... The valid time units are:  ns, us (or µs), ms, s, m, h. The default timeout for Serach Index create & update is 3h. Learn more about timeouts here.'
            token: '- (Required) The list of stop words that correspond to the tokens to remove. Value must be one or more stop words.'
            token_filters: '- Array containing zero or more token filters. Always require a type field, and some take additional options as well:'
            tokenizer: '- (Required) Tokenizer to use. Determines how Atlas Search splits up text into discrete chunks of indexing. Always require a type field, and some take additional options as well.'
            "true": '- to ignore case and remove all tokens that match the specified stop words'
            type: '- (Required) Must be htmlStrip'
            types: 'of character filters:'
            wait_for_index_build_completion: '- (Optional) Wait for search index to achieve Active status before terraform considers resource built.'
        importStatements: []
    serverless instance:
        subCategory: ""
        description: Provides a Serverless Instance resource.
        name: serverless instance
        title: serverless instance
        argumentDocs:
            connection_strings_private_endpoint_srv: '- List of Serverless Private Endpoint Connections'
            connection_strings_standard_srv: '- Public mongodb+srv:// connection string that you can use to connect to this serverless instance.'
            continuous_backup_enabled: '- (Optional) Flag that indicates whether the serverless instance uses Serverless Continuous Backup. If this parameter is false or not used, the serverless instance uses Basic Backup.'
            create_date: '- Timestamp that indicates when MongoDB Cloud created the serverless instance. The timestamp displays in the ISO 8601 date and time format in UTC.'
            id: '- Unique 24-hexadecimal digit string that identifies the serverless instance.'
            mongo_db_version: '- Version of MongoDB that the serverless instance runs, in <major version>.<minor version> format.'
            name: '- (Required) Human-readable label that identifies the serverless instance.'
            project_id: '- (Required) The ID of the organization or project you want to create the serverless instance within.'
            provider_settings_backing_provider_name: '- (Required) Cloud service provider on which MongoDB Cloud provisioned the serverless instance.'
            provider_settings_provider_name: '- (Required) Cloud service provider that applies to the provisioned the serverless instance.'
            provider_settings_region_name: |-
                - (Required)
                Human-readable label that identifies the physical location of your MongoDB serverless instance. The region you choose can affect network latency for clients accessing your databases.
            state_name: '- Stage of deployment of this serverless instance when the resource made its request.'
            termination_protection_enabled: '- Flag that indicates whether termination protection is enabled on the cluster. If set to true, MongoDB Cloud won''t delete the cluster. If set to false, MongoDB Cloud will delete the cluster.'
        importStatements: []
